{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "12_report.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "699d979d"
      },
      "source": [
        "**`COPYRIGHT(C) 2021 THE CYBER UNIVERSITY OF KOREA ALL RIGHTS RESERVED.`**\n",
        "\n",
        "본 파일의 외부 배포를 금지합니다."
      ],
      "id": "699d979d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c7410fc"
      },
      "source": [
        "# 1번과제 - position regression 2.0 (50점)  "
      ],
      "id": "3c7410fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c37fb08"
      },
      "source": [
        "**템플릿 A**"
      ],
      "id": "0c37fb08"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ff61ec"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 재현 가능한 난수 생성\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "def load_data():\n",
        "    n = 2000\n",
        "    split = 0.8\n",
        "    n_train = (int)(split*n)\n",
        "    \n",
        "    y = np.random.randint(28, size=(n,2))\n",
        "    x = np.empty((n,28,28))\n",
        "    \n",
        "    for i in tqdm(range(n)):\n",
        "        img = np.zeros((28,28))\n",
        "        cv2.circle(img, (y[i][0],y[i][1]), 3, 255, -1)\n",
        "        x[i] = img\n",
        "    return ((x[:n_train], y[:n_train]), (x[n_train:], y[n_train:]))\n",
        "\n",
        "def label(y):\n",
        "    return np.around(y).astype('int')\n",
        "        \n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "# normalize image\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(str(label(y_test[i])))\n",
        "plt.show()\n",
        "\n",
        "def pos_accuracy(y_true, y_pred):\n",
        "    label_true = tf.round(y_true)\n",
        "    label_pred = tf.round(y_pred)\n",
        "    is_correct = tf.reduce_all(label_true == label_pred, axis=1)\n",
        "    is_correct = tf.cast(is_correct, 'float32')\n",
        "    score = tf.reduce_mean(is_correct)\n",
        "    return score\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(2, activation=None)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=SGD(learning_rate=0.001), loss='mse', metrics=[pos_accuracy])\n",
        "\n",
        "# 이 자리에 LrReducer snippet을 추가합니다.\n",
        "# def LrReducer():\n",
        "#    ...\n",
        "# lrreducer = LrReducer()\n",
        "\n",
        "# 이 자리에 ModelCheckpoint snippet을 추가합니다.\n",
        "\n",
        "n_batch = 32\n",
        "n_epochs = 400\n",
        "\n",
        "# 1. model.fit의 반환 결과를 history 변수에 저장합니다.\n",
        "# 2. lrreducer callback을 추가합니다.\n",
        "# 3. checkpoint callback을 추가합니다.\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    batch_size=n_batch,\n",
        "    epochs=n_epochs,\n",
        ")\n",
        "\n",
        "# 여기에 저장된 weights를 loading하는 코드를 추가합니다.\n",
        "\n",
        "# 여기에 Graph snippet 코드를 추가합니다.\n",
        "\n",
        "# LrReducer 중 patience의 역할은 무엇입니까?\n",
        "ans01 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\"\n",
        "\n",
        "# LrReducer 중 reduce_rate의 역할은 무엇입니까?\n",
        "ans02 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\"\n",
        "\n",
        "# LrReducer 중 reduce_nb의 역할은 무엇입니까?\n",
        "ans03 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\"\n",
        "\n",
        "#  4주차 과제와 차이가 발생하였는지에 대해, 여기에 결과와 이유를 적어봅시다.\n",
        "#  주의: 아래의 코드 중 \"\"\"으로 둘러져있는 것은 python에서 여러줄의 텍스트를 string으로 지정하는 문법입니다. 이 문법을 유지하면서 내용을 적어주세요\n",
        "ans04 = \"\"\"\n",
        "결과: 4주차 과제에서는 val_pos_accuracy가 0.000 이었다.\n",
        "이유: ???????? 라고 생각한다.\n",
        "\"\"\"\n",
        "\n",
        "# 모델을 ans02 변수에 기록합니다. \n",
        "ans05 = model\n",
        "\n",
        "# 모델의 성능 측정\n",
        "val_loss, val_pos_accuracy = model.evaluate(x_test, y_test)\n",
        "print('val_loss =', val_loss, 'val_pos_accuracy =', val_pos_accuracy)\n",
        "\n",
        "# val_loss의 저장 \n",
        "ans06 = val_loss\n",
        "ans07 = val_pos_accuracy\n",
        "\n",
        "# Fully connnected Net의 경우와 ConvNet의 검증셋 성능 차이에 대해 그 이유를 추정해 봅시다.\n",
        "ans08 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\""
      ],
      "id": "08ff61ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b88bdc26"
      },
      "source": [
        "이번 과제는 4주차 과제중 하나인 position regression을 개선하는 것입니다.  \n",
        "기본 소스에 대한 설명은 4주차 과제에 있으니, 필요하신 분들은 다시 다운로드 받아서 읽어봐 주십시오.  \n",
        "\n",
        "이 과제는 컨볼루션 신경망의 좋은 성능을 확인해 볼 수 있는 예제라고 하겠습니다.  \n",
        "Epoch에 따른 손실함수와 정확도의 추이를 볼 수 있는 그래픽 출력을 추가하였습니다.  \n",
        "또한, LrReducer 콜백 함수를 통하여 learning rate를 자동적으로 조절하는 기능을 추가하였습니다.  \n",
        "따라서 이번 과제에서는 learning rate의 조절은 필요없습니다.  \n",
        "가장 높은 성능에서 모델의 weights를 저장하는 콜백 기능도 추가 되었습니다.  \n",
        "이 기능까지를 추가하고 나면 FC(fully connected) 모델의 성능을 확인하고 이전 과제와 비교해 보시면 됩니다.  \n",
        "마지막으로는 코드를 컨볼루션 신경망으로 전환하고 튜닝하여 그 차이를 확인해 보도록 하겠습니다.  \n",
        "\n",
        "\n",
        "1. 그래프의 출력\n",
        "\n",
        "   loss와 pos_accuracy를 그래프로 그리기 위해서 model.fit의 결과를 history변수로 먼저 저장합니다.  \n",
        "```python\n",
        "history = model.fit( ... )\n",
        "```\n",
        "   이제 저장된 history를 이용하여 학습이 완료된 후 그래프를 출력합니다.  \n",
        "   다음의 코드 snippet을 이용합니다.  \n",
        "   **Graph snippet**  \n",
        "```python\n",
        "# 학습 정확성 값과 검증 정확성 값을 그래프로 그립니다.\n",
        "plt.plot(history.history['pos_accuracy'])\n",
        "plt.plot(history.history['val_pos_accuracy'])\n",
        "plt.title('Model pos_accuracy')\n",
        "plt.ylabel('Pos_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "# Loss의 그래프\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0.0,1.0)\n",
        "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "2. Learning Rate Reducer callback의 추가\n",
        "\n",
        "   템플릿에서 learning rate는 0.001로 시작하였습니다.  \n",
        "   학습이 진행되면 더이상 검증셋의 정확도(여기서는 val_pos_accuracy)가 증가하지 않을 수 있습니다.  \n",
        "   이때에는 fine tuning을 위하여 learning rate를 점차적으로 줄여줄 필요가 있습니다.  \n",
        "   다음의 callback 함수 snippet을 이용합니다.  \n",
        "   **LrReducer snippet:**    \n",
        "```python\n",
        "class LrReducer(Callback):\n",
        "    def __init__(self, patience=5, reduce_rate=0.5, reduce_nb=5, verbose=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.best_score = -1.\n",
        "        self.reduce_rate = reduce_rate\n",
        "        self.current_reduce_nb = 0\n",
        "        self.reduce_nb = reduce_nb\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current_score = logs.get('val_pos_accuracy')\n",
        "        if current_score > self.best_score:\n",
        "            self.best_score = current_score\n",
        "            self.wait = 0\n",
        "            if self.verbose > 0:\n",
        "                print('---current best score: %.3f' % current_score)\n",
        "        else:\n",
        "            if self.wait >= self.patience:\n",
        "                self.current_reduce_nb += 1\n",
        "                if self.current_reduce_nb <= self.reduce_nb:\n",
        "                    lr = keras.backend.get_value(self.model.optimizer.lr)\n",
        "                    keras.backend.set_value(self.model.optimizer.lr, lr*self.reduce_rate)\n",
        "                    self.wait = 0\n",
        "                    if self.verbose > 0:\n",
        "                        print('---lr decreasing: %e' % (lr*self.reduce_rate))\n",
        "                else:\n",
        "                    if self.verbose > 0:\n",
        "                        print(\"Epoch %d: early stopping\" % (epoch))\n",
        "                    self.model.stop_training = True\n",
        "            self.wait += 1\n",
        "lrreducer = LrReducer(patience=20)\n",
        "```\n",
        "\n",
        "    callback 함수를 이용하기 위해서는 다음과 같이 model.fit을 수정합니다.  \n",
        "```python\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    batch_size=n_batch,\n",
        "    epochs=n_epochs,\n",
        "    callbacks = [lrreducer]\n",
        ")\n",
        "```\n",
        "   실행을 해보고 정상적으로 동작하는 지 확인합시다. \n",
        "   LrReducer callback함수는 학습의 매 epoch이 끝날 때마다 호출됩니다.  \n",
        "   LrReducer의 소스를 읽고 그 원리를 파악합니다.  \n",
        "   `patience` 설정 값은 어떤 역할을 합니까? `ans01`에 적어주세요.  \n",
        "   `reduce_rate`(감소율)의 설정 값은 어떤 역할을 합니까? `ans02`에 적어주세요.  \n",
        "   `reduce_nb`(감소 수)의 설정 값은 어떤 역할을 합니까? `ans03`에 적어주세요.  \n",
        "\n",
        "3. checkpoint callback의 추가  \n",
        "    이번에는 `val_pos_accuracy`가 최고점을 갱신하면 자동으로 모델의 weights를 저장하도록 callback을 추가합니다.  \n",
        "    **ModelCheckpoint snippet:**  \n",
        "```python\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_pos_accuracy', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)\n",
        "```\n",
        "    callback 사용을 위하여 최종적인 `model.fit`을 다음과 같이 수정합니다.\n",
        "```python\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    batch_size=n_batch,\n",
        "    epochs=n_epochs,\n",
        "    callbacks = [lrreducer, checkpoint] # 두 가지의 callback 모두 사용\n",
        ")\n",
        "```\n",
        "\n",
        "4. 학습이 끝난 후에 저장한 weights를 다시 loading하여 불러오는 코드를 `model.fit` 호출 다음에 추가합니다.  \n",
        "    최고 `val_pos_accuracy`가 저장되어 있을 것입니다.  \n",
        "```python\n",
        "model.load_weights(\"best_model.h5\")\n",
        "```\n",
        "\n",
        "5. 이제 검증셋의 `val_loss`와 `val_pos_accuracy`를 확인해 봅시다.  \n",
        "    아래의 코드는 이미 템플릿에 포함되어 있으므로 별도의 수정이 필요없습니다.  \n",
        "```python\n",
        "val_loss, val_pos_accuracy = model.evaluate(x_test, y_test)\n",
        "print('val_loss =', val_loss, 'val_pos_accuracy =', val_pos_accuracy)\n",
        "```\n",
        "\n",
        "6. 결과의 분석  \n",
        "    이 모델의 목표였던 `val_pos_accuracy`는 약 0.887입니다.  \n",
        "    이제 이 결과를 4주차 과제였던 여러분의 모델과 비교해 봅시다.  \n",
        "    (4주차 과제에서 `val_pos_accuracy` 대신에 `val_accuracy`를 측정했던 분들은 코드를 수정하여 다시 확인해 봅시다.)  \n",
        "    정확도(val_pos_accuracy)를 비교해 보니까 어떻습니까?  \n",
        "    여러분이 4주차에 만들었던 모델과 성능차이가 있다면, 어떤 부분에서 차이가 났는지에 대해 간단히 추정해 봅시다.  \n",
        "    추정한 내용을 `ans04`에 적어봅시다.  \n",
        "\n",
        "7. CNN으로의 전환  \n",
        "    이제 모델 정의 부분을 ConvNet으로 변경하여 봅시다.  \n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Reshape(input_shape=(28, 28), target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='valid', activation='relu'),\n",
        "    # ...\n",
        "    # ...\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(2, activation=None)\n",
        "])\n",
        "```\n",
        "    맨 처음 `Reshape`부분은 Conv2D를 위하여 채널을 추가하기 위한 것입니다. (수정하지 않도록 합시다.)  \n",
        "    맨 마지막 `Flatten`과 `Dense` 레이어는 x,y좌표의 결과 출력을 위한 것입니다. (이 코드는 수정하지 않도록 합시다.)  \n",
        "    `Reshape`과 `Flatten`사이에 복수개의 Conv2D 레이어를 추가합니다.  \n",
        "    이 부분에서는 다음의 하이퍼 파라미터를 조절할 수 있습니다.  \n",
        "    먼저 Conv2D의 레이어 갯수입니다.  \n",
        "    다음은 각 Conv2D 레이어의 필터 수 입니다.  \n",
        "    다음은 `padding`입니다. `same` or `valid` 중에 적절한 것을 선택합니다. (레이어마다 달라도 관계없습니다.)  \n",
        "    `Conv2D`의 활성함수는 모두 `relu`를 사용하도록 합시다.  \n",
        "    kernel size는 모두 3x3으로 고정합니다.  \n",
        "    \n",
        "    목표는 성능 최적화, 즉, `val_pos_accuracy`를 최대화 하는 것입니다.  \n",
        "    성능이 만족되면, 성능을 유지하도록 하면서 총 parameter의 수를 줄이도록 노력해 봅시다.  \n",
        "    model.summary()를 이용하여 parameter의 수를 확인해 봅시다.  \n",
        "    각 레이어의 parameter의 수를 손으로 직접 계산하여 model.summary()의 출력과 일치하는 지 비교해 봅시다.  \n",
        "    \n",
        "    완성된 모델을 `ans05` 변수에 기록합니다.  (이미 템플릿 코드에 포함되어 있으므로, 별도의 수정이 필요없습니다.)  \n",
        "    `val_loss`와 `val_pos_accuracy`를 각각 `ans06`과 `ans07`에 기록합니다.  (이미 템플릿 코드에 포함되어 있습니다.)  \n",
        "    \n",
        "    처음에 수행한 FC 네트워크와 ConvNet의 성능을 비교해서 성능의 증가 여부와, 그 이유를 추정해 봅시다. `ans08`변수에 저장합니다.  \n",
        "    중요한 것은 학습셋(training set)의 성능은 98%~99% 정도로 두 네트워크 다 높다는 것입니다.  \n",
        "    하지만 테스트셋(혹은 검증셋)에서는 차이가 발생할 것입니다.  \n",
        "    왜 그럴까요?  \n",
        "    차이의 이유를 추정해서 `ans09`에 기입합니다.  "
      ],
      "id": "b88bdc26"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "001a50f1"
      },
      "source": [
        "**과제 기입란**  \n",
        "최종 코드는 모든 수정사항이 반영된 ConvNet이어야 합니다. "
      ],
      "id": "001a50f1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88a8ce29"
      },
      "source": [
        "# 여기에 템플릿을 복사하고 수정하여 코드를 완성합니다.\n",
        "#"
      ],
      "id": "88a8ce29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5baba92"
      },
      "source": [
        "# 2번과제 - 객체 탐지의 성능 측정 (50점)"
      ],
      "id": "c5baba92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcf5249a"
      },
      "source": [
        "**템플릿 B**"
      ],
      "id": "fcf5249a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0e69cbb"
      },
      "source": [
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image as mp_image\n",
        "from matplotlib import patches\n",
        "import numpy as np\n",
        "\n",
        "# YOLO의 객체 탐지 추론 결과 (coco dataset 기준)\n",
        "# data/VOC2012/JPEGImages/2007_000559.jpg 이미지의 YOLO 추론 결과  \n",
        "pred_class = ['person', 'mouse', 'keyboard', 'bottle', 'cup', 'tvmonitor']\n",
        "\n",
        "# 실제 추론결과에 맞도록 데이터를 수정하세요.\n",
        "confidence = np.array([ 0.11111111, 0.997644, 0.9980441, 0.95675963, 0.49908316, 0.962777 ])\n",
        "pred_box = np.array(\n",
        "[[176.23101175,  33.64125229, 341.28030115, 208.93697127],\n",
        " [333.33333333, 311.97865129, 444.84830765, 348.11431027],\n",
        " [ 79.03037965, 311.5952915,  380.61593198, 366.52572849],\n",
        " [ 33.85694697, 247.93674767,  79.78938358, 354.1084524 ],\n",
        " [405.63467145, 177.77686685, 461.20873177, 238.07753231],\n",
        " [159.79316831,  26.0287001,  371.51022765, 219.53228937]]\n",
        ")\n",
        "\n",
        "ans09 = confidence[0]\n",
        "ans10 = pred_box[2][0]\n",
        "\n",
        "# data/VOC2012/JPEGImages/2007_000559.jpg 이미지의 Ground Truth\n",
        "y_class = ['bottle', 'tvmonitor', 'keyboard', 'cup', 'mouse']\n",
        "y_box = np.array(\n",
        "[[111, 111, 222, 222], # bottle 이 부분을 수정하세요\n",
        " [ 50, 222, 122, 333], # tvmonitor 이 부분을 수정하세요\n",
        " [ 77, 313, 382, 366], # keyboard\n",
        " [405, 177, 461, 238], # cup\n",
        " [385, 311, 444, 348]] # mouse\n",
        ", dtype = 'float64'\n",
        ")\n",
        "\n",
        "ans11 = y_box[0:2]\n",
        "\n",
        "img_url = 'https://user-images.githubusercontent.com/38934308/141396886-34953093-8fb6-4984-a0e9-3598ba802828.jpg'\n",
        "img_path = keras.utils.get_file(\"2007_000559.jpg\", img_url)\n",
        "image = mp_image.imread(img_path)\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "for box in pred_box:\n",
        "    ax.add_patch(patches.Rectangle(\n",
        "        (box[0], box[1]), box[2]-box[0]+1, box[3]-box[1]+1,\n",
        "        edgecolor = 'tab:blue', linewidth=3,\n",
        "        fill=False\n",
        "    ))\n",
        "for box in y_box:\n",
        "    ax.add_patch(patches.Rectangle(\n",
        "        (box[0], box[1]), box[2]-box[0]+1, box[3]-box[1]+1,\n",
        "        edgecolor = 'orange', linewidth=3, alpha=0.7,\n",
        "        fill=False\n",
        "    ))\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "# 두 개의 bounding box의 iou 계산\n",
        "def bbox_iou(box1, box2):\n",
        "    # box의 넓이 계산: area = w * h\n",
        "    box1_area = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
        "    box2_area = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
        "    \n",
        "    # 교집합 box의 upper-left 좌표\n",
        "    left_up = np.maximum(box1[:2], box2[:2])\n",
        "    # 교집합 box의 lower-right 좌표\n",
        "    right_down = np.minimum(box1[2:], box2[2:])\n",
        "    \n",
        "    # 교집합 box의 width와 height\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    \n",
        "    # 교집합 box의 넓이: area = w * h\n",
        "    inter_area = inter_section[0]*inter_section[1]\n",
        "    \n",
        "    # 합집합 면적\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # IOU의 산출\n",
        "    iou = inter_area/union_area\n",
        "    return iou\n",
        "\n",
        "# 교집합 box의 upper-left 좌표와 lower-right좌표를 산출하는 원리를 적어주세요.\n",
        "ans12 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\"\n",
        "\n",
        "# 어떤 경우에 right_down - left_up이 음수가 되는 지 확인해 봅시다.\n",
        "ans13 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\"\n",
        "\n",
        "tp = []\n",
        "for p_c, p_b in zip(pred_class, pred_box):\n",
        "    tp_tmp = 0\n",
        "    for y_c, y_b in zip(y_class, y_box):\n",
        "        if y_c == p_c and bbox_iou(p_b, y_b) > 0.5:\n",
        "            tp_tmp = 1\n",
        "            break\n",
        "    tp.append(tp_tmp)\n",
        "\n",
        "tp = np.array(tp)\n",
        "# False Positive \n",
        "fp = 1 - tp\n",
        "\n",
        "npos = len(y_box) # 총 GT의 갯수\n",
        "\n",
        "# sort by confidence (confidence가 큰 순으로 정렬)\n",
        "sorted_ind = np.argsort(-confidence)\n",
        "tp = tp[sorted_ind]\n",
        "fp = fp[sorted_ind]\n",
        "\n",
        "print('sorted tp =', tp)\n",
        "print('sorted fp =', fp)\n",
        "\n",
        "# 누적 precision recall의 계산\n",
        "fp = np.cumsum(fp)\n",
        "tp = np.cumsum(tp)\n",
        "rec = tp / float(npos)  # 누적 tp를 GT의 갯수로 나눔\n",
        "prec = tp / (tp + fp)\n",
        "print('prec =', prec)\n",
        "print('rec =', rec)\n",
        "\n",
        "# AP (average precision의 계산)\n",
        "def voc_ap(rec, prec):\n",
        "    # correct AP calculation\n",
        "    # first append sentinel values at the end\n",
        "    mrec = np.concatenate(([0.], rec, [1.]))\n",
        "    mpre = np.concatenate(([0.], prec, [0.]))\n",
        "\n",
        "    # compute the precision envelope\n",
        "    for i in range(mpre.size - 1, 0, -1):\n",
        "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "    # to calculate area under PR curve, look for points\n",
        "    # where X axis (recall) changes value\n",
        "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "    # and sum (\\Delta recall) * prec\n",
        "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap\n",
        "\n",
        "ap = voc_ap(rec, prec)\n",
        "print('ap =', ap)\n",
        "\n",
        "ans14 = ap\n",
        "\n",
        "# 본 과제를 수행한 시간이나 기타 의견 등이 있으시면 적어 주세요. (공란으로 두셔도 됩니다.)\n",
        "ans15 = \"\"\"\n",
        "여기에 적어주세요.\n",
        "\"\"\""
      ],
      "id": "c0e69cbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3e623ac"
      },
      "source": [
        "이번에는 YOLO 객체 탐지 모델을 실행하고 성능을 측정하는 과제입니다.  \n",
        "이번 과제는 길어 보이지만 실제로 코드를 수정하는 부분은 없고, 데이터 부분만 수정하여 구동하는 것과 소스의 분석이 주된 목표입니다.  \n",
        "이 과제를 통하여 객체탐지의 성능 지표인 mAP에 대한 구성요소를 이해할 수 있을 것입니다.  \n",
        "(TP, FP, FN의 이해)  \n",
        "(precision과 recall의 이해)   \n",
        "(precision-recall graph를 이용한 AP 산출식의 이해)    \n",
        "\n",
        "1. 샘플 이미지를 이용한 YOLO의 구동\n",
        "\n",
        "    먼저 실습자료인 `08-voc.ipynb`를 처음부터 실행해봅시다.  \n",
        "    **convert YOLOv4 weights to Keras h5** 섹션까지만 실행합니다.  \n",
        "    (**mAP의 계산** 섹션은 많은 시간이 소요되기 때문입니다.)  \n",
        "\n",
        "    다음 cell까지 실행하면 성공입니다.  \n",
        "```python\n",
        "image = cv2.imread('data/VOC2012/JPEGImages/2007_000187.jpg')\n",
        "image, boxes, scores, classes = _decode.detect_image(image, True)\n",
        "cv2_imshow(image)\n",
        "```\n",
        "\n",
        "    이제 이미지의 경로를 다음과 같이 변경하고 실행합니다.\n",
        "```python\n",
        "image = cv2.imread('data/VOC2012/JPEGImages/2007_000559.jpg')\n",
        "image, boxes, scores, classes = _decode.detect_image(image, True)\n",
        "cv2_imshow(image)\n",
        "```\n",
        "\n",
        "    다음의 이미지가 출력될 것입니다.  \n",
        "\n",
        "    **그림 1.**  \n",
        "![그림1](https://user-images.githubusercontent.com/38934308/141392547-5fd69ae5-070a-49b9-8207-8ecbb4c2d50d.png)  \n",
        "\n",
        "    Cell에 다음 코드를 추가하고 실행합니다. (`08-voc.ipynb`에서 수행합니다.)  \n",
        "```python\n",
        "class_names = get_class('model_data/coco_classes.txt')\n",
        "for c, s in zip(classes, scores):\n",
        "    print(class_names[c], s)\n",
        "print(boxes)\n",
        "```\n",
        "    그러면 다음과 같은 출력 결과를 얻을 수 있습니다.  \n",
        "    (`????`부분은 여러분들이 직접 데이터를 확인해 주세요.)\n",
        "```\n",
        "person ?.????????\n",
        "mouse 0.997644\n",
        "keyboard 0.9980441\n",
        "bottle 0.95675963\n",
        "cup 0.49908316\n",
        "tvmonitor 0.962777\n",
        "[[176.23101175  33.64125229 341.28030115 208.93697127]\n",
        " [???.???????? 311.97865129 444.84830765 348.11431027]\n",
        " [ 79.03037965 311.5952915  380.61593198 366.52572849]\n",
        " [ 33.85694697 247.93674767  79.78938358 354.1084524 ]\n",
        " [405.63467145 177.77686685 461.20873177 238.07753231]\n",
        " [159.79316831  26.0287001  371.51022765 219.53228937]]\n",
        "```\n",
        "    윗 부분은 각각의 인식 결과와 그 confidence score입니다.  \n",
        "    아래의 list 부분은 객체의 위치 인식 결과 입니다.  \n",
        "    위치는 `[xmin, ymin, xmax, ymax]`의 형식입니다.  \n",
        "    결과부분을 복사하여 메모장에 붙여넣기 해 둡니다.\n",
        "\n",
        "    이제 템플릿 B의 코드를 복사하신 후, 과제기입란에서 `confidence`와 `pred_box`를 해당 데이터에 맞게 수정합시다.  \n",
        "    대부분의 값은 템플릿 B에 이미 있습니다.  \n",
        "    수정할 부분은 `pred_conficence` 중 `0.11111111` 부분과, box 중 `333.33333333` 두 군데 입니다.  \n",
        "    수정된 결과가 `ans09`와 `ans10`에 저장됩니다. (템플릿에 이미 포함되어 있습니다.)  \n",
        "\n",
        "    이제 이 이미지의 annotation 결과(Ground Truth)를 확인해 보겠습니다.  \n",
        "    `08-voc.ipynb`에 cell을 추가하고 다음 명령을 수행해 봅시다.  \n",
        "```\n",
        "!cat data/VOC2012/Annotations/2007_000559.xml\n",
        "```\n",
        "    xml 출력 결과를 복사하여 메모장에 붙여넣기 해주세요.  \n",
        "    여기까지 끝나셨으면 `08-voc.ipynb` 실습 노트북은 종료하셔도 됩니다.   \n",
        "\n",
        "    xml 데이터의 내용을 잘 보시면 bottle과 tvmonitor만이 들어있습니다.  \n",
        "    이것은 80개 class인 coco dataset과 달리, VOC에는 20개의 class 밖에 없기 때문입니다.  \n",
        "    나머지 객체들은 ground truth에서 빠져있습니다.  \n",
        "    그래서 keyboard, cup, mouse의 annotation결과를 y_box에 추가하였습니다. \n",
        "\n",
        "    원래 VOC xml 데이터에 있는 bottle과 tvmonitor의 bounding box의 좌표값을 `y_box`에 옮겨서 완성합니다.  \n",
        "    `y_box` 데이터의 처음 두 줄을 수정하시면 됩니다.  \n",
        "\n",
        "    수정된 결과가 `ans11`에 저장됩니다. (템플릿에 이미 포함되어 있습니다.)  \n",
        "\n",
        "    데이터가 수정되었으면, 정상적으로 실행되는 지 확인해 봅시다.  \n",
        "    출력된 이미지에서 파란색은 prediction된 결과이고, 주황색은 ground truth입니다.  \n",
        "    인터넷에서 matplotlib를 이용하여 사각형을 그리는 함수인 `patches.Rectangle`에 대해 검색하고 파라미터의 의미를 이해해 봅시다.  \n",
        "    파란색 box가 **그림 1**의 box와 일치하는 지 확인합시다.  \n",
        "\n",
        "2. IOU의 계산  \n",
        "\n",
        "    다음은 IOU를 계산하는 `bbox_iou`함수입니다.  \n",
        "```python\n",
        "# 두 개의 bounding box의 iou 계산\n",
        "def bbox_iou(box1, box2): # box1, box2는 [xmin, ymin, xmax, ymax]의 형식\n",
        "    # box의 넓이 계산: area = w * h\n",
        "    box1_area = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
        "    box2_area = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
        "    \n",
        "    # 교집합 box의 upper-left 좌표\n",
        "    left_up = np.maximum(box1[:2], box2[:2])\n",
        "    # 교집합 box의 lower-right 좌표\n",
        "    right_down = np.minimum(box1[2:], box2[2:])\n",
        "    \n",
        "    # 교집합 box의 width와 height\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    \n",
        "    # 교집합 box의 넓이: area = w * h\n",
        "    inter_area = inter_section[0]*inter_section[1]\n",
        "    \n",
        "    # 합집합 면적\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # IOU의 산출\n",
        "    iou = inter_area/union_area\n",
        "    return iou\n",
        "```\n",
        "    소스 코드를 읽고 이해해 봅시다.  \n",
        "    코드 중 교집합 box의 좌상위치(`left_up`)과 우하위치(`right_down`)를 계산하는 코드는 다음과 같습니다.  \n",
        "```python\n",
        "left_up = np.maximum(box1[:2], box2[:2])\n",
        "right_down = np.minimum(box1[2:], box2[2:])\n",
        "```\n",
        "    위의 코드가 어떻게 교집합의 위치를 추출하는 지를 `ans12`에 적어주세요.  \n",
        "\n",
        "    교집합 box의 width와 height를 계산하는 코드는 다음과 같습니다.   \n",
        "```python\n",
        "right_down - left_up\n",
        "```\n",
        "    여기서 `right_down`과 `left_up`은 모두 `x,y`의 데이터가 저장된 `(2,)` shape의 텐서입니다.    \n",
        "    따라서 두 값을 빼면, width와 height가 동시에 생성됩니다.   \n",
        "    여기에 추가적으로 `np.maximum(..., 0.0)`이 사용되었습니다.  \n",
        "    즉, width와 height가 음수가 나오면 0으로 변경한다는 의미입니다.  \n",
        "\n",
        "    어떤 경우에 width혹은 height가 음수가 나오는지 `ans13`에 적어주세요.  \n",
        "\n",
        "    필요하다면 다음의 디버깅 코드를 이용하여, 실제로 두 box의 값을 변경하면서 IOU가 정상적으로 출력되는 지 확인해 봅시다.  \n",
        "```python\n",
        "# IOU 테스트 코드 (이부분의 실험은 별도 cell에서 각자 수행해 보세요.)\n",
        "sample_box1 = np.array([0.0, 0.0, 2.0, 2.0])\n",
        "sample_box2 = np.array([1.0, 1.0, 3.0, 3.0])\n",
        "print(bbox_iou(sample_box1, sample_box2))\n",
        "```\n",
        "\n",
        "    이 IOU 계산 함수를 `09_yolo.ipynb` 실습 파일 내의 `bbox_iou`함수와 비교하여 봅시다.  \n",
        "    실습 파일의 bbox_iou는 입력 box의 형식이 중심좌표, w,h의 형식이고 여러개의 box들의 iou를 동시에 계산한다는 점이 다릅니다.  \n",
        "    (numpy 대신에 tensorflow 텐서 계산 함수가 사용되었습니다.)  \n",
        "    과제에서 IOU를 계산하는 코드에, if문이나, for문이 사용되지 않았음에 주목합시다.  \n",
        "    전체를 tensor operation만을 이용하여 해결하였습니다.  \n",
        "    이것은 더 많은 여러개의 box에 대한 IOU를 동시에 계산하는 코드로 확장할 수 있게 합니다. (`09_yolo.ipynb`내의 bbox_iou처럼)  \n",
        "    이와 같은 코드는 확장 가능할 뿐 아니라, GPU에서의 병렬처리 속도를 증가시킵니다.  \n",
        "    따라서 딥러닝의 핵심 코드(모델, 손실함수) 들은 텐서와 텐서 연산만을 사용하여 처리하는 것이 바람직하다고 하겠습니다.  \n",
        "\n",
        "3. mAP의 계산 (여기서는 AP까지만 계산합니다.)  \n",
        "    이제 `tp` (True Positive) 여부를 산정합니다.   \n",
        "    class가 일치하고 IOU가 0.5이상이면 True Positive로 판정합니다. (VOC의 판정기준을 따랐습니다.)\n",
        "```python\n",
        "tp = []\n",
        "for p_c, p_b in zip(pred_class, pred_box):\n",
        "    tp_tmp = 0\n",
        "    for y_c, y_b in zip(y_class, y_box):\n",
        "        if y_c == p_c and bbox_iou(p_b, y_b) > 0.5:\n",
        "            tp_tmp = 1\n",
        "            break\n",
        "    tp.append(tp_tmp)\n",
        "```\n",
        "    YOLO의 추론결과를 보면 `person`이 오인식 되었다는 것을 알 수 있습니다.  \n",
        "    따라서 `tp` 중 `person`에 해당하는 것은 0이어야 합니다.  \n",
        "    마찬가지로 `fp`(False Positive) 중 `person`에 해당하는 것은 1이어야 합니다.  \n",
        "\n",
        "    이것을 이용해서 AP를 구해보겠습니다.  \n",
        "    원래는 같은 class들에서 AP를 구하는 것이나, 편의상 모든 class에 대해 구하도록 하겠습니다.  \n",
        "\n",
        "    AP의 계산에 대한 상세 설명은 `08_voc.ipynb`의 맨 마지막 부분에 예제와 소스 코드를 추가해 놓았습니다.  \n",
        "    각자 읽어보고 실행해 보도록 합시다.  \n",
        "\n",
        "    이 AP 계산 부분과 소스코드의 이해는 과제 채점에 반영하지 않고, 자율적인 학습에 맡기겠습니다.  \n",
        "    맨 처음에 데이터를 정상적으로 수정하였다면, 최종 결과는 템플릿 코드에 의해 산출될 것입니다.  \n",
        "    이 AP를 `ans14`에 저장합니다. (이미 템플릿에 포함되어 있습니다.)  \n",
        "\n"
      ],
      "id": "c3e623ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glDYfiehhYQX"
      },
      "source": [
        "**과제 기입란**"
      ],
      "id": "glDYfiehhYQX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a542662"
      },
      "source": [
        "# 여기에 템플릿을 복사하고 수정합니다.\n",
        "#\n"
      ],
      "id": "0a542662",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20b45b10"
      },
      "source": [
        "**다음은 답안의 형식을 확인하는 코드입니다. 실행해서 오류가 없는 지 확인합시다.**"
      ],
      "id": "20b45b10"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d15caf"
      },
      "source": [
        "from tensorflow import keras\n",
        "# 답안의 형식을 점검합니다.\n",
        "\n",
        "error = False\n",
        "\n",
        "try:\n",
        "    if type(ans01) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans01 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans02) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans02 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans03) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans03 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans04) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans04 error')\n",
        "    \n",
        "try:\n",
        "    if ans05.inputs[0].shape.as_list() != [None, 28, 28]:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans05 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans06) != float:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans06 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans07) != float:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans07 error')\n",
        "    \n",
        "try:\n",
        "    if type(ans08) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans08 error')\n",
        "    \n",
        "try:\n",
        "    if not isinstance(ans09, np.float64):\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans09 error')\n",
        "    \n",
        "try:\n",
        "    if not isinstance(ans10, np.float64):\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans10 error')\n",
        "    \n",
        "try:\n",
        "    if not isinstance(ans11, np.ndarray):\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans11 error')\n",
        "\n",
        "try:\n",
        "    if type(ans12) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans12 error')\n",
        "\n",
        "try:\n",
        "    if type(ans13) != str:\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans13 error')\n",
        "\n",
        "try:\n",
        "    if not isinstance(ans14, np.float64):\n",
        "        raise\n",
        "except:\n",
        "    error = True\n",
        "    print('ans14 error')\n",
        "\n",
        "if error:\n",
        "    print('답안을 확인하여 주세요')\n",
        "else:\n",
        "    print('답안의 형식 확인이 완료되었습니다.')"
      ],
      "id": "63d15caf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XpkANKpjOsm"
      },
      "source": [
        "# 과제 제출 방법\n",
        "\n",
        "1. **런타임** -> **다시 시작 및 모두 실행**을 수행하여 정상적으로 결과가 출력되는 지 다시 한번 확인합니다.  \n",
        "\n",
        "2. **수정** -> **모든 출력 지우기**를 선택하여 cell의 출력을 지웁니다.\n",
        "\n",
        "3. **파일** -> **`.ipynb`** 다운로드를 선택하여 노트북을 다운로드 합니다.\n",
        "\n",
        "4. 파일 이름을 학번으로 변경합니다. 예) `202099999.ipynb`\n",
        "\n",
        "5. 노트북 파일을 제출하시면 됩니다."
      ],
      "id": "8XpkANKpjOsm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuBUDyB9j2CL"
      },
      "source": [
        ""
      ],
      "id": "zuBUDyB9j2CL",
      "execution_count": null,
      "outputs": []
    }
  ]
}