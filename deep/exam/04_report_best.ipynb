{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68d987b",
   "metadata": {},
   "source": [
    "# FC sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81a7953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 88594.90it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 22:41:35.135202: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-13 22:41:35.550814: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-12-13 22:41:35.550848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19742 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:b5:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                18840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 19,382\n",
      "Trainable params: 19,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 22:41:35.812092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/320\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 61.1680 - pos_accuracy: 0.0037 - val_loss: 29.0588 - val_pos_accuracy: 0.0335\n",
      "Epoch 2/320\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 30.2770 - pos_accuracy: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 22:41:36.562121: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 12.1804 - pos_accuracy: 0.0469 - val_loss: 2.6454 - val_pos_accuracy: 0.1071\n",
      "Epoch 3/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5813 - pos_accuracy: 0.1013 - val_loss: 9.9535 - val_pos_accuracy: 0.0022\n",
      "Epoch 4/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.2057 - pos_accuracy: 0.0825 - val_loss: 1.2307 - val_pos_accuracy: 0.2679\n",
      "Epoch 5/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0114 - pos_accuracy: 0.1931 - val_loss: 1.1315 - val_pos_accuracy: 0.1987\n",
      "Epoch 6/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3213 - pos_accuracy: 0.1425 - val_loss: 1.1286 - val_pos_accuracy: 0.1116\n",
      "Epoch 7/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9671 - pos_accuracy: 0.2100 - val_loss: 1.5099 - val_pos_accuracy: 0.0424\n",
      "Epoch 8/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5845 - pos_accuracy: 0.3806 - val_loss: 0.6378 - val_pos_accuracy: 0.4397\n",
      "Epoch 9/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7818 - pos_accuracy: 0.2000 - val_loss: 0.5959 - val_pos_accuracy: 0.4442\n",
      "Epoch 10/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4075 - pos_accuracy: 0.4931 - val_loss: 0.4923 - val_pos_accuracy: 0.5536\n",
      "Epoch 11/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3699 - pos_accuracy: 0.5269 - val_loss: 0.4815 - val_pos_accuracy: 0.5022\n",
      "Epoch 12/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3567 - pos_accuracy: 0.5175 - val_loss: 0.4367 - val_pos_accuracy: 0.5446\n",
      "Epoch 13/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5470 - pos_accuracy: 0.2756 - val_loss: 0.8201 - val_pos_accuracy: 0.2254\n",
      "Epoch 14/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5059 - pos_accuracy: 0.3731 - val_loss: 0.3814 - val_pos_accuracy: 0.6004\n",
      "Epoch 15/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2662 - pos_accuracy: 0.6369 - val_loss: 0.3819 - val_pos_accuracy: 0.5625\n",
      "Epoch 16/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2927 - pos_accuracy: 0.5494 - val_loss: 0.3899 - val_pos_accuracy: 0.5290\n",
      "Epoch 17/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2507 - pos_accuracy: 0.6181 - val_loss: 0.3719 - val_pos_accuracy: 0.4911\n",
      "Epoch 18/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2850 - pos_accuracy: 0.5181 - val_loss: 0.3958 - val_pos_accuracy: 0.4754\n",
      "Epoch 19/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2701 - pos_accuracy: 0.5544 - val_loss: 0.2900 - val_pos_accuracy: 0.6696\n",
      "Epoch 20/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2909 - pos_accuracy: 0.5019 - val_loss: 0.3402 - val_pos_accuracy: 0.5469\n",
      "Epoch 21/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3113 - pos_accuracy: 0.4638 - val_loss: 0.2833 - val_pos_accuracy: 0.6629\n",
      "Epoch 22/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1986 - pos_accuracy: 0.6919 - val_loss: 0.2592 - val_pos_accuracy: 0.6808\n",
      "Epoch 23/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2067 - pos_accuracy: 0.6456 - val_loss: 0.2614 - val_pos_accuracy: 0.6763\n",
      "Epoch 24/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4354 - pos_accuracy: 0.3869 - val_loss: 0.3407 - val_pos_accuracy: 0.5156\n",
      "Epoch 25/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1815 - pos_accuracy: 0.7006 - val_loss: 0.2374 - val_pos_accuracy: 0.6786\n",
      "Epoch 26/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1593 - pos_accuracy: 0.7362 - val_loss: 0.2264 - val_pos_accuracy: 0.6920\n",
      "Epoch 27/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1638 - pos_accuracy: 0.7250 - val_loss: 0.2222 - val_pos_accuracy: 0.6964\n",
      "Epoch 28/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1528 - pos_accuracy: 0.7469 - val_loss: 0.2225 - val_pos_accuracy: 0.7143\n",
      "Epoch 29/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1611 - pos_accuracy: 0.7319 - val_loss: 0.2214 - val_pos_accuracy: 0.7009\n",
      "Epoch 30/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1584 - pos_accuracy: 0.7231 - val_loss: 0.4479 - val_pos_accuracy: 0.2701\n",
      "Epoch 31/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2658 - pos_accuracy: 0.5387 - val_loss: 0.1967 - val_pos_accuracy: 0.7344\n",
      "Epoch 32/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1465 - pos_accuracy: 0.7437 - val_loss: 0.2116 - val_pos_accuracy: 0.7165\n",
      "Epoch 33/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1413 - pos_accuracy: 0.7556 - val_loss: 0.1883 - val_pos_accuracy: 0.7433\n",
      "Epoch 34/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1128 - pos_accuracy: 0.8056 - val_loss: 0.1767 - val_pos_accuracy: 0.7500\n",
      "Epoch 35/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1217 - pos_accuracy: 0.7994 - val_loss: 0.1826 - val_pos_accuracy: 0.7567\n",
      "Epoch 36/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1132 - pos_accuracy: 0.8131 - val_loss: 0.1674 - val_pos_accuracy: 0.7612\n",
      "Epoch 37/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1279 - pos_accuracy: 0.7806 - val_loss: 0.1749 - val_pos_accuracy: 0.7656\n",
      "Epoch 38/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1039 - pos_accuracy: 0.8263 - val_loss: 0.1614 - val_pos_accuracy: 0.7612\n",
      "Epoch 39/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1384 - pos_accuracy: 0.7425 - val_loss: 0.1779 - val_pos_accuracy: 0.7478\n",
      "Epoch 40/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1101 - pos_accuracy: 0.8150 - val_loss: 0.1562 - val_pos_accuracy: 0.7902\n",
      "Epoch 41/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1187 - pos_accuracy: 0.8025 - val_loss: 0.1813 - val_pos_accuracy: 0.7277\n",
      "Epoch 42/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0997 - pos_accuracy: 0.8344 - val_loss: 0.1964 - val_pos_accuracy: 0.7009\n",
      "Epoch 43/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1003 - pos_accuracy: 0.8425 - val_loss: 0.1492 - val_pos_accuracy: 0.7924\n",
      "Epoch 44/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0848 - pos_accuracy: 0.8656 - val_loss: 0.1378 - val_pos_accuracy: 0.8080\n",
      "Epoch 45/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0816 - pos_accuracy: 0.8725 - val_loss: 0.1438 - val_pos_accuracy: 0.8080\n",
      "Epoch 46/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0796 - pos_accuracy: 0.8756 - val_loss: 0.1339 - val_pos_accuracy: 0.8125\n",
      "Epoch 47/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0980 - pos_accuracy: 0.8456 - val_loss: 0.1481 - val_pos_accuracy: 0.8214\n",
      "Epoch 48/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0954 - pos_accuracy: 0.8569 - val_loss: 0.1405 - val_pos_accuracy: 0.7946\n",
      "Epoch 49/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0698 - pos_accuracy: 0.8925 - val_loss: 0.1289 - val_pos_accuracy: 0.8371\n",
      "Epoch 50/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0770 - pos_accuracy: 0.8931 - val_loss: 0.1182 - val_pos_accuracy: 0.8549\n",
      "Epoch 51/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0654 - pos_accuracy: 0.9056 - val_loss: 0.1230 - val_pos_accuracy: 0.8348\n",
      "Epoch 52/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0710 - pos_accuracy: 0.9013 - val_loss: 0.1227 - val_pos_accuracy: 0.8304\n",
      "Epoch 53/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0626 - pos_accuracy: 0.9081 - val_loss: 0.1088 - val_pos_accuracy: 0.8638\n",
      "Epoch 54/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0575 - pos_accuracy: 0.9194 - val_loss: 0.1079 - val_pos_accuracy: 0.8705\n",
      "Epoch 55/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0550 - pos_accuracy: 0.9225 - val_loss: 0.1175 - val_pos_accuracy: 0.8594\n",
      "Epoch 56/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0612 - pos_accuracy: 0.9187 - val_loss: 0.1136 - val_pos_accuracy: 0.8549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0904 - pos_accuracy: 0.8537 - val_loss: 0.1026 - val_pos_accuracy: 0.8772\n",
      "Epoch 58/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0685 - pos_accuracy: 0.9000 - val_loss: 0.1101 - val_pos_accuracy: 0.8839\n",
      "Epoch 59/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0639 - pos_accuracy: 0.9225 - val_loss: 0.1022 - val_pos_accuracy: 0.8728\n",
      "Epoch 60/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0496 - pos_accuracy: 0.9356 - val_loss: 0.0990 - val_pos_accuracy: 0.8951\n",
      "Epoch 61/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0511 - pos_accuracy: 0.9306 - val_loss: 0.0925 - val_pos_accuracy: 0.8929\n",
      "Epoch 62/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0445 - pos_accuracy: 0.9431 - val_loss: 0.0943 - val_pos_accuracy: 0.8750\n",
      "Epoch 63/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0575 - pos_accuracy: 0.9306 - val_loss: 0.0898 - val_pos_accuracy: 0.8951\n",
      "Epoch 64/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0472 - pos_accuracy: 0.9456 - val_loss: 0.0972 - val_pos_accuracy: 0.9085\n",
      "Epoch 65/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0430 - pos_accuracy: 0.9469 - val_loss: 0.0903 - val_pos_accuracy: 0.9062\n",
      "Epoch 66/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0457 - pos_accuracy: 0.9494 - val_loss: 0.1059 - val_pos_accuracy: 0.8817\n",
      "Epoch 67/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0449 - pos_accuracy: 0.9494 - val_loss: 0.1001 - val_pos_accuracy: 0.8951\n",
      "Epoch 68/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0455 - pos_accuracy: 0.9513 - val_loss: 0.0938 - val_pos_accuracy: 0.9129\n",
      "Epoch 69/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0547 - pos_accuracy: 0.9431 - val_loss: 0.0870 - val_pos_accuracy: 0.8951\n",
      "Epoch 70/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0389 - pos_accuracy: 0.9556 - val_loss: 0.1043 - val_pos_accuracy: 0.8929\n",
      "Epoch 71/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0376 - pos_accuracy: 0.9638 - val_loss: 0.0764 - val_pos_accuracy: 0.9286\n",
      "Epoch 72/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0402 - pos_accuracy: 0.9550 - val_loss: 0.0904 - val_pos_accuracy: 0.9040\n",
      "Epoch 73/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0551 - pos_accuracy: 0.9344 - val_loss: 0.0759 - val_pos_accuracy: 0.9330\n",
      "Epoch 74/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0318 - pos_accuracy: 0.9644 - val_loss: 0.0774 - val_pos_accuracy: 0.9196\n",
      "Epoch 75/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0432 - pos_accuracy: 0.9531 - val_loss: 0.0799 - val_pos_accuracy: 0.9241\n",
      "Epoch 76/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0321 - pos_accuracy: 0.9625 - val_loss: 0.0705 - val_pos_accuracy: 0.9330\n",
      "Epoch 77/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0382 - pos_accuracy: 0.9538 - val_loss: 0.1318 - val_pos_accuracy: 0.7835\n",
      "Epoch 78/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0549 - pos_accuracy: 0.9150 - val_loss: 0.0802 - val_pos_accuracy: 0.9040\n",
      "Epoch 79/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0350 - pos_accuracy: 0.9619 - val_loss: 0.0708 - val_pos_accuracy: 0.9263\n",
      "Epoch 80/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0423 - pos_accuracy: 0.9538 - val_loss: 0.1348 - val_pos_accuracy: 0.8170\n",
      "Epoch 81/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1436 - pos_accuracy: 0.6881 - val_loss: 0.0695 - val_pos_accuracy: 0.9308\n",
      "Epoch 82/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0306 - pos_accuracy: 0.9669 - val_loss: 0.0754 - val_pos_accuracy: 0.9263\n",
      "Epoch 83/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0320 - pos_accuracy: 0.9656 - val_loss: 0.0717 - val_pos_accuracy: 0.9353\n",
      "Epoch 84/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0331 - pos_accuracy: 0.9694 - val_loss: 0.0637 - val_pos_accuracy: 0.9330\n",
      "Epoch 85/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0455 - pos_accuracy: 0.9394 - val_loss: 0.1214 - val_pos_accuracy: 0.8058\n",
      "Epoch 86/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0318 - pos_accuracy: 0.9663 - val_loss: 0.0784 - val_pos_accuracy: 0.9174\n",
      "Epoch 87/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0290 - pos_accuracy: 0.9706 - val_loss: 0.0633 - val_pos_accuracy: 0.9353\n",
      "Epoch 88/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0260 - pos_accuracy: 0.9719 - val_loss: 0.0610 - val_pos_accuracy: 0.9308\n",
      "Epoch 89/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0287 - pos_accuracy: 0.9706 - val_loss: 0.0673 - val_pos_accuracy: 0.9286\n",
      "Epoch 90/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0245 - pos_accuracy: 0.9731 - val_loss: 0.0589 - val_pos_accuracy: 0.9330\n",
      "Epoch 91/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0240 - pos_accuracy: 0.9719 - val_loss: 0.0608 - val_pos_accuracy: 0.9353\n",
      "Epoch 92/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0270 - pos_accuracy: 0.9725 - val_loss: 0.0611 - val_pos_accuracy: 0.9420\n",
      "Epoch 93/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0228 - pos_accuracy: 0.9750 - val_loss: 0.0574 - val_pos_accuracy: 0.9353\n",
      "Epoch 94/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0244 - pos_accuracy: 0.9750 - val_loss: 0.0588 - val_pos_accuracy: 0.9375\n",
      "Epoch 95/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0268 - pos_accuracy: 0.9769 - val_loss: 0.0571 - val_pos_accuracy: 0.9420\n",
      "Epoch 96/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0231 - pos_accuracy: 0.9756 - val_loss: 0.0600 - val_pos_accuracy: 0.9353\n",
      "Epoch 97/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0269 - pos_accuracy: 0.9744 - val_loss: 0.0782 - val_pos_accuracy: 0.9107\n",
      "Epoch 98/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0299 - pos_accuracy: 0.9750 - val_loss: 0.0607 - val_pos_accuracy: 0.9442\n",
      "Epoch 99/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0262 - pos_accuracy: 0.9769 - val_loss: 0.0602 - val_pos_accuracy: 0.9442\n",
      "Epoch 100/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0276 - pos_accuracy: 0.9762 - val_loss: 0.0593 - val_pos_accuracy: 0.9397\n",
      "Epoch 101/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0282 - pos_accuracy: 0.9756 - val_loss: 0.0645 - val_pos_accuracy: 0.9353\n",
      "Epoch 102/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0255 - pos_accuracy: 0.9762 - val_loss: 0.0522 - val_pos_accuracy: 0.9442\n",
      "Epoch 103/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0172 - pos_accuracy: 0.9800 - val_loss: 0.0519 - val_pos_accuracy: 0.9420\n",
      "Epoch 104/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0184 - pos_accuracy: 0.9812 - val_loss: 0.0540 - val_pos_accuracy: 0.9442\n",
      "Epoch 105/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - pos_accuracy: 0.9750 - val_loss: 0.0702 - val_pos_accuracy: 0.9286\n",
      "Epoch 106/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0269 - pos_accuracy: 0.9806 - val_loss: 0.0553 - val_pos_accuracy: 0.9375\n",
      "Epoch 107/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - pos_accuracy: 0.9800 - val_loss: 0.0531 - val_pos_accuracy: 0.9442\n",
      "Epoch 108/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - pos_accuracy: 0.9825 - val_loss: 0.0513 - val_pos_accuracy: 0.9442\n",
      "Epoch 109/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0170 - pos_accuracy: 0.9806 - val_loss: 0.0486 - val_pos_accuracy: 0.9442\n",
      "Epoch 110/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0211 - pos_accuracy: 0.9800 - val_loss: 0.0501 - val_pos_accuracy: 0.9442\n",
      "Epoch 111/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - pos_accuracy: 0.9825 - val_loss: 0.0518 - val_pos_accuracy: 0.9487\n",
      "Epoch 112/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - pos_accuracy: 0.9837 - val_loss: 0.0498 - val_pos_accuracy: 0.9487\n",
      "Epoch 113/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0156 - pos_accuracy: 0.9844 - val_loss: 0.0510 - val_pos_accuracy: 0.9464\n",
      "Epoch 114/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0244 - pos_accuracy: 0.9819 - val_loss: 0.0640 - val_pos_accuracy: 0.9464\n",
      "Epoch 115/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0190 - pos_accuracy: 0.9825 - val_loss: 0.0480 - val_pos_accuracy: 0.9487\n",
      "Epoch 116/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - pos_accuracy: 0.9837 - val_loss: 0.0475 - val_pos_accuracy: 0.9487\n",
      "Epoch 117/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0148 - pos_accuracy: 0.9862 - val_loss: 0.0522 - val_pos_accuracy: 0.9464\n",
      "Epoch 118/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0265 - pos_accuracy: 0.9812 - val_loss: 0.0520 - val_pos_accuracy: 0.9487\n",
      "Epoch 119/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - pos_accuracy: 0.9831 - val_loss: 0.0473 - val_pos_accuracy: 0.9464\n",
      "Epoch 120/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0134 - pos_accuracy: 0.9850 - val_loss: 0.0458 - val_pos_accuracy: 0.9509\n",
      "Epoch 121/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0226 - pos_accuracy: 0.9844 - val_loss: 0.0514 - val_pos_accuracy: 0.9509\n",
      "Epoch 122/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0175 - pos_accuracy: 0.9869 - val_loss: 0.0459 - val_pos_accuracy: 0.9509\n",
      "Epoch 123/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0138 - pos_accuracy: 0.9862 - val_loss: 0.0440 - val_pos_accuracy: 0.9487\n",
      "Epoch 124/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0128 - pos_accuracy: 0.9869 - val_loss: 0.0446 - val_pos_accuracy: 0.9554\n",
      "Epoch 125/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0124 - pos_accuracy: 0.9875 - val_loss: 0.0445 - val_pos_accuracy: 0.9487\n",
      "Epoch 126/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0163 - pos_accuracy: 0.9850 - val_loss: 0.0481 - val_pos_accuracy: 0.9531\n",
      "Epoch 127/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0131 - pos_accuracy: 0.9869 - val_loss: 0.0450 - val_pos_accuracy: 0.9509\n",
      "Epoch 128/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0156 - pos_accuracy: 0.9862 - val_loss: 0.0436 - val_pos_accuracy: 0.9531\n",
      "Epoch 129/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - pos_accuracy: 0.9881 - val_loss: 0.0431 - val_pos_accuracy: 0.9531\n",
      "Epoch 130/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0119 - pos_accuracy: 0.9875 - val_loss: 0.0434 - val_pos_accuracy: 0.9509\n",
      "Epoch 131/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0122 - pos_accuracy: 0.9881 - val_loss: 0.0428 - val_pos_accuracy: 0.9509\n",
      "Epoch 132/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0177 - pos_accuracy: 0.9869 - val_loss: 0.0626 - val_pos_accuracy: 0.9353\n",
      "Epoch 133/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0214 - pos_accuracy: 0.9887 - val_loss: 0.0434 - val_pos_accuracy: 0.9576\n",
      "Epoch 134/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0156 - pos_accuracy: 0.9881 - val_loss: 0.0558 - val_pos_accuracy: 0.9330\n",
      "Epoch 135/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0200 - pos_accuracy: 0.9812 - val_loss: 0.0411 - val_pos_accuracy: 0.9509\n",
      "Epoch 136/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0122 - pos_accuracy: 0.9894 - val_loss: 0.0403 - val_pos_accuracy: 0.9531\n",
      "Epoch 137/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0109 - pos_accuracy: 0.9881 - val_loss: 0.0403 - val_pos_accuracy: 0.9531\n",
      "Epoch 138/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0115 - pos_accuracy: 0.9894 - val_loss: 0.0428 - val_pos_accuracy: 0.9554\n",
      "Epoch 139/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0111 - pos_accuracy: 0.9894 - val_loss: 0.0387 - val_pos_accuracy: 0.9531\n",
      "Epoch 140/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0102 - pos_accuracy: 0.9887 - val_loss: 0.0388 - val_pos_accuracy: 0.9554\n",
      "Epoch 141/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0101 - pos_accuracy: 0.9894 - val_loss: 0.0394 - val_pos_accuracy: 0.9531\n",
      "Epoch 142/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0110 - pos_accuracy: 0.9900 - val_loss: 0.0458 - val_pos_accuracy: 0.9576\n",
      "Epoch 143/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0099 - pos_accuracy: 0.9894 - val_loss: 0.0393 - val_pos_accuracy: 0.9531\n",
      "Epoch 144/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0102 - pos_accuracy: 0.9887 - val_loss: 0.0387 - val_pos_accuracy: 0.9554\n",
      "Epoch 145/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0118 - pos_accuracy: 0.9900 - val_loss: 0.0378 - val_pos_accuracy: 0.9576\n",
      "Epoch 146/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0090 - pos_accuracy: 0.9894 - val_loss: 0.0401 - val_pos_accuracy: 0.9598\n",
      "Epoch 147/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0283 - pos_accuracy: 0.9831 - val_loss: 0.0698 - val_pos_accuracy: 0.9330\n",
      "Epoch 148/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0417 - pos_accuracy: 0.9694 - val_loss: 0.0592 - val_pos_accuracy: 0.9375\n",
      "Epoch 149/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0456 - pos_accuracy: 0.9675 - val_loss: 0.0449 - val_pos_accuracy: 0.9576\n",
      "Epoch 150/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - pos_accuracy: 0.9894 - val_loss: 0.0414 - val_pos_accuracy: 0.9576\n",
      "Epoch 151/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0116 - pos_accuracy: 0.9900 - val_loss: 0.0372 - val_pos_accuracy: 0.9576\n",
      "Epoch 152/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0150 - pos_accuracy: 0.9894 - val_loss: 0.0422 - val_pos_accuracy: 0.9598\n",
      "Epoch 153/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0104 - pos_accuracy: 0.9900 - val_loss: 0.0400 - val_pos_accuracy: 0.9621\n",
      "Epoch 154/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - pos_accuracy: 0.9900 - val_loss: 0.0396 - val_pos_accuracy: 0.9598\n",
      "Epoch 155/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0099 - pos_accuracy: 0.9906 - val_loss: 0.0357 - val_pos_accuracy: 0.9621\n",
      "Epoch 156/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0089 - pos_accuracy: 0.9906 - val_loss: 0.0370 - val_pos_accuracy: 0.9621\n",
      "Epoch 157/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0125 - pos_accuracy: 0.9906 - val_loss: 0.0363 - val_pos_accuracy: 0.9598\n",
      "Epoch 158/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0089 - pos_accuracy: 0.9906 - val_loss: 0.0385 - val_pos_accuracy: 0.9598\n",
      "Epoch 159/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0108 - pos_accuracy: 0.9906 - val_loss: 0.0368 - val_pos_accuracy: 0.9621\n",
      "Epoch 160/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0084 - pos_accuracy: 0.9912 - val_loss: 0.0347 - val_pos_accuracy: 0.9621\n",
      "Epoch 161/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - pos_accuracy: 0.9912 - val_loss: 0.0415 - val_pos_accuracy: 0.9621\n",
      "Epoch 162/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0095 - pos_accuracy: 0.9906 - val_loss: 0.0346 - val_pos_accuracy: 0.9598\n",
      "Epoch 163/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0100 - pos_accuracy: 0.9906 - val_loss: 0.0350 - val_pos_accuracy: 0.9621\n",
      "Epoch 164/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0091 - pos_accuracy: 0.9906 - val_loss: 0.0394 - val_pos_accuracy: 0.9576\n",
      "Epoch 165/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0094 - pos_accuracy: 0.9912 - val_loss: 0.0353 - val_pos_accuracy: 0.9621\n",
      "Epoch 166/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0121 - pos_accuracy: 0.9906 - val_loss: 0.0412 - val_pos_accuracy: 0.9598\n",
      "Epoch 167/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0319 - pos_accuracy: 0.9794 - val_loss: 0.0573 - val_pos_accuracy: 0.9286\n",
      "Epoch 168/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0316 - pos_accuracy: 0.9725 - val_loss: 0.1243 - val_pos_accuracy: 0.6964\n",
      "Epoch 169/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0366 - pos_accuracy: 0.9675 - val_loss: 0.0666 - val_pos_accuracy: 0.9062\n",
      "Epoch 170/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0279 - pos_accuracy: 0.9850 - val_loss: 0.0547 - val_pos_accuracy: 0.9420\n",
      "Epoch 171/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0237 - pos_accuracy: 0.9894 - val_loss: 0.0432 - val_pos_accuracy: 0.9420\n",
      "Epoch 172/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0097 - pos_accuracy: 0.9912 - val_loss: 0.0346 - val_pos_accuracy: 0.9643\n",
      "Epoch 173/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0074 - pos_accuracy: 0.9912 - val_loss: 0.0335 - val_pos_accuracy: 0.9643\n",
      "Epoch 174/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0082 - pos_accuracy: 0.9912 - val_loss: 0.0326 - val_pos_accuracy: 0.9621\n",
      "Epoch 175/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0072 - pos_accuracy: 0.9912 - val_loss: 0.0333 - val_pos_accuracy: 0.9621\n",
      "Epoch 176/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0086 - pos_accuracy: 0.9912 - val_loss: 0.0346 - val_pos_accuracy: 0.9665\n",
      "Epoch 177/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0082 - pos_accuracy: 0.9919 - val_loss: 0.0350 - val_pos_accuracy: 0.9621\n",
      "Epoch 178/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0081 - pos_accuracy: 0.9912 - val_loss: 0.0343 - val_pos_accuracy: 0.9621\n",
      "Epoch 179/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0071 - pos_accuracy: 0.9912 - val_loss: 0.0330 - val_pos_accuracy: 0.9643\n",
      "Epoch 180/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0086 - pos_accuracy: 0.9919 - val_loss: 0.0338 - val_pos_accuracy: 0.9665\n",
      "Epoch 181/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0090 - pos_accuracy: 0.9925 - val_loss: 0.0327 - val_pos_accuracy: 0.9621\n",
      "Epoch 182/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0065 - pos_accuracy: 0.9912 - val_loss: 0.0324 - val_pos_accuracy: 0.9621\n",
      "Epoch 183/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0103 - pos_accuracy: 0.9912 - val_loss: 0.0356 - val_pos_accuracy: 0.9598\n",
      "Epoch 184/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0080 - pos_accuracy: 0.9931 - val_loss: 0.0386 - val_pos_accuracy: 0.9509\n",
      "Epoch 185/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - pos_accuracy: 0.9925 - val_loss: 0.0320 - val_pos_accuracy: 0.9621\n",
      "Epoch 186/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0066 - pos_accuracy: 0.9931 - val_loss: 0.0321 - val_pos_accuracy: 0.9621\n",
      "Epoch 187/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0073 - pos_accuracy: 0.9919 - val_loss: 0.0333 - val_pos_accuracy: 0.9643\n",
      "Epoch 188/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0084 - pos_accuracy: 0.9931 - val_loss: 0.0329 - val_pos_accuracy: 0.9621\n",
      "Epoch 189/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0067 - pos_accuracy: 0.9931 - val_loss: 0.0310 - val_pos_accuracy: 0.9621\n",
      "Epoch 190/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0059 - pos_accuracy: 0.9931 - val_loss: 0.0334 - val_pos_accuracy: 0.9665\n",
      "Epoch 191/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0069 - pos_accuracy: 0.9925 - val_loss: 0.0305 - val_pos_accuracy: 0.9643\n",
      "Epoch 192/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - pos_accuracy: 0.9931 - val_loss: 0.0326 - val_pos_accuracy: 0.9643\n",
      "Epoch 193/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - pos_accuracy: 0.9931 - val_loss: 0.0305 - val_pos_accuracy: 0.9665\n",
      "Epoch 194/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0070 - pos_accuracy: 0.9931 - val_loss: 0.0342 - val_pos_accuracy: 0.9621\n",
      "Epoch 195/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0060 - pos_accuracy: 0.9931 - val_loss: 0.0322 - val_pos_accuracy: 0.9598\n",
      "Epoch 196/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - pos_accuracy: 0.9931 - val_loss: 0.0342 - val_pos_accuracy: 0.9688\n",
      "Epoch 197/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0062 - pos_accuracy: 0.9937 - val_loss: 0.0298 - val_pos_accuracy: 0.9665\n",
      "Epoch 198/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0055 - pos_accuracy: 0.9931 - val_loss: 0.0296 - val_pos_accuracy: 0.9665\n",
      "Epoch 199/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0063 - pos_accuracy: 0.9931 - val_loss: 0.0362 - val_pos_accuracy: 0.9688\n",
      "Epoch 200/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - pos_accuracy: 0.9906 - val_loss: 0.0339 - val_pos_accuracy: 0.9710\n",
      "Epoch 201/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - pos_accuracy: 0.9881 - val_loss: 0.0347 - val_pos_accuracy: 0.9643\n",
      "Epoch 202/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0077 - pos_accuracy: 0.9937 - val_loss: 0.0303 - val_pos_accuracy: 0.9665\n",
      "Epoch 203/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0078 - pos_accuracy: 0.9937 - val_loss: 0.0309 - val_pos_accuracy: 0.9621\n",
      "Epoch 204/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0110 - pos_accuracy: 0.9944 - val_loss: 0.0297 - val_pos_accuracy: 0.9643\n",
      "Epoch 205/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - pos_accuracy: 0.9944 - val_loss: 0.0373 - val_pos_accuracy: 0.9643\n",
      "Epoch 206/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0084 - pos_accuracy: 0.9937 - val_loss: 0.0335 - val_pos_accuracy: 0.9576\n",
      "Epoch 207/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - pos_accuracy: 0.9937 - val_loss: 0.0415 - val_pos_accuracy: 0.9487\n",
      "Epoch 208/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0088 - pos_accuracy: 0.9944 - val_loss: 0.0294 - val_pos_accuracy: 0.9665\n",
      "Epoch 209/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0058 - pos_accuracy: 0.9956 - val_loss: 0.0300 - val_pos_accuracy: 0.9732\n",
      "Epoch 210/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0064 - pos_accuracy: 0.9937 - val_loss: 0.0304 - val_pos_accuracy: 0.9710\n",
      "Epoch 211/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0056 - pos_accuracy: 0.9950 - val_loss: 0.0288 - val_pos_accuracy: 0.9643\n",
      "Epoch 212/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0080 - pos_accuracy: 0.9950 - val_loss: 0.0349 - val_pos_accuracy: 0.9531\n",
      "Epoch 213/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0095 - pos_accuracy: 0.9950 - val_loss: 0.0305 - val_pos_accuracy: 0.9732\n",
      "Epoch 214/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - pos_accuracy: 0.9956 - val_loss: 0.0287 - val_pos_accuracy: 0.9754\n",
      "Epoch 215/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0101 - pos_accuracy: 0.9962 - val_loss: 0.0326 - val_pos_accuracy: 0.9688\n",
      "Epoch 216/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0099 - pos_accuracy: 0.9944 - val_loss: 0.0339 - val_pos_accuracy: 0.9576\n",
      "Epoch 217/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0108 - pos_accuracy: 0.9944 - val_loss: 0.0307 - val_pos_accuracy: 0.9665\n",
      "Epoch 218/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0077 - pos_accuracy: 0.9956 - val_loss: 0.0302 - val_pos_accuracy: 0.9688\n",
      "Epoch 219/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0049 - pos_accuracy: 0.9962 - val_loss: 0.0278 - val_pos_accuracy: 0.9732\n",
      "Epoch 220/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0142 - pos_accuracy: 0.9944 - val_loss: 0.0505 - val_pos_accuracy: 0.9531\n",
      "Epoch 221/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0271 - pos_accuracy: 0.9919 - val_loss: 0.0386 - val_pos_accuracy: 0.9554\n",
      "Epoch 222/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0345 - pos_accuracy: 0.9600 - val_loss: 0.0549 - val_pos_accuracy: 0.9420\n",
      "Epoch 223/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0153 - pos_accuracy: 0.9912 - val_loss: 0.0288 - val_pos_accuracy: 0.9710\n",
      "Epoch 224/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0062 - pos_accuracy: 0.9962 - val_loss: 0.0308 - val_pos_accuracy: 0.9710\n",
      "Epoch 225/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0057 - pos_accuracy: 0.9969 - val_loss: 0.0286 - val_pos_accuracy: 0.9710\n",
      "Epoch 226/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0056 - pos_accuracy: 0.9962 - val_loss: 0.0280 - val_pos_accuracy: 0.9710\n",
      "Epoch 227/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0060 - pos_accuracy: 0.9969 - val_loss: 0.0323 - val_pos_accuracy: 0.9598\n",
      "Epoch 228/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0066 - pos_accuracy: 0.9969 - val_loss: 0.0274 - val_pos_accuracy: 0.9732\n",
      "Epoch 229/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0044 - pos_accuracy: 0.9969 - val_loss: 0.0278 - val_pos_accuracy: 0.9732\n",
      "Epoch 230/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0056 - pos_accuracy: 0.9962 - val_loss: 0.0281 - val_pos_accuracy: 0.9754\n",
      "Epoch 231/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0060 - pos_accuracy: 0.9969 - val_loss: 0.0304 - val_pos_accuracy: 0.9732\n",
      "Epoch 232/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0143 - pos_accuracy: 0.9912 - val_loss: 0.0268 - val_pos_accuracy: 0.9732\n",
      "Epoch 233/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0047 - pos_accuracy: 0.9975 - val_loss: 0.0283 - val_pos_accuracy: 0.9710\n",
      "Epoch 234/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0052 - pos_accuracy: 0.9962 - val_loss: 0.0282 - val_pos_accuracy: 0.9710\n",
      "Epoch 235/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0114 - pos_accuracy: 0.9975 - val_loss: 0.0347 - val_pos_accuracy: 0.9710\n",
      "Epoch 236/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0150 - pos_accuracy: 0.9969 - val_loss: 0.0339 - val_pos_accuracy: 0.9710\n",
      "Epoch 237/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0062 - pos_accuracy: 0.9969 - val_loss: 0.0268 - val_pos_accuracy: 0.9732\n",
      "Epoch 238/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0043 - pos_accuracy: 0.9975 - val_loss: 0.0266 - val_pos_accuracy: 0.9732\n",
      "Epoch 239/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0049 - pos_accuracy: 0.9969 - val_loss: 0.0275 - val_pos_accuracy: 0.9710\n",
      "Epoch 240/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0058 - pos_accuracy: 0.9975 - val_loss: 0.0335 - val_pos_accuracy: 0.9688\n",
      "Epoch 241/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0053 - pos_accuracy: 0.9962 - val_loss: 0.0298 - val_pos_accuracy: 0.9732\n",
      "Epoch 242/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0102 - pos_accuracy: 0.9975 - val_loss: 0.0274 - val_pos_accuracy: 0.9710\n",
      "Epoch 243/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0042 - pos_accuracy: 0.9975 - val_loss: 0.0298 - val_pos_accuracy: 0.9688\n",
      "Epoch 244/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0064 - pos_accuracy: 0.9975 - val_loss: 0.0311 - val_pos_accuracy: 0.9576\n",
      "Epoch 245/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0142 - pos_accuracy: 0.9975 - val_loss: 0.0391 - val_pos_accuracy: 0.9665\n",
      "Epoch 246/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0330 - pos_accuracy: 0.9844 - val_loss: 0.0604 - val_pos_accuracy: 0.9308\n",
      "Epoch 247/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0161 - pos_accuracy: 0.9944 - val_loss: 0.0271 - val_pos_accuracy: 0.9732\n",
      "Epoch 248/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0042 - pos_accuracy: 0.9975 - val_loss: 0.0258 - val_pos_accuracy: 0.9732\n",
      "Epoch 249/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0041 - pos_accuracy: 0.9975 - val_loss: 0.0273 - val_pos_accuracy: 0.9732\n",
      "Epoch 250/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0047 - pos_accuracy: 0.9975 - val_loss: 0.0261 - val_pos_accuracy: 0.9777\n",
      "Epoch 251/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0054 - pos_accuracy: 0.9975 - val_loss: 0.0291 - val_pos_accuracy: 0.9710\n",
      "Epoch 252/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0066 - pos_accuracy: 0.9975 - val_loss: 0.0270 - val_pos_accuracy: 0.9732\n",
      "Epoch 253/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0065 - pos_accuracy: 0.9975 - val_loss: 0.0312 - val_pos_accuracy: 0.9688\n",
      "Epoch 254/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0144 - pos_accuracy: 0.9912 - val_loss: 0.0273 - val_pos_accuracy: 0.9710\n",
      "Epoch 255/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0049 - pos_accuracy: 0.9969 - val_loss: 0.0257 - val_pos_accuracy: 0.9754\n",
      "Epoch 256/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - pos_accuracy: 0.9975 - val_loss: 0.0270 - val_pos_accuracy: 0.9710\n",
      "Epoch 257/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0038 - pos_accuracy: 0.9975 - val_loss: 0.0257 - val_pos_accuracy: 0.9732\n",
      "Epoch 258/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0037 - pos_accuracy: 0.9975 - val_loss: 0.0272 - val_pos_accuracy: 0.9710\n",
      "Epoch 259/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0035 - pos_accuracy: 0.9975 - val_loss: 0.0266 - val_pos_accuracy: 0.9598\n",
      "Epoch 260/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0035 - pos_accuracy: 0.9975 - val_loss: 0.0251 - val_pos_accuracy: 0.9710\n",
      "Epoch 261/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - pos_accuracy: 0.9975 - val_loss: 0.0280 - val_pos_accuracy: 0.9621\n",
      "Epoch 262/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0047 - pos_accuracy: 0.9975 - val_loss: 0.0261 - val_pos_accuracy: 0.9710\n",
      "Epoch 263/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0039 - pos_accuracy: 0.9975 - val_loss: 0.0262 - val_pos_accuracy: 0.9554\n",
      "Epoch 264/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0041 - pos_accuracy: 0.9975 - val_loss: 0.0253 - val_pos_accuracy: 0.9754\n",
      "Epoch 265/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0034 - pos_accuracy: 0.9975 - val_loss: 0.0254 - val_pos_accuracy: 0.9732\n",
      "Epoch 266/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0041 - pos_accuracy: 0.9975 - val_loss: 0.0255 - val_pos_accuracy: 0.9710\n",
      "Epoch 267/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - pos_accuracy: 0.9975 - val_loss: 0.0301 - val_pos_accuracy: 0.9710\n",
      "Epoch 268/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0101 - pos_accuracy: 0.9975 - val_loss: 0.0363 - val_pos_accuracy: 0.9688\n",
      "Epoch 269/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - pos_accuracy: 0.9975 - val_loss: 0.0317 - val_pos_accuracy: 0.9754\n",
      "Epoch 270/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0103 - pos_accuracy: 0.9975 - val_loss: 0.0283 - val_pos_accuracy: 0.9621\n",
      "Epoch 271/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0060 - pos_accuracy: 0.9981 - val_loss: 0.0258 - val_pos_accuracy: 0.9732\n",
      "Epoch 272/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - pos_accuracy: 0.9975 - val_loss: 0.0301 - val_pos_accuracy: 0.9732\n",
      "Epoch 273/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0048 - pos_accuracy: 0.9975 - val_loss: 0.0241 - val_pos_accuracy: 0.9754\n",
      "Epoch 274/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0043 - pos_accuracy: 0.9975 - val_loss: 0.0343 - val_pos_accuracy: 0.9665\n",
      "Epoch 275/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0145 - pos_accuracy: 0.9969 - val_loss: 0.0338 - val_pos_accuracy: 0.9621\n",
      "Epoch 276/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0094 - pos_accuracy: 0.9975 - val_loss: 0.0265 - val_pos_accuracy: 0.9754\n",
      "Epoch 277/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0033 - pos_accuracy: 0.9975 - val_loss: 0.0243 - val_pos_accuracy: 0.9732\n",
      "Epoch 278/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0035 - pos_accuracy: 0.9975 - val_loss: 0.0244 - val_pos_accuracy: 0.9732\n",
      "Epoch 279/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0029 - pos_accuracy: 0.9975 - val_loss: 0.0248 - val_pos_accuracy: 0.9777\n",
      "Epoch 280/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0029 - pos_accuracy: 0.9975 - val_loss: 0.0271 - val_pos_accuracy: 0.9754\n",
      "Epoch 281/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0064 - pos_accuracy: 0.9975 - val_loss: 0.0310 - val_pos_accuracy: 0.9643\n",
      "Epoch 282/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - pos_accuracy: 0.9956 - val_loss: 0.0310 - val_pos_accuracy: 0.9754\n",
      "Epoch 283/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0080 - pos_accuracy: 0.9975 - val_loss: 0.0299 - val_pos_accuracy: 0.9777\n",
      "Epoch 284/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0049 - pos_accuracy: 0.9981 - val_loss: 0.0256 - val_pos_accuracy: 0.9777\n",
      "Epoch 285/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0097 - pos_accuracy: 0.9981 - val_loss: 0.0285 - val_pos_accuracy: 0.9643\n",
      "Epoch 286/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0047 - pos_accuracy: 0.9975 - val_loss: 0.0240 - val_pos_accuracy: 0.9777\n",
      "Epoch 287/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0032 - pos_accuracy: 0.9987 - val_loss: 0.0255 - val_pos_accuracy: 0.9821\n",
      "Epoch 288/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0042 - pos_accuracy: 0.9981 - val_loss: 0.0263 - val_pos_accuracy: 0.9777\n",
      "Epoch 289/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0068 - pos_accuracy: 0.9975 - val_loss: 0.0270 - val_pos_accuracy: 0.9621\n",
      "Epoch 290/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0194 - pos_accuracy: 0.9944 - val_loss: 0.0556 - val_pos_accuracy: 0.9487\n",
      "Epoch 291/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0577 - pos_accuracy: 0.8888 - val_loss: 0.0341 - val_pos_accuracy: 0.9643\n",
      "Epoch 292/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - pos_accuracy: 0.9981 - val_loss: 0.0281 - val_pos_accuracy: 0.9754\n",
      "Epoch 293/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0101 - pos_accuracy: 0.9981 - val_loss: 0.0323 - val_pos_accuracy: 0.9643\n",
      "Epoch 294/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0133 - pos_accuracy: 0.9987 - val_loss: 0.0295 - val_pos_accuracy: 0.9777\n",
      "Epoch 295/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0142 - pos_accuracy: 0.9981 - val_loss: 0.0316 - val_pos_accuracy: 0.9643\n",
      "Epoch 296/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0136 - pos_accuracy: 0.9981 - val_loss: 0.0362 - val_pos_accuracy: 0.9688\n",
      "Epoch 297/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - pos_accuracy: 0.9981 - val_loss: 0.0336 - val_pos_accuracy: 0.9643\n",
      "Epoch 298/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0136 - pos_accuracy: 0.9981 - val_loss: 0.0286 - val_pos_accuracy: 0.9777\n",
      "Epoch 299/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0044 - pos_accuracy: 0.9987 - val_loss: 0.0258 - val_pos_accuracy: 0.9777\n",
      "Epoch 300/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0061 - pos_accuracy: 0.9981 - val_loss: 0.0247 - val_pos_accuracy: 0.9777\n",
      "Epoch 301/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0028 - pos_accuracy: 0.9994 - val_loss: 0.0264 - val_pos_accuracy: 0.9754\n",
      "Epoch 302/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0034 - pos_accuracy: 0.9975 - val_loss: 0.0231 - val_pos_accuracy: 0.9799\n",
      "Epoch 303/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0025 - pos_accuracy: 0.9987 - val_loss: 0.0250 - val_pos_accuracy: 0.9665\n",
      "Epoch 304/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0032 - pos_accuracy: 0.9987 - val_loss: 0.0231 - val_pos_accuracy: 0.9777\n",
      "Epoch 305/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0028 - pos_accuracy: 0.9987 - val_loss: 0.0236 - val_pos_accuracy: 0.9821\n",
      "Epoch 306/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0024 - pos_accuracy: 0.9987 - val_loss: 0.0229 - val_pos_accuracy: 0.9777\n",
      "Epoch 307/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - pos_accuracy: 0.9987 - val_loss: 0.0242 - val_pos_accuracy: 0.9799\n",
      "Epoch 308/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0043 - pos_accuracy: 0.9994 - val_loss: 0.0233 - val_pos_accuracy: 0.9821\n",
      "Epoch 309/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0047 - pos_accuracy: 0.9987 - val_loss: 0.0232 - val_pos_accuracy: 0.9777\n",
      "Epoch 310/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - pos_accuracy: 0.9994 - val_loss: 0.0226 - val_pos_accuracy: 0.9799\n",
      "Epoch 311/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - pos_accuracy: 0.9987 - val_loss: 0.0249 - val_pos_accuracy: 0.9799\n",
      "Epoch 312/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0054 - pos_accuracy: 0.9981 - val_loss: 0.0264 - val_pos_accuracy: 0.9621\n",
      "Epoch 313/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0054 - pos_accuracy: 0.9994 - val_loss: 0.0240 - val_pos_accuracy: 0.9821\n",
      "Epoch 314/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0025 - pos_accuracy: 0.9994 - val_loss: 0.0225 - val_pos_accuracy: 0.9821\n",
      "Epoch 315/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - pos_accuracy: 0.9994 - val_loss: 0.0233 - val_pos_accuracy: 0.9799\n",
      "Epoch 316/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0028 - pos_accuracy: 0.9994 - val_loss: 0.0243 - val_pos_accuracy: 0.9799\n",
      "Epoch 317/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - pos_accuracy: 0.9994 - val_loss: 0.0225 - val_pos_accuracy: 0.9821\n",
      "Epoch 318/320\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0024 - pos_accuracy: 0.9994 - val_loss: 0.0236 - val_pos_accuracy: 0.9821\n",
      "Epoch 319/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0029 - pos_accuracy: 0.9994 - val_loss: 0.0228 - val_pos_accuracy: 0.9821\n",
      "Epoch 320/320\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - pos_accuracy: 0.9994 - val_loss: 0.0221 - val_pos_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae8c6ac340>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 재현 가능한 난수 생성\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "def load_data():\n",
    "    n = 2000\n",
    "    split = 0.8\n",
    "    n_train = (int)(split*n)     # = 1,600\n",
    "    \n",
    "    y = np.random.randint(28, size=(n,2))   # [0, 27] x 2000개\n",
    "    x = np.empty((n,28,28))      \n",
    "    \n",
    "    for i in tqdm(range(n)):     # tqdm = 'progress' for iterables   \n",
    "        img = np.zeros((28,28))\n",
    "        cv2.circle(img, (y[i][0],y[i][1]), 3, 255, -1)    # circle(img, center, radius, color, thickness(-1은 원 안쪽을 채움))\n",
    "        x[i] = img\n",
    "    return ((x[:n_train], y[:n_train]), (x[n_train:], y[n_train:]))\n",
    "\n",
    "def label(y):\n",
    "    return np.around(y).astype('int')\n",
    "        \n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# normalize image\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(str(label(y_test[i])))\n",
    "plt.show()\n",
    "\n",
    "def pos_accuracy(y_true, y_pred):\n",
    "    label_true = tf.round(y_true)\n",
    "    label_pred = tf.round(y_pred)\n",
    "    is_correct = tf.reduce_all(label_true == label_pred, axis=1)\n",
    "    is_correct = tf.cast(is_correct, 'float32')\n",
    "    score = tf.reduce_mean(is_correct)\n",
    "    return score\n",
    "\n",
    "input_layer = Input((28, 28))\n",
    "x = Flatten()(input_layer)\n",
    "x = Dense(24, activation='sigmoid')(x)           # 여기에 Dense Layer를 복수개 구성합니다.\n",
    "x = Dense(20, activation='sigmoid')(x)           # 여기에 Dense Layer를 복수개 구성합니다.\n",
    "output_layer = Dense(2, activation = None)(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.1), loss='mse', metrics=[pos_accuracy])\n",
    "# custom metric을 추가하고 batch_size와 epochs를 변경하면서 실험해 봅시다.\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size = 64, epochs=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f760bb4",
   "metadata": {},
   "source": [
    "# CNN sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d02e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 92842.61it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 22:49:37.748984: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 7ms/step - loss: 157.1363 - pos_accuracy: 0.0012 - val_loss: 54.4519 - val_pos_accuracy: 0.0000e+00\n",
      "---current best score: 0.000\n",
      "\n",
      "Epoch 00001: val_pos_accuracy improved from -inf to 0.00000, saving model to best_model.h5\n",
      "Epoch 2/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 24.9767 - pos_accuracy: 0.0262 - val_loss: 9.1194 - val_pos_accuracy: 0.1418\n",
      "---current best score: 0.142\n",
      "\n",
      "Epoch 00002: val_pos_accuracy improved from 0.00000 to 0.14183, saving model to best_model.h5\n",
      "Epoch 3/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 5.7275 - pos_accuracy: 0.1256 - val_loss: 5.2152 - val_pos_accuracy: 0.1875\n",
      "---current best score: 0.188\n",
      "\n",
      "Epoch 00003: val_pos_accuracy improved from 0.14183 to 0.18750, saving model to best_model.h5\n",
      "Epoch 4/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.5906 - pos_accuracy: 0.1769 - val_loss: 3.6967 - val_pos_accuracy: 0.2764\n",
      "---current best score: 0.276\n",
      "\n",
      "Epoch 00004: val_pos_accuracy improved from 0.18750 to 0.27644, saving model to best_model.h5\n",
      "Epoch 5/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 2.5809 - pos_accuracy: 0.2344 - val_loss: 2.7667 - val_pos_accuracy: 0.2668\n",
      "\n",
      "Epoch 00005: val_pos_accuracy did not improve from 0.27644\n",
      "Epoch 6/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.9826 - pos_accuracy: 0.2600 - val_loss: 2.2166 - val_pos_accuracy: 0.2788\n",
      "---current best score: 0.279\n",
      "\n",
      "Epoch 00006: val_pos_accuracy improved from 0.27644 to 0.27885, saving model to best_model.h5\n",
      "Epoch 7/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.5234 - pos_accuracy: 0.2656 - val_loss: 1.7787 - val_pos_accuracy: 0.2548\n",
      "\n",
      "Epoch 00007: val_pos_accuracy did not improve from 0.27885\n",
      "Epoch 8/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1834 - pos_accuracy: 0.2900 - val_loss: 1.5178 - val_pos_accuracy: 0.2861\n",
      "---current best score: 0.286\n",
      "\n",
      "Epoch 00008: val_pos_accuracy improved from 0.27885 to 0.28606, saving model to best_model.h5\n",
      "Epoch 9/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.9649 - pos_accuracy: 0.3006 - val_loss: 1.1447 - val_pos_accuracy: 0.2812\n",
      "\n",
      "Epoch 00009: val_pos_accuracy did not improve from 0.28606\n",
      "Epoch 10/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7463 - pos_accuracy: 0.3419 - val_loss: 0.9459 - val_pos_accuracy: 0.2909\n",
      "---current best score: 0.291\n",
      "\n",
      "Epoch 00010: val_pos_accuracy improved from 0.28606 to 0.29087, saving model to best_model.h5\n",
      "Epoch 11/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5951 - pos_accuracy: 0.3725 - val_loss: 0.7272 - val_pos_accuracy: 0.3486\n",
      "---current best score: 0.349\n",
      "\n",
      "Epoch 00011: val_pos_accuracy improved from 0.29087 to 0.34856, saving model to best_model.h5\n",
      "Epoch 12/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.4797 - pos_accuracy: 0.4275 - val_loss: 0.6663 - val_pos_accuracy: 0.4255\n",
      "---current best score: 0.425\n",
      "\n",
      "Epoch 00012: val_pos_accuracy improved from 0.34856 to 0.42548, saving model to best_model.h5\n",
      "Epoch 13/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4107 - pos_accuracy: 0.4688 - val_loss: 0.5101 - val_pos_accuracy: 0.4399\n",
      "---current best score: 0.440\n",
      "\n",
      "Epoch 00013: val_pos_accuracy improved from 0.42548 to 0.43990, saving model to best_model.h5\n",
      "Epoch 14/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3352 - pos_accuracy: 0.5281 - val_loss: 0.4835 - val_pos_accuracy: 0.4423\n",
      "---current best score: 0.442\n",
      "\n",
      "Epoch 00014: val_pos_accuracy improved from 0.43990 to 0.44231, saving model to best_model.h5\n",
      "Epoch 15/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3058 - pos_accuracy: 0.5631 - val_loss: 0.4013 - val_pos_accuracy: 0.5529\n",
      "---current best score: 0.553\n",
      "\n",
      "Epoch 00015: val_pos_accuracy improved from 0.44231 to 0.55288, saving model to best_model.h5\n",
      "Epoch 16/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2654 - pos_accuracy: 0.6175 - val_loss: 0.3285 - val_pos_accuracy: 0.6298\n",
      "---current best score: 0.630\n",
      "\n",
      "Epoch 00016: val_pos_accuracy improved from 0.55288 to 0.62981, saving model to best_model.h5\n",
      "Epoch 17/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2199 - pos_accuracy: 0.6719 - val_loss: 0.3142 - val_pos_accuracy: 0.6490\n",
      "---current best score: 0.649\n",
      "\n",
      "Epoch 00017: val_pos_accuracy improved from 0.62981 to 0.64904, saving model to best_model.h5\n",
      "Epoch 18/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2023 - pos_accuracy: 0.6869 - val_loss: 0.2932 - val_pos_accuracy: 0.6659\n",
      "---current best score: 0.666\n",
      "\n",
      "Epoch 00018: val_pos_accuracy improved from 0.64904 to 0.66587, saving model to best_model.h5\n",
      "Epoch 19/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1762 - pos_accuracy: 0.7406 - val_loss: 0.2610 - val_pos_accuracy: 0.7139\n",
      "---current best score: 0.714\n",
      "\n",
      "Epoch 00019: val_pos_accuracy improved from 0.66587 to 0.71394, saving model to best_model.h5\n",
      "Epoch 20/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1599 - pos_accuracy: 0.7744 - val_loss: 0.2092 - val_pos_accuracy: 0.7692\n",
      "---current best score: 0.769\n",
      "\n",
      "Epoch 00020: val_pos_accuracy improved from 0.71394 to 0.76923, saving model to best_model.h5\n",
      "Epoch 21/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1445 - pos_accuracy: 0.7819 - val_loss: 0.2309 - val_pos_accuracy: 0.7163\n",
      "\n",
      "Epoch 00021: val_pos_accuracy did not improve from 0.76923\n",
      "Epoch 22/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1429 - pos_accuracy: 0.7925 - val_loss: 0.1889 - val_pos_accuracy: 0.7957\n",
      "---current best score: 0.796\n",
      "\n",
      "Epoch 00022: val_pos_accuracy improved from 0.76923 to 0.79567, saving model to best_model.h5\n",
      "Epoch 23/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1183 - pos_accuracy: 0.8306 - val_loss: 0.1716 - val_pos_accuracy: 0.8269\n",
      "---current best score: 0.827\n",
      "\n",
      "Epoch 00023: val_pos_accuracy improved from 0.79567 to 0.82692, saving model to best_model.h5\n",
      "Epoch 24/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1070 - pos_accuracy: 0.8625 - val_loss: 0.1513 - val_pos_accuracy: 0.8630\n",
      "---current best score: 0.863\n",
      "\n",
      "Epoch 00024: val_pos_accuracy improved from 0.82692 to 0.86298, saving model to best_model.h5\n",
      "Epoch 25/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0961 - pos_accuracy: 0.8869 - val_loss: 0.1424 - val_pos_accuracy: 0.8774\n",
      "---current best score: 0.877\n",
      "\n",
      "Epoch 00025: val_pos_accuracy improved from 0.86298 to 0.87740, saving model to best_model.h5\n",
      "Epoch 26/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0845 - pos_accuracy: 0.9106 - val_loss: 0.1385 - val_pos_accuracy: 0.8870\n",
      "---current best score: 0.887\n",
      "\n",
      "Epoch 00026: val_pos_accuracy improved from 0.87740 to 0.88702, saving model to best_model.h5\n",
      "Epoch 27/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0785 - pos_accuracy: 0.9256 - val_loss: 0.1236 - val_pos_accuracy: 0.9111\n",
      "---current best score: 0.911\n",
      "\n",
      "Epoch 00027: val_pos_accuracy improved from 0.88702 to 0.91106, saving model to best_model.h5\n",
      "Epoch 28/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0682 - pos_accuracy: 0.9419 - val_loss: 0.1057 - val_pos_accuracy: 0.9062\n",
      "\n",
      "Epoch 00028: val_pos_accuracy did not improve from 0.91106\n",
      "Epoch 29/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0654 - pos_accuracy: 0.9350 - val_loss: 0.1094 - val_pos_accuracy: 0.9183\n",
      "---current best score: 0.918\n",
      "\n",
      "Epoch 00029: val_pos_accuracy improved from 0.91106 to 0.91827, saving model to best_model.h5\n",
      "Epoch 30/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0590 - pos_accuracy: 0.9606 - val_loss: 0.0915 - val_pos_accuracy: 0.9231\n",
      "---current best score: 0.923\n",
      "\n",
      "Epoch 00030: val_pos_accuracy improved from 0.91827 to 0.92308, saving model to best_model.h5\n",
      "Epoch 31/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0613 - pos_accuracy: 0.9488 - val_loss: 0.0857 - val_pos_accuracy: 0.9543\n",
      "---current best score: 0.954\n",
      "\n",
      "Epoch 00031: val_pos_accuracy improved from 0.92308 to 0.95433, saving model to best_model.h5\n",
      "Epoch 32/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0527 - pos_accuracy: 0.9650 - val_loss: 0.0837 - val_pos_accuracy: 0.9471\n",
      "\n",
      "Epoch 00032: val_pos_accuracy did not improve from 0.95433\n",
      "Epoch 33/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0471 - pos_accuracy: 0.9681 - val_loss: 0.0810 - val_pos_accuracy: 0.9543\n",
      "\n",
      "Epoch 00033: val_pos_accuracy did not improve from 0.95433\n",
      "Epoch 34/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0468 - pos_accuracy: 0.9700 - val_loss: 0.0737 - val_pos_accuracy: 0.9567\n",
      "---current best score: 0.957\n",
      "\n",
      "Epoch 00034: val_pos_accuracy improved from 0.95433 to 0.95673, saving model to best_model.h5\n",
      "Epoch 35/400\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0400 - pos_accuracy: 0.9756 - val_loss: 0.0686 - val_pos_accuracy: 0.9736\n",
      "---current best score: 0.974\n",
      "\n",
      "Epoch 00035: val_pos_accuracy improved from 0.95673 to 0.97356, saving model to best_model.h5\n",
      "Epoch 36/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0446 - pos_accuracy: 0.9712 - val_loss: 0.0657 - val_pos_accuracy: 0.9639\n",
      "\n",
      "Epoch 00036: val_pos_accuracy did not improve from 0.97356\n",
      "Epoch 37/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0377 - pos_accuracy: 0.9731 - val_loss: 0.0651 - val_pos_accuracy: 0.9688\n",
      "\n",
      "Epoch 00037: val_pos_accuracy did not improve from 0.97356\n",
      "Epoch 38/400\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0352 - pos_accuracy: 0.9737 - val_loss: 0.0616 - val_pos_accuracy: 0.9808\n",
      "---current best score: 0.981\n",
      "\n",
      "Epoch 00038: val_pos_accuracy improved from 0.97356 to 0.98077, saving model to best_model.h5\n",
      "Epoch 39/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0354 - pos_accuracy: 0.9806 - val_loss: 0.0592 - val_pos_accuracy: 0.9736\n",
      "\n",
      "Epoch 00039: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 40/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0368 - pos_accuracy: 0.9806 - val_loss: 0.0627 - val_pos_accuracy: 0.9688\n",
      "\n",
      "Epoch 00040: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 41/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0329 - pos_accuracy: 0.9825 - val_loss: 0.0575 - val_pos_accuracy: 0.9808\n",
      "\n",
      "Epoch 00041: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 42/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0307 - pos_accuracy: 0.9825 - val_loss: 0.0536 - val_pos_accuracy: 0.9808\n",
      "\n",
      "Epoch 00042: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 43/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0281 - pos_accuracy: 0.9825 - val_loss: 0.0536 - val_pos_accuracy: 0.9736\n",
      "\n",
      "Epoch 00043: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 44/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0241 - pos_accuracy: 0.9862 - val_loss: 0.0499 - val_pos_accuracy: 0.9760\n",
      "\n",
      "Epoch 00044: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 45/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0244 - pos_accuracy: 0.9825 - val_loss: 0.0479 - val_pos_accuracy: 0.9808\n",
      "\n",
      "Epoch 00045: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 46/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0223 - pos_accuracy: 0.9869 - val_loss: 0.0468 - val_pos_accuracy: 0.9760\n",
      "\n",
      "Epoch 00046: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 47/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0229 - pos_accuracy: 0.9869 - val_loss: 0.0484 - val_pos_accuracy: 0.9760\n",
      "\n",
      "Epoch 00047: val_pos_accuracy did not improve from 0.98077\n",
      "Epoch 48/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0225 - pos_accuracy: 0.9850 - val_loss: 0.0474 - val_pos_accuracy: 0.9856\n",
      "---current best score: 0.986\n",
      "\n",
      "Epoch 00048: val_pos_accuracy improved from 0.98077 to 0.98558, saving model to best_model.h5\n",
      "Epoch 49/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0235 - pos_accuracy: 0.9881 - val_loss: 0.0474 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00049: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 50/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0201 - pos_accuracy: 0.9869 - val_loss: 0.0408 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00050: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 51/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0189 - pos_accuracy: 0.9894 - val_loss: 0.0432 - val_pos_accuracy: 0.9784\n",
      "\n",
      "Epoch 00051: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 52/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0172 - pos_accuracy: 0.9887 - val_loss: 0.0401 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00052: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 53/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0187 - pos_accuracy: 0.9894 - val_loss: 0.0383 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00053: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 54/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0201 - pos_accuracy: 0.9887 - val_loss: 0.0432 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00054: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 55/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0180 - pos_accuracy: 0.9887 - val_loss: 0.0349 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00055: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 56/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0140 - pos_accuracy: 0.9906 - val_loss: 0.0341 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00056: val_pos_accuracy did not improve from 0.98558\n",
      "Epoch 57/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0208 - pos_accuracy: 0.9869 - val_loss: 0.0500 - val_pos_accuracy: 0.9880\n",
      "---current best score: 0.988\n",
      "\n",
      "Epoch 00057: val_pos_accuracy improved from 0.98558 to 0.98798, saving model to best_model.h5\n",
      "Epoch 58/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0211 - pos_accuracy: 0.9881 - val_loss: 0.0551 - val_pos_accuracy: 0.9808\n",
      "\n",
      "Epoch 00058: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 59/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0226 - pos_accuracy: 0.9912 - val_loss: 0.0378 - val_pos_accuracy: 0.9832\n",
      "\n",
      "Epoch 00059: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 60/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0169 - pos_accuracy: 0.9906 - val_loss: 0.0341 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00060: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 61/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0146 - pos_accuracy: 0.9912 - val_loss: 0.0328 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00061: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 62/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0143 - pos_accuracy: 0.9887 - val_loss: 0.0352 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00062: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 63/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0132 - pos_accuracy: 0.9900 - val_loss: 0.0319 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00063: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 64/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0147 - pos_accuracy: 0.9925 - val_loss: 0.0294 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00064: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 65/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0133 - pos_accuracy: 0.9919 - val_loss: 0.0375 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00065: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 66/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0152 - pos_accuracy: 0.9931 - val_loss: 0.0272 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00066: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 67/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0116 - pos_accuracy: 0.9956 - val_loss: 0.0301 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00067: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 68/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0129 - pos_accuracy: 0.9925 - val_loss: 0.0307 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00068: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 69/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0132 - pos_accuracy: 0.9925 - val_loss: 0.0319 - val_pos_accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 70/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0130 - pos_accuracy: 0.9950 - val_loss: 0.0350 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00070: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 71/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0106 - pos_accuracy: 0.9950 - val_loss: 0.0286 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00071: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 72/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0101 - pos_accuracy: 0.9937 - val_loss: 0.0258 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00072: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 73/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0122 - pos_accuracy: 0.9925 - val_loss: 0.0366 - val_pos_accuracy: 0.9856\n",
      "\n",
      "Epoch 00073: val_pos_accuracy did not improve from 0.98798\n",
      "Epoch 74/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0124 - pos_accuracy: 0.9931 - val_loss: 0.0258 - val_pos_accuracy: 0.9928\n",
      "---current best score: 0.993\n",
      "\n",
      "Epoch 00074: val_pos_accuracy improved from 0.98798 to 0.99279, saving model to best_model.h5\n",
      "Epoch 75/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0113 - pos_accuracy: 0.9956 - val_loss: 0.0268 - val_pos_accuracy: 0.9904\n",
      "\n",
      "Epoch 00075: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 76/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0121 - pos_accuracy: 0.9950 - val_loss: 0.0280 - val_pos_accuracy: 0.9904\n",
      "\n",
      "Epoch 00076: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 77/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0102 - pos_accuracy: 0.9937 - val_loss: 0.0255 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00077: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 78/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0106 - pos_accuracy: 0.9950 - val_loss: 0.0330 - val_pos_accuracy: 0.9904\n",
      "\n",
      "Epoch 00078: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 79/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0135 - pos_accuracy: 0.9975 - val_loss: 0.0323 - val_pos_accuracy: 0.9904\n",
      "\n",
      "Epoch 00079: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 80/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0112 - pos_accuracy: 0.9962 - val_loss: 0.0258 - val_pos_accuracy: 0.9880\n",
      "\n",
      "Epoch 00080: val_pos_accuracy did not improve from 0.99279\n",
      "Epoch 81/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0090 - pos_accuracy: 0.9969 - val_loss: 0.0209 - val_pos_accuracy: 0.9952\n",
      "---current best score: 0.995\n",
      "\n",
      "Epoch 00081: val_pos_accuracy improved from 0.99279 to 0.99519, saving model to best_model.h5\n",
      "Epoch 82/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0078 - pos_accuracy: 0.9962 - val_loss: 0.0205 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00082: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 83/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0132 - pos_accuracy: 0.9969 - val_loss: 0.0367 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00083: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 84/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0194 - pos_accuracy: 0.9956 - val_loss: 0.0294 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00084: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 85/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0131 - pos_accuracy: 0.9969 - val_loss: 0.0238 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00085: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 86/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0136 - pos_accuracy: 0.9975 - val_loss: 0.0266 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00086: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 87/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0144 - pos_accuracy: 0.9981 - val_loss: 0.0339 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00087: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 88/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0275 - pos_accuracy: 0.9919 - val_loss: 0.0354 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00088: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 89/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0164 - pos_accuracy: 0.9956 - val_loss: 0.0212 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00089: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 90/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0090 - pos_accuracy: 0.9987 - val_loss: 0.0221 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00090: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 91/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0138 - pos_accuracy: 0.9975 - val_loss: 0.0256 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00091: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 92/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0101 - pos_accuracy: 0.9981 - val_loss: 0.0191 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00092: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 93/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0092 - pos_accuracy: 0.9975 - val_loss: 0.0230 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00093: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 94/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0151 - pos_accuracy: 0.9962 - val_loss: 0.0214 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00094: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 95/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0103 - pos_accuracy: 0.9987 - val_loss: 0.0246 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00095: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 96/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0153 - pos_accuracy: 0.9975 - val_loss: 0.0218 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00096: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 97/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0130 - pos_accuracy: 0.9975 - val_loss: 0.0238 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00097: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 98/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0094 - pos_accuracy: 1.0000 - val_loss: 0.0164 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00098: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 99/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0077 - pos_accuracy: 0.9987 - val_loss: 0.0202 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00099: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 100/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0156 - pos_accuracy: 0.9969 - val_loss: 0.0318 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00100: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 101/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0136 - pos_accuracy: 0.9987 - val_loss: 0.0196 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00101: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 102/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0122 - pos_accuracy: 0.9994 - val_loss: 0.0215 - val_pos_accuracy: 0.9928\n",
      "---lr decreasing: 5.000000e-04\n",
      "\n",
      "Epoch 00102: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 103/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - pos_accuracy: 0.9994 - val_loss: 0.0137 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00103: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 104/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0030 - pos_accuracy: 1.0000 - val_loss: 0.0153 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00104: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 105/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0031 - pos_accuracy: 0.9994 - val_loss: 0.0147 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00105: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 106/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0033 - pos_accuracy: 1.0000 - val_loss: 0.0150 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00106: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 107/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - pos_accuracy: 1.0000 - val_loss: 0.0138 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00107: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 108/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - pos_accuracy: 1.0000 - val_loss: 0.0133 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00108: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 109/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0027 - pos_accuracy: 1.0000 - val_loss: 0.0152 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00109: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 110/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0034 - pos_accuracy: 1.0000 - val_loss: 0.0127 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00110: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 111/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0030 - pos_accuracy: 1.0000 - val_loss: 0.0124 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00111: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 112/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - pos_accuracy: 1.0000 - val_loss: 0.0124 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00112: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 113/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - pos_accuracy: 1.0000 - val_loss: 0.0137 - val_pos_accuracy: 0.9928\n",
      "\n",
      "Epoch 00113: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 114/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - pos_accuracy: 1.0000 - val_loss: 0.0132 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00114: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 115/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0030 - pos_accuracy: 1.0000 - val_loss: 0.0132 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00115: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 116/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - pos_accuracy: 1.0000 - val_loss: 0.0139 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00116: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 117/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0031 - pos_accuracy: 1.0000 - val_loss: 0.0123 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00117: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 118/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - pos_accuracy: 1.0000 - val_loss: 0.0123 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00118: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 119/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - pos_accuracy: 1.0000 - val_loss: 0.0134 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00119: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 120/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0034 - pos_accuracy: 1.0000 - val_loss: 0.0146 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00120: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 121/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0032 - pos_accuracy: 1.0000 - val_loss: 0.0122 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00121: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 122/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - pos_accuracy: 1.0000 - val_loss: 0.0132 - val_pos_accuracy: 0.9952\n",
      "---lr decreasing: 2.500000e-04\n",
      "\n",
      "Epoch 00122: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 123/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - pos_accuracy: 1.0000 - val_loss: 0.0111 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00123: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 124/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - pos_accuracy: 1.0000 - val_loss: 0.0111 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00124: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 125/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0109 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00125: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 126/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0018 - pos_accuracy: 1.0000 - val_loss: 0.0110 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00126: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 127/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0108 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00127: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 128/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - pos_accuracy: 1.0000 - val_loss: 0.0111 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00128: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 129/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0019 - pos_accuracy: 1.0000 - val_loss: 0.0107 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00129: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 130/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - pos_accuracy: 1.0000 - val_loss: 0.0107 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00130: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 131/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0106 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00131: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 132/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0014 - pos_accuracy: 1.0000 - val_loss: 0.0107 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00132: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 133/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - pos_accuracy: 1.0000 - val_loss: 0.0105 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00133: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 134/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - pos_accuracy: 1.0000 - val_loss: 0.0105 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00134: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 135/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0106 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00135: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 136/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0104 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00136: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 137/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - pos_accuracy: 1.0000 - val_loss: 0.0105 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00137: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 138/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - pos_accuracy: 1.0000 - val_loss: 0.0109 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00138: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 139/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - pos_accuracy: 1.0000 - val_loss: 0.0108 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00139: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 140/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0016 - pos_accuracy: 1.0000 - val_loss: 0.0108 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00140: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 141/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - pos_accuracy: 1.0000 - val_loss: 0.0106 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00141: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 142/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - pos_accuracy: 1.0000 - val_loss: 0.0104 - val_pos_accuracy: 0.9952\n",
      "---lr decreasing: 1.250000e-04\n",
      "\n",
      "Epoch 00142: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 143/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00143: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 144/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0104 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00144: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 145/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - pos_accuracy: 1.0000 - val_loss: 0.0099 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00145: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 146/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0100 - val_pos_accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00146: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 147/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0097 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00147: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 148/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0011 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00148: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 149/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0101 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00149: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 150/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00150: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 151/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0013 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00151: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 152/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0013 - pos_accuracy: 1.0000 - val_loss: 0.0097 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00152: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 153/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00153: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 154/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0014 - pos_accuracy: 1.0000 - val_loss: 0.0099 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00154: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 155/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0096 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00155: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 156/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00156: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 157/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0098 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00157: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 158/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0096 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00158: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 159/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0096 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00159: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 160/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0094 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00160: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 161/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0096 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00161: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 162/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "---lr decreasing: 6.250000e-05\n",
      "\n",
      "Epoch 00162: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 163/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.7238e-04 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00163: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 164/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0010 - pos_accuracy: 1.0000 - val_loss: 0.0095 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00164: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 165/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.8116e-04 - pos_accuracy: 1.0000 - val_loss: 0.0094 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00165: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 166/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.5368e-04 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00166: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 167/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.7737e-04 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00167: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 168/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0010 - pos_accuracy: 1.0000 - val_loss: 0.0094 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00168: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 169/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.4904e-04 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00169: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 170/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.5616e-04 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00170: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 171/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.4959e-04 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00171: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 172/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.5533e-04 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00172: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 173/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0010 - pos_accuracy: 1.0000 - val_loss: 0.0092 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00173: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 174/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0011 - pos_accuracy: 1.0000 - val_loss: 0.0100 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00174: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 175/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00175: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 176/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.6678e-04 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00176: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 177/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.5075e-04 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00177: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 178/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.4140e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00178: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 179/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.1027e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00179: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 180/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.3276e-04 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00180: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 181/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 9.5295e-04 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00181: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 182/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0011 - pos_accuracy: 1.0000 - val_loss: 0.0093 - val_pos_accuracy: 0.9952\n",
      "---lr decreasing: 3.125000e-05\n",
      "\n",
      "Epoch 00182: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 183/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.6354e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00183: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 184/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.5539e-04 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00184: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 185/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3845e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00185: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 186/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.4915e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00186: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 187/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3917e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00187: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 188/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.2733e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00188: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 189/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3555e-04 - pos_accuracy: 1.0000 - val_loss: 0.0090 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00189: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 190/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.5686e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00190: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 191/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3648e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00191: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 192/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.5073e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00192: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 193/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.3444e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00193: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 194/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.2037e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00194: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 195/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.3633e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00195: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 196/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.1268e-04 - pos_accuracy: 1.0000 - val_loss: 0.0088 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00196: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 197/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.3384e-04 - pos_accuracy: 1.0000 - val_loss: 0.0091 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00197: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 198/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.2886e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00198: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 199/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.1134e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00199: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 200/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 8.4351e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00200: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 201/400\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.4089e-04 - pos_accuracy: 1.0000 - val_loss: 0.0089 - val_pos_accuracy: 0.9952\n",
      "\n",
      "Epoch 00201: val_pos_accuracy did not improve from 0.99519\n",
      "Epoch 202/400\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 7.9934e-04 - pos_accuracy: 1.0000 - val_loss: 0.0088 - val_pos_accuracy: 0.9952\n",
      "Epoch 201: early stopping\n",
      "\n",
      "Epoch 00202: val_pos_accuracy did not improve from 0.99519\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0209 - pos_accuracy: 0.9952\n",
      "val_loss = 0.020919721573591232 val_pos_accuracy = 0.995192289352417\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 재현 가능한 난수 생성\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "def load_data():\n",
    "    n = 2000\n",
    "    split = 0.8\n",
    "    n_train = (int)(split*n)\n",
    "    \n",
    "    y = np.random.randint(28, size=(n,2))\n",
    "    x = np.empty((n,28,28))\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        img = np.zeros((28,28))\n",
    "        cv2.circle(img, (y[i][0],y[i][1]), 3, 255, -1)\n",
    "        x[i] = img\n",
    "    return ((x[:n_train], y[:n_train]), (x[n_train:], y[n_train:]))\n",
    "\n",
    "def label(y):\n",
    "    return np.around(y).astype('int')\n",
    "        \n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# normalize image\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(str(label(y_test[i])))\n",
    "plt.show()\n",
    "\n",
    "def pos_accuracy(y_true, y_pred):\n",
    "    label_true = tf.round(y_true)\n",
    "    label_pred = tf.round(y_pred)\n",
    "    is_correct = tf.reduce_all(label_true == label_pred, axis=1)\n",
    "    is_correct = tf.cast(is_correct, 'float32')\n",
    "    score = tf.reduce_mean(is_correct)\n",
    "    return score\n",
    "\n",
    "model = keras.Sequential([\n",
    " keras.layers.Reshape(input_shape=(28, 28), target_shape=(28, 28, 1)),\n",
    " keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    " keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    " keras.layers.Conv2D(4, (3,3), padding='valid', activation='relu'),\n",
    " keras.layers.Flatten(),\n",
    " keras.layers.Dense(2, activation=None)\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[pos_accuracy])\n",
    "\n",
    "# 이 자리에 LrReducer snippet을 추가합니다.\n",
    "class LrReducer(Callback):\n",
    " def __init__(self, patience=5, reduce_rate=0.5, reduce_nb=5, verbose=1):\n",
    "     super(Callback, self).__init__()\n",
    "     self.patience = patience\n",
    "     self.wait = 0\n",
    "     self.best_score = -1.\n",
    "     self.reduce_rate = reduce_rate\n",
    "     self.current_reduce_nb = 0\n",
    "     self.reduce_nb = reduce_nb\n",
    "     self.verbose = verbose\n",
    "\n",
    " def on_epoch_end(self, epoch, logs={}):\n",
    "     current_score = logs.get('val_pos_accuracy')\n",
    "     if current_score > self.best_score:\n",
    "         self.best_score = current_score\n",
    "         self.wait = 0\n",
    "         if self.verbose > 0:\n",
    "             print('---current best score: %.3f' % current_score)\n",
    "     else:\n",
    "         if self.wait >= self.patience:\n",
    "             self.current_reduce_nb += 1\n",
    "             if self.current_reduce_nb <= self.reduce_nb:\n",
    "                 lr = keras.backend.get_value(self.model.optimizer.lr)\n",
    "                 keras.backend.set_value(self.model.optimizer.lr, lr*self.reduce_rate)\n",
    "                 self.wait = 0\n",
    "                 if self.verbose > 0:\n",
    "                     print('---lr decreasing: %e' % (lr*self.reduce_rate))\n",
    "             else:\n",
    "                 if self.verbose > 0:\n",
    "                     print(\"Epoch %d: early stopping\" % (epoch))\n",
    "                 self.model.stop_training = True\n",
    "         self.wait += 1\n",
    "lrreducer = LrReducer(patience=20)\n",
    "\n",
    "# 이 자리에 ModelCheckpoint snippet을 추가합니다.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_pos_accuracy', verbose=1,\n",
    " save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "n_batch = 32\n",
    "n_epochs = 400\n",
    "\n",
    "# 1. model.fit의 반환 결과를 history 변수에 저장합니다.\n",
    "# 2. lrreducer callback을 추가합니다.\n",
    "# 3. checkpoint callback을 추가합니다.\n",
    "history = model.fit(\n",
    " x_train, y_train,\n",
    " validation_data=(x_test, y_test),\n",
    " batch_size=n_batch,\n",
    " epochs=n_epochs,\n",
    " callbacks = [lrreducer, checkpoint] # 두 가지의 callback 모두 사용\n",
    ")\n",
    "\n",
    "# 여기에 저장된 weights를 loading하는 코드를 추가합니다.\n",
    "model.load_weights(\"best_model.h5\")\n",
    "\n",
    "# 여기에 Graph snippet 코드를 추가합니다.\n",
    "# 학습 정확성 값과 검증 정확성 값을 그래프로 그립니다.\n",
    "plt.plot(history.history['pos_accuracy'])\n",
    "plt.plot(history.history['val_pos_accuracy'])\n",
    "plt.title('Model pos_accuracy')\n",
    "plt.ylabel('Pos_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss의 그래프\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0.0,1.0)\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 모델의 성능 측정\n",
    "val_loss, val_pos_accuracy = model.evaluate(x_test, y_test)\n",
    "print('val_loss =', val_loss, 'val_pos_accuracy =', val_pos_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad18fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
