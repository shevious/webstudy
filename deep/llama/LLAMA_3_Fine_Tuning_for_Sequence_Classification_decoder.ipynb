{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqufrL0vwDod"
   },
   "source": [
    "# LLAMA3 Fine-tuning for text classification using QLORA\n",
    "\n",
    "This notebook is an implementaton of:\n",
    "https://arxiv.org/abs/2305.14314\n",
    "\n",
    "This notebook is derived from:\n",
    "https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb\n",
    "\n",
    "Where I adapated the problem and data set from:\n",
    "https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners\n",
    "\n",
    "### Requirements:\n",
    "* A GPU with enough memory, 12GB VRAM or more.  Nvidia/Tesla T4 or better would work\n",
    "\n",
    "### Installs\n",
    "* They suggest using latest version of transformers\n",
    "* Must restart after install because the accelerate package used in the hugging face trainer requires it.\n",
    "\n",
    "### Google Colab\n",
    "For your convenience open this notebook on google colab with this link\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jkyamog/ml-experiments/blob/main/fine-tuning-qlora/LLAMA_3_Fine_Tuning_for_Sequence_Classification.ipynb)\n",
    "\n",
    "Add the following secrets to Colab's secret:\n",
    "* huggingface - hugging face token to access models\n",
    "* kaggle_user - kaggle username from Setting > Account > API\n",
    "* kaggle_key - kaggle key from Setting > Account > API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1719950917608
    },
    "id": "QzSvk9-psdeH",
    "outputId": "7be5fc20-c176-4fdb-c528-f84cfd907086"
   },
   "outputs": [],
   "source": [
    "# Install Pytorch\n",
    "#%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "#%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                1.5.2\n",
      "bitsandbytes              0.45.3\n",
      "datasets                  3.4.1\n",
      "evaluate                  0.4.3\n",
      "huggingface-hub           0.29.3\n",
      "peft                      0.14.0\n",
      "transformers              4.49.0\n",
      "trl                       0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep \"transformers\\\\|datasets\\\\|accelerate\\\\|evaluate\\\\|bitsandbytes\\\\|huggingface-hub\\\\|trl\\\\|peft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIS0yOVNRHcB"
   },
   "source": [
    "### Big Picture Overview of Parameter Efficient Fine Tuning Methods like LoRA and QLoRA Fine Tuning for Sequence Classification\n",
    "\n",
    "**The Essence of Fine-tuning**\n",
    "- LLMs are pre-trained on vast amounts of data for broad language understanding.\n",
    "- Fine-tuning is crucial for specializing in specific domains or tasks, involving adjustments with smaller, relevant datasets.\n",
    "\n",
    "**Model Fine-tuning with PEFT: Exploring LoRA and QLoRA**\n",
    "- Traditional fine-tuning is resource-intensive; PEFT (Parameter Efficient Fine-tuning) makes the process faster and less demanding.\n",
    "- Focus on two PEFT methods: LoRA and QLoRA.\n",
    "\n",
    "**The Power of PEFT**\n",
    "- PEFT modifies only a subset of the LLM's parameters, enhancing speed and reducing memory demands, making it suitable for less powerful devices.\n",
    "\n",
    "**LoRA: Efficiency through Adapters**\n",
    "- **Low-Rank Adaptation (LoRA):** Injects small trainable adapters into the pre-trained model.\n",
    "- **Equation:** For a weight matrix $W$, LoRA approximates $W = W_0 + BA$, where $W_0$ is the original weight matrix, and $BA$ represents the low-rank modification through trainable matrices $B$ and $A$.\n",
    "- Adapters learn task nuances while keeping the majority of the LLM unchanged, minimizing overhead.\n",
    "\n",
    "**QLoRA: Compression and Speed**\n",
    "- **Quantized LoRA (QLoRA):** Extends LoRA by quantizing the model’s weights, further reducing size and enhancing speed.\n",
    "- **Innovations in QLoRA:**\n",
    "  1. **4-bit Quantization:** Uses a 4-bit data type, NormalFloat (NF4), for optimal weight quantization, drastically reducing memory usage.\n",
    "  2. **Low-Rank Adapters:** Fine-tuned with 16-bit precision to effectively capture task-specific nuances.\n",
    "  3. **Double Quantization:** Reduces quantization constants from 32-bit to 8-bit, saving additional memory without accuracy loss.\n",
    "  4. **Paged Optimizers:** Manages memory efficiently during training, optimizing for large tasks.\n",
    "\n",
    "**Why PEFT Matters**\n",
    "- **Rapid Learning:** Speeds up model adaptation.\n",
    "- **Smaller Footprint:** Eases deployment with reduced model size.\n",
    "- **Edge-Friendly:** Fits better on devices with limited resources, enhancing accessibility.\n",
    "\n",
    "**Conclusion**\n",
    "- PEFT methods like LoRA and QLoRA revolutionize LLM fine-tuning by focusing on efficiency, facilitating faster adaptability, smaller models, and broader device compatibility.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAs9tbj8tiBZ"
   },
   "source": [
    "### Fine-tuning for Text Classification:\n",
    "\n",
    "\n",
    "#### 1. Text Generation with Classification Label as part of text\n",
    "- **Approach**: Train the model to generate text that naturally appends the classification label at the end.\n",
    "- **Input**: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\"\n",
    "- **Output**: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit 0.25\"\n",
    "- **Use Case**: This method is useful for classifiying text\n",
    "\n",
    "\n",
    "#### 2. Sequence Classification Head\n",
    "- **Approach**: Add a sequence classification head (linear layer) on top of the LLaMa Model transformer. This setup is similar to GPT-2 and focuses on classifying the sentiment based on the last relevant token in the sequence.\n",
    "    - **Token Positioning**:\n",
    "        - **With pad_token_id**: The model identifies and ignores padding tokens, using the last non-padding token for classification.\n",
    "        - **Without pad_token_id**: It defaults to the last token in each sequence.\n",
    "        - **inputs_embeds**: If embeddings are directly passed (without input_ids), the model cannot identify padding tokens and takes the last embedding in each sequence as the input for classification.\n",
    "- **Input**: Specific sentences (e.g., \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\").\n",
    "- **Output**: Direct classification (e.g., \"0.25\", \"0.50\").\n",
    "- **Training Objective**: Minimize cross-entropy loss between the predicted and the actual sentiment labels.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/en/model_doc/llama\n",
    "\n",
    "### Peft Configs\n",
    "* Bits and bytes config for quantization\n",
    "* Lora config for lora\n",
    "\n",
    "### Going to use Hugginface Transformers trainer class: Main componenents\n",
    "* Hugging face dataset (for train + eval)\n",
    "* Data collater\n",
    "* Compute Metrics\n",
    "* Class weights since we use custom trainer and also custom weighted loss..\n",
    "* trainingArgs: like # epochs, learning rate, weight decay etc..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCNt55YNyA3d"
   },
   "source": [
    "### Login to huggingface hub to put your LLama token so we can access Llama 3 7B Param Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_map=\"DDP\" # for DDP and running with `accelerate launch test_sft.py`\n",
    "device_map='auto' # for PP and running with `python test_sft.py`\n",
    "\n",
    "if device_map == \"DDP\":\n",
    "    device_string = PartialState().process_index\n",
    "    device_map={'':device_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8157Tsw3Vo3",
    "outputId": "c3a4c48f-9b9b-4627-cd67-68ff0bb28b6d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import userdata\n",
    "#hugginface_token = userdata.get('huggingface')\n",
    "#!huggingface-cli login --token $hugginface_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_5AVUyey1io"
   },
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1720052464680
    },
    "id": "h5NPLc7isjdM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPHo5hnA1Fsq"
   },
   "source": [
    "The easiest way to download Kaggle datasets is to use the Kaggle API. You can install this using pip by running this in a notebook cell:\n",
    "\n",
    "!pip install kaggle\n",
    "You need an API key to use the Kaggle API; to get one, click on your profile picture on the Kaggle website, and choose My Account, then click Create New API Token. This will save a file called kaggle.json to your PC. You need to copy this key on your GPU server. To do so, open the file you downloaded, copy the contents, and paste them in the following cell (e.g., creds = '{\"username\":\"xxx\",\"key\":\"xxx\"}'):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rBzvYhwBtlSw"
   },
   "outputs": [],
   "source": [
    "#creds = '{\"username\":\"' + userdata.get('kaggle_user') + '\",\"key\":\"' + userdata.get('kaggle_key') + '\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpsWwKRpuIxD"
   },
   "source": [
    "Then execute this cell (this only needs to be run once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720041564511
    },
    "id": "YOq1vMB-oQzQ",
    "outputId": "f2db1a80-b3f8-446e-f15f-6bb1bd46f47e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kotech/.kaggle/kaggle.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install kaggle\n",
    "\n",
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "iskaggle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
    "if not cred_path.exists():\n",
    "  cred_path.parent.mkdir(exist_ok=True)\n",
    "  cred_path.write_text(creds)\n",
    "  cred_path.chmod(0o600)\n",
    "\n",
    "cred_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDJ3LlWTt1L7"
   },
   "source": [
    "Now you can download datasets from Kaggle.\n",
    "\n",
    "add Codeadd Markdown\n",
    "path = Path('us-patent-phrase-to-phrase-matching')\n",
    "add Codeadd Markdown\n",
    "And use the Kaggle API to download the dataset to that path, and extract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1720041623972
    },
    "id": "yFIRWaIH1SHb"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "if not iskaggle and not path.exists():\n",
    "    import zipfile,kaggle\n",
    "    kaggle.api.competition_download_cli(str(path))\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720053018867
    },
    "id": "R2o1th0qp4c2",
    "outputId": "987cc154-386d-447d-d576-b3e590d95f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path = Path('us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "!ls {path}\n",
    "\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC0ls6RVlzHC"
   },
   "source": [
    "* Add also a numeric 0,1,2,3,4 version of label since we will need it later for fine tuning. We can save it in 'score_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "gather": {
     "logged": 1720053021270
    },
    "id": "kHiBd07ikx0N",
    "outputId": "03d8524d-592b-49f0-e2a8-42b0f1e8ba85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>score_ascat</th>\n",
       "      <th>score_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
       "...                 ...           ...                     ...     ...    ...   \n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00   \n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50   \n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50   \n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75   \n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50   \n",
       "\n",
       "      score_ascat  score_category  \n",
       "0            0.50               2  \n",
       "1            0.75               3  \n",
       "2            0.25               1  \n",
       "3            0.50               2  \n",
       "4            0.00               0  \n",
       "...           ...             ...  \n",
       "36468        1.00               4  \n",
       "36469        0.50               2  \n",
       "36470        0.50               2  \n",
       "36471        0.75               3  \n",
       "36472        0.50               2  \n",
       "\n",
       "[36473 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score_ascat']=df['score'].astype('category')\n",
    "df['score_category']=df['score_ascat'].cat.codes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnaLFMhfk1u_"
   },
   "source": [
    "* Suppose you want to decode later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "gather": {
     "logged": 1720053088213
    },
    "id": "r0eMOMiky_8b",
    "outputId": "0001f358-0318-4025-9857-432809b9092c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     8d135da0b55b8c88  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score_ascat'].cat.categories\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720053115165
    },
    "id": "oZEezWPak0Oh",
    "outputId": "503a3640-c82c-43ab-d0c8-91007779aad0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map = {code: category for code, category in enumerate(df['score_ascat'].cat.categories)}\n",
    "category_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv3ToinDzIwE"
   },
   "source": [
    "### Convert from Pandas DataFrame to Hugging Face Dataset\n",
    "* Also let's shuffle the training set.\n",
    "* We put the components train,val,test into a DatasetDict so we can access them later with HF trainer.\n",
    "* Later we will add a tokenized dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1720056089938
    },
    "id": "1g5EdzTN21Tq"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(path/'test.csv')\n",
    "\n",
    "train_size = 0.8 # 80% of data\n",
    "test_size = 0.2 # 20% of data\n",
    "df_train, df_val = train_test_split(pd.read_csv(path/'train.csv'), train_size=train_size, test_size=test_size, random_state=42)\n",
    "\n",
    "def generate_features(df):\n",
    "  df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n",
    "  if 'score' in df.columns:\n",
    "    df['score_ascat']=df['score'].astype('category')\n",
    "    df['score_category']=df['score_ascat'].cat.codes\n",
    "  else:\n",
    "    df['score_category'] = pd.NA\n",
    "\n",
    "generate_features(df_train)\n",
    "generate_features(df_val)\n",
    "\n",
    "\n",
    "# Converting pandas DataFrames into Hugging Face Dataset objects:\n",
    "dataset_train = Dataset.from_pandas(df_train.drop(['score_ascat', 'score'],axis=1).reset_index(drop=True))\n",
    "dataset_val = Dataset.from_pandas(df_val.drop(['score_ascat', 'score'],axis=1).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720056885366
    },
    "id": "xREu-St-zeGE",
    "outputId": "b4bbbc1a-429a-4fb4-d981-5492e45e1f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'input', 'score_category'],\n",
       "        num_rows: 29178\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'input', 'score_category'],\n",
       "        num_rows: 7295\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine them into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'val': dataset_val,\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6mX_Hfe0hei"
   },
   "source": [
    "* Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
    "* Convert to pytorch tensor since we will need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720056899952
    },
    "id": "Z6z0M7tf0g3q",
    "outputId": "b6a3cc63-1d56-400d-805a-ad223c5577eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_category\n",
       "2    0.337994\n",
       "1    0.315854\n",
       "0    0.204538\n",
       "3    0.109500\n",
       "4    0.032113\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.score_category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720057969380
    },
    "id": "e6Nvgfy-zsyM",
    "outputId": "28d410a0-fe55-415b-9ae9-5e25b7227d6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0953, 0.0617, 0.0577, 0.1781, 0.6072])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=(1/df_train.score_category.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights=torch.tensor(class_weights)\n",
    "class_weights=class_weights/class_weights.sum()\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QolyR2Cd2Bsg"
   },
   "source": [
    "## Load LLama model with 4 bit quantization as specified in bits and bytes and prepare model for peft training\n",
    "\n",
    "### Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1720054181900
    },
    "id": "mXkyNcgt2fet"
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzRyVNmN2jlO"
   },
   "source": [
    "#### Quantization Config (for QLORA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1720054183577
    },
    "id": "BtR7MXs43GJf"
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4-bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxRLidIwS4Xu"
   },
   "source": [
    "#### Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1720054187625
    },
    "id": "EG950ljoS3RM"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 16, # the dimension of the low-rank matrices\n",
    "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "    task_type = 'SEQ_CLS'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brl04t2KS69t"
   },
   "source": [
    "#### Load model\n",
    "* AutomodelForSequenceClassification\n",
    "* Num Labels is # of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.llama import LlamaPreTrainedModel\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from transformers.cache_utils import Cache, DynamicCache, StaticCache\n",
    "from transformers.modeling_outputs import (\n",
    "    #BaseModelOutputWithPast,\n",
    "    #CausalLMOutputWithPast,\n",
    "    #QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    #TokenClassifierOutput,\n",
    ")\n",
    "from transformers.models.llama import LlamaModel\n",
    "from torch import nn\n",
    "from transformers.models.llama.modeling_llama import LlamaDecoderLayer, LlamaRotaryEmbedding\n",
    "\n",
    "class LlamaForSequenceClassification2(LlamaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.vocab_size = config.vocab_size\n",
    "        \n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = LlamaModel(config)\n",
    "        \n",
    "        self.out_num_layers = 1\n",
    "        self.outlayers = nn.ModuleList(\n",
    "            [LlamaDecoderLayer(config, layer_idx+config.num_hidden_layers) for layer_idx in range(self.out_num_layers)]\n",
    "        )\n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "        self.rotary_emb = self.model.rotary_emb\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        \n",
    "        self.outlayers[0].load_state_dict(self.model.layers[31].state_dict())\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.model.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.model.embed_tokens = value\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        '''\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.model.embed_tokens(input_ids)\n",
    "        \n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        if use_cache and past_key_values is None:\n",
    "            past_key_values = DynamicCache()\n",
    "            \n",
    "        cache_position = None\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "            )\n",
    "            \n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "        '''\n",
    "\n",
    "        transformer_outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            #cache_position = cache_position,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "\n",
    "        #use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        use_cache = False\n",
    "        past_key_values = None\n",
    "        \n",
    "        if use_cache and past_key_values is None:\n",
    "            past_key_values = DynamicCache()\n",
    "            \n",
    "        cache_position = None\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + hidden_states.shape[1], device=hidden_states.device\n",
    "            )\n",
    "            \n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "        \n",
    "        causal_mask = self.model._update_causal_mask(\n",
    "            attention_mask, hidden_states, cache_position, past_key_values, output_attentions\n",
    "        )\n",
    "\n",
    "        # create position embeddings to be shared across the decoder layers\n",
    "        #position_embeddings = self.rotary_emb(inputs_embeds, position_ids)\n",
    "        position_embeddings = self.rotary_emb(hidden_states, position_ids)\n",
    "        #print('input shape =', hidden_states.shape)\n",
    "        #print('hidden_states =', hidden_states)\n",
    "        #print('causal_mask =', causal_mask)\n",
    "        #print('position_ids =', position_ids)\n",
    "        #print('past_key_values=', past_key_values)\n",
    "        #print('output_attentions=', output_attentions)\n",
    "        #print('use_cache=', use_cache)\n",
    "        #print('cache_position=', cache_position)\n",
    "        #print('position_embeddings=', position_embeddings)\n",
    "\n",
    "        #print('input shape =', hidden_states.shape)\n",
    "        for decoder_layer in self.outlayers[: self.out_num_layers]:\n",
    "            layer_outputs = decoder_layer(\n",
    "                    hidden_states,\n",
    "                    attention_mask=causal_mask,\n",
    "                    position_ids=position_ids,\n",
    "                    past_key_value=past_key_values,\n",
    "                    output_attentions=output_attentions,\n",
    "                    use_cache=use_cache,\n",
    "                    cache_position=cache_position,\n",
    "                    position_embeddings=position_embeddings,\n",
    "                    #**flash_attn_kwargs,\n",
    "                )\n",
    "            hidden_states = layer_outputs[0]\n",
    "        #print('output shape =', hidden_states.shape)\n",
    "        #print('hidden_states =', hidden_states)\n",
    "        hidden_states = self.model.norm(hidden_states)\n",
    "        '''\n",
    "        '''\n",
    "        logits = self.score(hidden_states)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size = input_ids.shape[0]\n",
    "        else:\n",
    "            batch_size = inputs_embeds.shape[0]\n",
    "            \n",
    "        #print('config.pad_token_id =', self.config.pad_token_id)\n",
    "        #print('batch_size =', batch_size)\n",
    "\n",
    "        if self.config.pad_token_id is None and batch_size != 1:\n",
    "            raise ValueError(\"Cannot handle batch sizes > 1 if no padding token is defined.\")\n",
    "        if self.config.pad_token_id is None:\n",
    "            last_non_pad_token = -1\n",
    "        elif input_ids is not None:\n",
    "            # To handle both left- and right- padding, we take the rightmost token that is not equal to pad_token_id\n",
    "            non_pad_mask = (input_ids != self.config.pad_token_id).to(logits.device, torch.int32)\n",
    "            token_indices = torch.arange(input_ids.shape[-1], device=logits.device)\n",
    "            last_non_pad_token = (token_indices * non_pad_mask).argmax(-1)\n",
    "        else:\n",
    "            last_non_pad_token = -1\n",
    "            logger.warning_once(\n",
    "                f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
    "                \"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
    "            )\n",
    "\n",
    "        pooled_logits = logits[torch.arange(batch_size, device=logits.device), last_non_pad_token]\n",
    "        #print('pooled_logits.shape =', pooled_logits.shape)\n",
    "        #print('pooled_logits =', pooled_logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(logits=logits, labels=labels, pooled_logits=pooled_logits, config=self.config)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (pooled_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        #raise\n",
    "\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=pooled_logits,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918,
     "referenced_widgets": [
      "efcd9b2d530c4a7d842c4985acb201d1",
      "0e7bfb272af3480e9384f56b892fec47",
      "dae6e96c41c549ffbc6d53e9b6e4d176",
      "8cec5b1b342e432f942dfe0c07bdbc55",
      "630d6c2edaa34ff4820b0f3cbc776eda",
      "e4eacc874a6049c38b1989b6229b5954",
      "e0544d43054549af9272caafb43c1aaa",
      "c63262ee29ec4a17b1d976643512ac72",
      "2c016d643bf6480c9411f88e751063b1",
      "ad5633fc3e094227800f7d14b9902b76",
      "ba80ab2b7ad643e0b509f94450c072c9",
      "4a50cdc6ba00447e9a272e106cdf0b2b",
      "4c53d928e8444ceb88ce3baad0462aa7",
      "9c6db2d631944b83a9ed1b3224de2d4a",
      "7974731eb1c14344b82a78dad06f95a7",
      "fca39da904da4d249964985162897242",
      "77c8b02ac50d40b18bfb7e03995044b3",
      "0bbee1644fd942ba84d79581cdbe16e1",
      "c86d5ce5126e493d8ed5068285ee04c1",
      "3ea6cac855db48aebdc66b0328486a7e",
      "9f6760d652ec419f967c8f8f1fad471a",
      "1f534ef0bb5e4fcfb7398e1cb628ac42",
      "02d3830727284700bb3d0027689683e3",
      "c9dce19ac35441589f8bcee5f8c77f0f",
      "6ac206dbfab94f5481384577c941b125",
      "bc9c9c8c55834d95afa2ff1358dc5906",
      "c83e62f823ef455eb45c35c5fce68dae",
      "eb2194b7d8244247bf369d11ad165f64",
      "9325e3aa39f04ea289bcb9b524a1912e",
      "d4fc63186a1741a192548b27ddcfa35b",
      "b000d0fa59b64669a1302972ac8fbbf7",
      "8e24192905cb44a2808fd02c71bb4909",
      "96ee1cf007c746219beefd1133beb0ab",
      "6f04b99a7732436c95a44819400de789",
      "e7cddf4af8ea485aa3e893af5dd365cb",
      "2cbb7ecb92a64db89d59f0bbaada569c",
      "3f30159710bf490db518adc57c2cbf0c",
      "aecf9dd24860401e88f7f56b208bab46",
      "ebc4adc1f2ef48ddba5aafcc93f48477",
      "9fb6e17fb523419fa868703cc1633efa",
      "328e749dadc94bd689c5257716b1e267",
      "f9d266bc194c44dcbdbc12b51daff386",
      "cf84a617bc6b4f5dae1c0648f8c969b1",
      "21b77dc7dac245858176d38860ae10cd",
      "868ae5fcd4b3449297a6596de8cf892e",
      "edebaac0cf86431aa2ac5b24748a50d7",
      "bad280c1f832422dbe2e7d3ce8bfe205",
      "50c59fccba734f8b9de37b6f6ef28cfd",
      "bc6647483e594a8e95def8964b058768",
      "d18bf0ecca7643319d7d8a43fd31973d",
      "0495f42403f440a5b589ed4b39c27e26",
      "dd012db000204884bf6e17c9d17664a6",
      "a5ee890dd2e94e21989bb30ad3ff50fb",
      "8aeb45a4f8d14487bfd598eb071876dc",
      "9622056982814fe48e3d1a23d6311011",
      "9c98a0d7f1f34e438d116fdec59292f9",
      "4f958021df09474fbe60c8830ccc4810",
      "24c365ce42a2473ea86e9a3ff3b4bbdb",
      "031ad948be37418397f06cbf2f7eaa19",
      "27cb423a33794a2fb329a0265856fce1",
      "a9d5df847f5e40d5be45f7ad24ad23fb",
      "4ca85e56a8064d0d8bc1740e2559827d",
      "cf28511f878b4402a3d1ec95944ed38c",
      "6280494fe6974847ad497587d378523e",
      "f18f2bf7ed5f4b4c9aacf141ae34d2a9",
      "f209b3c55af54890b110e49760eaf6f0",
      "e3541a1ff2b14488b765c368d1df8664",
      "12f2a80a725548e1b4a448ff5cf3c6b8",
      "0a2c6d42c43948acaec95f97de0cf7ac",
      "b3076d10a2d64e89a199946fadefbea0",
      "f550c3b95d134de9b7937bc6b3d775d3",
      "c9f48e5ed19140ec96b3681e30f71292",
      "6e7cbd8115d645e292b219bb0bbf8fe1",
      "4097d35df75f42c38e60100f5ed5ba00",
      "83f162c9af04440a93aa19aeb58efbde",
      "83f3dfc8d5984267b224c27f489177e1",
      "11be9dd298754155ac5521ad4341d6a1",
      "60f421ee47854b37a58f0cbea78eb474",
      "fc911804053e44f98215ae7bef27e206",
      "86a059793efc4567a66a12277b7f5dc4",
      "ae8454dfa7da4ac2a63a36eaddf04359",
      "29d5da530e0d4f078dd2dd1967e9e6a2",
      "85f350094d1347e2b55b8a37331997cb",
      "2d0cab209a1d4b6195d72e5fc906567e",
      "3b84c5d287db40a09845d2615fd18e10",
      "e4b5d7f6495c4444864ae0aa591b8bcd",
      "0560c42edd444e6cbf857665f24207b5",
      "f9714a9508e2460586f1c12a9caaba21"
     ]
    },
    "gather": {
     "logged": 1720057989009
    },
    "id": "pJtZAdKp4WdT",
    "outputId": "9a180bbc-22e8-465f-a5f0-3550dd523cc3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaf27037f1040e581d6e71e2da9dafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification2 were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['outlayers.0.input_layernorm.weight', 'outlayers.0.mlp.down_proj.weight', 'outlayers.0.mlp.gate_proj.weight', 'outlayers.0.mlp.up_proj.weight', 'outlayers.0.post_attention_layernorm.weight', 'outlayers.0.self_attn.k_proj.weight', 'outlayers.0.self_attn.o_proj.weight', 'outlayers.0.self_attn.q_proj.weight', 'outlayers.0.self_attn.v_proj.weight', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification2(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (outlayers): ModuleList(\n",
       "    (0): LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=5, bias=False)\n",
       "  (rotary_emb): LlamaRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForSequenceClassification2.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=quantization_config,\n",
    "    num_labels=len(category_map),\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prFT0qY0mVkR"
   },
   "source": [
    "* prepare_model_for_kbit_training() function to preprocess the quantized model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "outlayers.0.self_attn.q_proj.weight\n",
      "outlayers.0.self_attn.k_proj.weight\n",
      "outlayers.0.self_attn.v_proj.weight\n",
      "outlayers.0.self_attn.o_proj.weight\n",
      "outlayers.0.mlp.gate_proj.weight\n",
      "outlayers.0.mlp.up_proj.weight\n",
      "outlayers.0.mlp.down_proj.weight\n",
      "outlayers.0.input_layernorm.weight\n",
      "outlayers.0.post_attention_layernorm.weight\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720057993981
    },
    "id": "-NcEtG0jmTqO",
    "outputId": "c383e586-010d-42a7-d4a2-493c97d4cc5c"
   },
   "outputs": [],
   "source": [
    "#model = prepare_model_for_kbit_training(model)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.score.parameters():\n",
    "    param.requires_grad = True\n",
    "#for param in model.score1.parameters():\n",
    "#    param.requires_grad = True\n",
    "#for param in model.score2.parameters():\n",
    "#    param.requires_grad = True\n",
    "for param in model.outlayers.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlayers.0.self_attn.q_proj.weight\n",
      "outlayers.0.self_attn.k_proj.weight\n",
      "outlayers.0.self_attn.v_proj.weight\n",
      "outlayers.0.self_attn.o_proj.weight\n",
      "outlayers.0.mlp.gate_proj.weight\n",
      "outlayers.0.mlp.up_proj.weight\n",
      "outlayers.0.mlp.down_proj.weight\n",
      "outlayers.0.input_layernorm.weight\n",
      "outlayers.0.post_attention_layernorm.weight\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25JDWS0Hmb0y"
   },
   "source": [
    "* get_peft_model prepares a model for training with a PEFT method such as LoRA by wrapping the base model and PEFT configuration with get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720057997545
    },
    "id": "zIXKJgTfmU-H",
    "outputId": "dc4e0cca-a4c6-4c11-eeab-fa59f7c0a5b5"
   },
   "outputs": [],
   "source": [
    "#model = get_peft_model(model, lora_config)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('self_attn.q_proj.weight',\n",
       "              tensor([[ 8.3618e-03, -3.4790e-03,  7.8735e-03,  ..., -6.8665e-04,\n",
       "                       -1.4114e-03, -1.9684e-03],\n",
       "                      [ 3.1128e-03, -1.5717e-03,  1.3428e-02,  ..., -1.5991e-02,\n",
       "                       -3.8452e-03,  1.1902e-03],\n",
       "                      [ 7.1716e-03,  1.2207e-02, -1.0376e-02,  ...,  2.9504e-06,\n",
       "                       -2.6733e-02,  3.2501e-03],\n",
       "                      ...,\n",
       "                      [-6.0425e-03,  1.6846e-02,  1.4221e-02,  ..., -1.0132e-02,\n",
       "                       -1.6602e-02,  2.4048e-02],\n",
       "                      [-1.7944e-02, -2.4902e-02,  1.0803e-02,  ..., -3.4424e-02,\n",
       "                        2.3956e-03, -2.2217e-02],\n",
       "                      [-3.8757e-03, -1.7090e-02,  1.1414e-02,  ...,  2.1973e-03,\n",
       "                       -5.9891e-04, -6.9427e-04]], device='cuda:3')),\n",
       "             ('self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0126, -0.0272,  0.0303,  ...,  0.0481, -0.0062,  0.0065],\n",
       "                      [-0.0266, -0.0155, -0.0435,  ..., -0.0216, -0.0515,  0.0091],\n",
       "                      [ 0.0107,  0.0070,  0.0159,  ..., -0.0048, -0.0025, -0.0025],\n",
       "                      ...,\n",
       "                      [-0.0197,  0.0422, -0.0142,  ..., -0.0164, -0.0437,  0.0079],\n",
       "                      [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
       "                      [-0.0092,  0.0048,  0.0143,  ..., -0.0170, -0.0391,  0.0198]],\n",
       "                     device='cuda:3')),\n",
       "             ('self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0171,  0.0178, -0.0027,  ..., -0.0255, -0.0188,  0.0130],\n",
       "                      [-0.0052,  0.0041, -0.0131,  ..., -0.0074,  0.0082, -0.0030],\n",
       "                      [-0.0427, -0.0253, -0.0144,  ..., -0.0292,  0.0300, -0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0076,  0.0003, -0.0002,  ...,  0.0096, -0.0047, -0.0043],\n",
       "                      [-0.0016, -0.0041, -0.0073,  ..., -0.0107, -0.0015, -0.0214],\n",
       "                      [-0.0231,  0.0022,  0.0057,  ...,  0.0069, -0.0096, -0.0069]],\n",
       "                     device='cuda:3')),\n",
       "             ('self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0199, -0.0128, -0.0223,  ...,  0.0118, -0.0031,  0.0134],\n",
       "                      [ 0.0003, -0.0035, -0.0044,  ...,  0.0014, -0.0001,  0.0105],\n",
       "                      [-0.0073,  0.0129, -0.0082,  ..., -0.0009,  0.0072, -0.0061],\n",
       "                      ...,\n",
       "                      [ 0.0019,  0.0116, -0.0045,  ..., -0.0007, -0.0011,  0.0127],\n",
       "                      [-0.0167,  0.0031,  0.0167,  ..., -0.0004, -0.0119,  0.0073],\n",
       "                      [ 0.0179, -0.0021,  0.0160,  ..., -0.0198,  0.0091, -0.0002]],\n",
       "                     device='cuda:3')),\n",
       "             ('mlp.gate_proj.weight',\n",
       "              tensor([[-1.4160e-02,  1.5503e-02, -2.3071e-02,  ...,  1.3855e-02,\n",
       "                        4.3640e-03,  6.8054e-03],\n",
       "                      [-8.6212e-04,  7.7209e-03,  7.7209e-03,  ...,  1.5381e-02,\n",
       "                        7.3547e-03,  1.2207e-02],\n",
       "                      [-1.1169e-02,  2.0264e-02, -1.4099e-02,  ...,  6.4697e-03,\n",
       "                       -7.1411e-03, -9.1553e-05],\n",
       "                      ...,\n",
       "                      [ 5.4016e-03, -3.8452e-03,  2.5879e-02,  ...,  2.7161e-03,\n",
       "                        1.7700e-02,  1.7700e-02],\n",
       "                      [-1.7822e-02, -1.7822e-02,  5.0964e-03,  ...,  1.3245e-02,\n",
       "                       -8.7280e-03, -1.1108e-02],\n",
       "                      [-2.7222e-02, -2.6855e-02, -2.3560e-02,  ...,  3.6865e-02,\n",
       "                        3.9062e-02,  8.4839e-03]], device='cuda:3')),\n",
       "             ('mlp.up_proj.weight',\n",
       "              tensor([[-1.6602e-02, -2.5146e-02, -5.6152e-03,  ...,  1.8188e-02,\n",
       "                       -7.7820e-03,  9.3994e-03],\n",
       "                      [ 6.1951e-03,  1.6861e-03,  1.2390e-02,  ...,  7.6599e-03,\n",
       "                        3.4180e-02, -2.9602e-03],\n",
       "                      [ 4.8828e-03,  2.5330e-03,  5.7678e-03,  ..., -8.8501e-03,\n",
       "                        1.4343e-02, -2.2095e-02],\n",
       "                      ...,\n",
       "                      [ 2.6245e-02,  1.7929e-03,  1.8677e-02,  ...,  4.8828e-03,\n",
       "                        1.1108e-02, -3.4571e-05],\n",
       "                      [-4.8218e-03,  1.3367e-02, -8.7280e-03,  ...,  6.3171e-03,\n",
       "                        1.1292e-03,  1.1841e-02],\n",
       "                      [ 9.5825e-03, -1.3855e-02, -2.0294e-03,  ..., -4.5776e-03,\n",
       "                       -3.0670e-03, -9.1553e-03]], device='cuda:3')),\n",
       "             ('mlp.down_proj.weight',\n",
       "              tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0018,  0.0121,  0.0007],\n",
       "                      [-0.0042, -0.0064,  0.0035,  ..., -0.0035,  0.0032, -0.0089],\n",
       "                      [-0.0090, -0.0223, -0.0219,  ...,  0.0029, -0.0059, -0.0084],\n",
       "                      ...,\n",
       "                      [ 0.0126,  0.0019, -0.0042,  ..., -0.0164, -0.0074,  0.0112],\n",
       "                      [-0.0132,  0.0069,  0.0142,  ..., -0.0195,  0.0114,  0.0111],\n",
       "                      [-0.0074, -0.0138,  0.0107,  ...,  0.0106,  0.0027,  0.0029]],\n",
       "                     device='cuda:3')),\n",
       "             ('input_layernorm.weight',\n",
       "              tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008], device='cuda:3')),\n",
       "             ('post_attention_layernorm.weight',\n",
       "              tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258], device='cuda:3'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[31].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outlayers[0].load_state_dict(model.model.layers[31].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 8.3618e-03, -3.4790e-03,  7.8735e-03,  ..., -6.8665e-04,\n",
      "         -1.4114e-03, -1.9684e-03],\n",
      "        [ 3.1128e-03, -1.5717e-03,  1.3428e-02,  ..., -1.5991e-02,\n",
      "         -3.8452e-03,  1.1902e-03],\n",
      "        [ 7.1716e-03,  1.2207e-02, -1.0376e-02,  ...,  2.9504e-06,\n",
      "         -2.6733e-02,  3.2501e-03],\n",
      "        ...,\n",
      "        [-6.0425e-03,  1.6846e-02,  1.4221e-02,  ..., -1.0132e-02,\n",
      "         -1.6602e-02,  2.4048e-02],\n",
      "        [-1.7944e-02, -2.4902e-02,  1.0803e-02,  ..., -3.4424e-02,\n",
      "          2.3956e-03, -2.2217e-02],\n",
      "        [-3.8757e-03, -1.7090e-02,  1.1414e-02,  ...,  2.1973e-03,\n",
      "         -5.9891e-04, -6.9427e-04]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0126, -0.0272,  0.0303,  ...,  0.0481, -0.0062,  0.0065],\n",
      "        [-0.0266, -0.0155, -0.0435,  ..., -0.0216, -0.0515,  0.0091],\n",
      "        [ 0.0107,  0.0070,  0.0159,  ..., -0.0048, -0.0025, -0.0025],\n",
      "        ...,\n",
      "        [-0.0197,  0.0422, -0.0142,  ..., -0.0164, -0.0437,  0.0079],\n",
      "        [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
      "        [-0.0092,  0.0048,  0.0143,  ..., -0.0170, -0.0391,  0.0198]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0171,  0.0178, -0.0027,  ..., -0.0255, -0.0188,  0.0130],\n",
      "        [-0.0052,  0.0041, -0.0131,  ..., -0.0074,  0.0082, -0.0030],\n",
      "        [-0.0427, -0.0253, -0.0144,  ..., -0.0292,  0.0300, -0.0129],\n",
      "        ...,\n",
      "        [ 0.0076,  0.0003, -0.0002,  ...,  0.0096, -0.0047, -0.0043],\n",
      "        [-0.0016, -0.0041, -0.0073,  ..., -0.0107, -0.0015, -0.0214],\n",
      "        [-0.0231,  0.0022,  0.0057,  ...,  0.0069, -0.0096, -0.0069]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0199, -0.0128, -0.0223,  ...,  0.0118, -0.0031,  0.0134],\n",
      "        [ 0.0003, -0.0035, -0.0044,  ...,  0.0014, -0.0001,  0.0105],\n",
      "        [-0.0073,  0.0129, -0.0082,  ..., -0.0009,  0.0072, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0116, -0.0045,  ..., -0.0007, -0.0011,  0.0127],\n",
      "        [-0.0167,  0.0031,  0.0167,  ..., -0.0004, -0.0119,  0.0073],\n",
      "        [ 0.0179, -0.0021,  0.0160,  ..., -0.0198,  0.0091, -0.0002]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.4160e-02,  1.5503e-02, -2.3071e-02,  ...,  1.3855e-02,\n",
      "          4.3640e-03,  6.8054e-03],\n",
      "        [-8.6212e-04,  7.7209e-03,  7.7209e-03,  ...,  1.5381e-02,\n",
      "          7.3547e-03,  1.2207e-02],\n",
      "        [-1.1169e-02,  2.0264e-02, -1.4099e-02,  ...,  6.4697e-03,\n",
      "         -7.1411e-03, -9.1553e-05],\n",
      "        ...,\n",
      "        [ 5.4016e-03, -3.8452e-03,  2.5879e-02,  ...,  2.7161e-03,\n",
      "          1.7700e-02,  1.7700e-02],\n",
      "        [-1.7822e-02, -1.7822e-02,  5.0964e-03,  ...,  1.3245e-02,\n",
      "         -8.7280e-03, -1.1108e-02],\n",
      "        [-2.7222e-02, -2.6855e-02, -2.3560e-02,  ...,  3.6865e-02,\n",
      "          3.9062e-02,  8.4839e-03]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.6602e-02, -2.5146e-02, -5.6152e-03,  ...,  1.8188e-02,\n",
      "         -7.7820e-03,  9.3994e-03],\n",
      "        [ 6.1951e-03,  1.6861e-03,  1.2390e-02,  ...,  7.6599e-03,\n",
      "          3.4180e-02, -2.9602e-03],\n",
      "        [ 4.8828e-03,  2.5330e-03,  5.7678e-03,  ..., -8.8501e-03,\n",
      "          1.4343e-02, -2.2095e-02],\n",
      "        ...,\n",
      "        [ 2.6245e-02,  1.7929e-03,  1.8677e-02,  ...,  4.8828e-03,\n",
      "          1.1108e-02, -3.4571e-05],\n",
      "        [-4.8218e-03,  1.3367e-02, -8.7280e-03,  ...,  6.3171e-03,\n",
      "          1.1292e-03,  1.1841e-02],\n",
      "        [ 9.5825e-03, -1.3855e-02, -2.0294e-03,  ..., -4.5776e-03,\n",
      "         -3.0670e-03, -9.1553e-03]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0018,  0.0121,  0.0007],\n",
      "        [-0.0042, -0.0064,  0.0035,  ..., -0.0035,  0.0032, -0.0089],\n",
      "        [-0.0090, -0.0223, -0.0219,  ...,  0.0029, -0.0059, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0019, -0.0042,  ..., -0.0164, -0.0074,  0.0112],\n",
      "        [-0.0132,  0.0069,  0.0142,  ..., -0.0195,  0.0114,  0.0111],\n",
      "        [-0.0074, -0.0138,  0.0107,  ...,  0.0106,  0.0027,  0.0029]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008], device='cuda:3',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258], device='cuda:3',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.outlayers.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 8.3618e-03, -3.4790e-03,  7.8735e-03,  ..., -6.8665e-04,\n",
      "         -1.4114e-03, -1.9684e-03],\n",
      "        [ 3.1128e-03, -1.5717e-03,  1.3428e-02,  ..., -1.5991e-02,\n",
      "         -3.8452e-03,  1.1902e-03],\n",
      "        [ 7.1716e-03,  1.2207e-02, -1.0376e-02,  ...,  2.9504e-06,\n",
      "         -2.6733e-02,  3.2501e-03],\n",
      "        ...,\n",
      "        [-6.0425e-03,  1.6846e-02,  1.4221e-02,  ..., -1.0132e-02,\n",
      "         -1.6602e-02,  2.4048e-02],\n",
      "        [-1.7944e-02, -2.4902e-02,  1.0803e-02,  ..., -3.4424e-02,\n",
      "          2.3956e-03, -2.2217e-02],\n",
      "        [-3.8757e-03, -1.7090e-02,  1.1414e-02,  ...,  2.1973e-03,\n",
      "         -5.9891e-04, -6.9427e-04]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0126, -0.0272,  0.0303,  ...,  0.0481, -0.0062,  0.0065],\n",
      "        [-0.0266, -0.0155, -0.0435,  ..., -0.0216, -0.0515,  0.0091],\n",
      "        [ 0.0107,  0.0070,  0.0159,  ..., -0.0048, -0.0025, -0.0025],\n",
      "        ...,\n",
      "        [-0.0197,  0.0422, -0.0142,  ..., -0.0164, -0.0437,  0.0079],\n",
      "        [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
      "        [-0.0092,  0.0048,  0.0143,  ..., -0.0170, -0.0391,  0.0198]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0171,  0.0178, -0.0027,  ..., -0.0255, -0.0188,  0.0130],\n",
      "        [-0.0052,  0.0041, -0.0131,  ..., -0.0074,  0.0082, -0.0030],\n",
      "        [-0.0427, -0.0253, -0.0144,  ..., -0.0292,  0.0300, -0.0129],\n",
      "        ...,\n",
      "        [ 0.0076,  0.0003, -0.0002,  ...,  0.0096, -0.0047, -0.0043],\n",
      "        [-0.0016, -0.0041, -0.0073,  ..., -0.0107, -0.0015, -0.0214],\n",
      "        [-0.0231,  0.0022,  0.0057,  ...,  0.0069, -0.0096, -0.0069]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0199, -0.0128, -0.0223,  ...,  0.0118, -0.0031,  0.0134],\n",
      "        [ 0.0003, -0.0035, -0.0044,  ...,  0.0014, -0.0001,  0.0105],\n",
      "        [-0.0073,  0.0129, -0.0082,  ..., -0.0009,  0.0072, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0116, -0.0045,  ..., -0.0007, -0.0011,  0.0127],\n",
      "        [-0.0167,  0.0031,  0.0167,  ..., -0.0004, -0.0119,  0.0073],\n",
      "        [ 0.0179, -0.0021,  0.0160,  ..., -0.0198,  0.0091, -0.0002]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.4160e-02,  1.5503e-02, -2.3071e-02,  ...,  1.3855e-02,\n",
      "          4.3640e-03,  6.8054e-03],\n",
      "        [-8.6212e-04,  7.7209e-03,  7.7209e-03,  ...,  1.5381e-02,\n",
      "          7.3547e-03,  1.2207e-02],\n",
      "        [-1.1169e-02,  2.0264e-02, -1.4099e-02,  ...,  6.4697e-03,\n",
      "         -7.1411e-03, -9.1553e-05],\n",
      "        ...,\n",
      "        [ 5.4016e-03, -3.8452e-03,  2.5879e-02,  ...,  2.7161e-03,\n",
      "          1.7700e-02,  1.7700e-02],\n",
      "        [-1.7822e-02, -1.7822e-02,  5.0964e-03,  ...,  1.3245e-02,\n",
      "         -8.7280e-03, -1.1108e-02],\n",
      "        [-2.7222e-02, -2.6855e-02, -2.3560e-02,  ...,  3.6865e-02,\n",
      "          3.9062e-02,  8.4839e-03]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.6602e-02, -2.5146e-02, -5.6152e-03,  ...,  1.8188e-02,\n",
      "         -7.7820e-03,  9.3994e-03],\n",
      "        [ 6.1951e-03,  1.6861e-03,  1.2390e-02,  ...,  7.6599e-03,\n",
      "          3.4180e-02, -2.9602e-03],\n",
      "        [ 4.8828e-03,  2.5330e-03,  5.7678e-03,  ..., -8.8501e-03,\n",
      "          1.4343e-02, -2.2095e-02],\n",
      "        ...,\n",
      "        [ 2.6245e-02,  1.7929e-03,  1.8677e-02,  ...,  4.8828e-03,\n",
      "          1.1108e-02, -3.4571e-05],\n",
      "        [-4.8218e-03,  1.3367e-02, -8.7280e-03,  ...,  6.3171e-03,\n",
      "          1.1292e-03,  1.1841e-02],\n",
      "        [ 9.5825e-03, -1.3855e-02, -2.0294e-03,  ..., -4.5776e-03,\n",
      "         -3.0670e-03, -9.1553e-03]], device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0018,  0.0121,  0.0007],\n",
      "        [-0.0042, -0.0064,  0.0035,  ..., -0.0035,  0.0032, -0.0089],\n",
      "        [-0.0090, -0.0223, -0.0219,  ...,  0.0029, -0.0059, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0019, -0.0042,  ..., -0.0164, -0.0074,  0.0112],\n",
      "        [-0.0132,  0.0069,  0.0142,  ..., -0.0195,  0.0114,  0.0111],\n",
      "        [-0.0074, -0.0138,  0.0107,  ...,  0.0106,  0.0027,  0.0029]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008], device='cuda:3',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258], device='cuda:3',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.outlayers.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j9Ubd2DVAOW"
   },
   "source": [
    "### Load the tokenizer\n",
    "\n",
    "#### Since LLAMA3 pre-training doesn't have EOS token\n",
    "* Set the pad_token_id to eos_token_id\n",
    "* Set pad token ot eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "42a51c892624492a866e464c097cbdaf",
      "49d7855e5b224ed6a4917b2a55815bbb",
      "1d92eeaace3e41d3975b52aa03e374ca",
      "e58dabd441b14f4aafda2830c9446ac6",
      "0e614e25f1704d9695bc6f1abf253e02",
      "7c49cfcdeabb46ba873ca43542a3382c",
      "ddd49b4c0b82453ebde671025ef535ab",
      "b1b5c6e8419a4ff5ba14a17d990ac38e",
      "b8c8a96600d04722a75ea14a891fc194",
      "5f0844fe920e458a8eaa1a7ee1c8dd71",
      "89469d75cb0c45549c3b03a1984f898a",
      "be6f22366fc8438dbbccf600149d6f0d",
      "9189bc0b83b14ce6b3b216092aa25978",
      "572b81f10a6d47e6bd8bff73c63c9880",
      "368880e7312540b195eb1a6f06f6f910",
      "437afb8ae45840d29e2e7aed5cdb88a1",
      "51c4812edc07486b83d4a386c79d1450",
      "e76203fdd5f8498aa20e46de395b6880",
      "9a41053fd34243899f46b2dd76bcadcd",
      "69c134844e3f4ff7b04e6b7f6c646a82",
      "af580ea95446412185d0c1d82c4efcaa",
      "45b5c91a0747477aaf34b651a00bab9a",
      "c5f372bb9112428293bb7fd895dc9280",
      "1554cf5f5f84430abb74d6300a9cf6b1",
      "186ea7fd18a841bbaaed69d7881bac9f",
      "700206a3a8d845d6a08e2a2ae91aaedb",
      "711c5c0af6ef462c922f7cd89ca0e633",
      "0510e21ca4c14617a76b2f77f5683b0c",
      "e8d06ae113094a8e8f1946c60dc85a37",
      "69299a0e13344310a70ea9529de8a04a",
      "ae66c264b87e48d6a6fea43d5a08bee9",
      "b35e68194ef64fcd8ecc99d05f3ed8fd",
      "eb066f1351b24551a92e912a1a42a47b"
     ]
    },
    "gather": {
     "logged": 1720054675017
    },
    "id": "DzS5OhVO8Tuo",
    "outputId": "701c9055-2b25-425d-c5cd-ec39e3cb5ac0"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akDra1649hcn"
   },
   "source": [
    "#### Update some model configs\n",
    "* Must use .cache = False as below or it crashes from my experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1720058012627
    },
    "id": "XBFCNrrE9hAR"
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aM2eCK47kf2"
   },
   "source": [
    "# Trainer Components\n",
    "* model\n",
    "* tokenizer\n",
    "* training arguments\n",
    "* train dataset\n",
    "* eval dataset\n",
    "* Data Collater\n",
    "* Compute Metrics\n",
    "* class_weights: In our case since we are using a custom trainer so we can use a weighted loss we will subclass trainer and define the custom loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQCINMPIVgvS"
   },
   "source": [
    "#### Create LLAMA tokenized dataset which will house our train/val parts during the training process but after applying tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "8c130497475546e685db1b7d193e3258",
      "43cb89109de14d26a661110d29b08532",
      "e2c473a3ac8b4d369256ab0b7184043d",
      "e7f583fe5f6640799ba5686fc3d7f7c4",
      "7b66df957ac3466bb659e54319e0603f",
      "44c0a61594fd49e79952d8543ac3ba0d",
      "1e0e41b44dff40ba8f918fbf55a6f975",
      "60449fba179b4d86b48e0bb7b9022e2b",
      "435eca0c7f604c1abbbbc71265571be6",
      "bf58bc0260724bfcbe97be7e8602c89b",
      "c5a75440ec6243bba1f5134844f735ca",
      "6afd13779f44436fb28b35a3e493dc39",
      "28c7354a06a84f0faed3213ffcc40e6a",
      "0330f298c23846ea8a606632b929ee21",
      "4bef9665443b4c468b262f2cbbdeef76",
      "05e24f26d03a4cd39473c16c48851afc",
      "e16caa2c30754ad5ab09ef48438f9035",
      "2c30f545c45345da861029e015ff9845",
      "861899abe6ad46f4b68ddee5e430fd6d",
      "f1e0f5cb31d34dfa91257da4a5a104df",
      "cf4aae3a8bdd4129b120c50165b47995",
      "dd450fadac8d4f0c8240fb2f481bb361"
     ]
    },
    "gather": {
     "logged": 1720058030896
    },
    "id": "MJ8t0ZtVVfPv",
    "outputId": "00efe238-941a-4c47-e52f-db0054fa18ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571ef9c8229f4cc787b927a56cce7258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f533587dc90b402db27cfba7eab5d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7295 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "col_to_delete = ['id', 'anchor', 'context', 'target']\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['input'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"score_category\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFMAsvJFVlMc"
   },
   "source": [
    "## Data Collator\n",
    "A **data collator** prepares batches of data for training or inference in machine learning, ensuring uniform formatting and adherence to model input requirements. This is especially crucial for variable-sized inputs like text sequences.\n",
    "\n",
    "### Functions of Data Collator\n",
    "\n",
    "1. **Padding:** Uniformly pads sequences to the length of the longest sequence using a special token, allowing simultaneous batch processing.\n",
    "2. **Batching:** Groups individual data points into batches for efficient processing.\n",
    "3. **Handling Special Tokens:** Adds necessary special tokens to sequences.\n",
    "4. **Converting to Tensor:** Transforms data into tensors, the required format for machine learning frameworks.\n",
    "\n",
    "### `DataCollatorWithPadding`\n",
    "\n",
    "The `DataCollatorWithPadding` specifically manages padding, using a tokenizer to ensure that all sequences are padded to the same length for consistent model input.\n",
    "\n",
    "- **Syntax:** `collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)`\n",
    "- **Purpose:** Automatically pads text data to the longest sequence in a batch, crucial for models like BERT or GPT.\n",
    "- **Tokenizer:** Uses the provided `tokenizer` for sequence processing, respecting model-specific vocabulary and formatting rules.\n",
    "\n",
    "This collator is commonly used with libraries like Hugging Face's Transformers, facilitating data preprocessing for various NLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1720058033937
    },
    "id": "XfpRu7l5Vjx9"
   },
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHh8YAiqVu06"
   },
   "source": [
    "# define which metrics to compute for evaluation\n",
    "* We will use balanced accuracy and accuracy for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1720058039266
    },
    "id": "F3fjS8YO4do1"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    try:\n",
    "        # it's a classification task, take the argmax\n",
    "        predictions_processed = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson, _ = pearsonr(predictions_processed, labels)\n",
    "\n",
    "        return {'pearson': pearson}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_metrics: {e}\")\n",
    "        return {'pearson': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IKaB5d6Wbni"
   },
   "source": [
    "### Define custom trainer with classweights\n",
    "* We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gather": {
     "logged": 1720058045595
    },
    "id": "wc4zAX1iXvDD"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfFh6JMw8y7E"
   },
   "source": [
    "# define training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1720058048519
    },
    "id": "5AET29lE9qqw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotech/venv-llama/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'sequence_classification',\n",
    "    learning_rate = 1e-3,\n",
    "    #lr_scheduler_type = 'cosine',\n",
    "    lr_scheduler_type = 'polynomial',\n",
    "    lr_scheduler_kwargs = { 'power': 2, 'lr_end': 1e-5 },\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 15,\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyDI7Wm89-0p"
   },
   "source": [
    "#### Define custom trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720058051324
    },
    "id": "BGHhP9R09rUR",
    "outputId": "11ec6bdf-045a-4aa9-aba6-3551230ffe4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63478/37245773.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/tmp/ipykernel_63478/37245773.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['val'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCN4zFN0fRpJ"
   },
   "source": [
    "* https://huggingface.co/docs/transformers/en/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tIQ3lxk-BLL"
   },
   "source": [
    "### Run trainer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msdfsdfrr\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kotech/workspace/webstudy/deep/llama/wandb/run-20250327_163729-ejtmp96k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sdfsdfrr/huggingface/runs/ejtmp96k' target=\"_blank\">sequence_classification</a></strong> to <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sdfsdfrr/huggingface/runs/ejtmp96k' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface/runs/ejtmp96k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48928' max='54720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48928/54720 3:42:31 < 26:20, 3.66 it/s, Epoch 13.41/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.582400</td>\n",
       "      <td>1.543643</td>\n",
       "      <td>0.399051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.305000</td>\n",
       "      <td>1.196669</td>\n",
       "      <td>0.567383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.190300</td>\n",
       "      <td>1.173575</td>\n",
       "      <td>0.588461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.103700</td>\n",
       "      <td>1.199388</td>\n",
       "      <td>0.618502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.048600</td>\n",
       "      <td>1.069140</td>\n",
       "      <td>0.656459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>0.975858</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>0.679241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.998553</td>\n",
       "      <td>0.700248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.676203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.987652</td>\n",
       "      <td>0.694850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.802600</td>\n",
       "      <td>0.963616</td>\n",
       "      <td>0.696346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.764700</td>\n",
       "      <td>0.966824</td>\n",
       "      <td>0.699615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.982619</td>\n",
       "      <td>0.699280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15434' max='36480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15434/36480 1:13:36 < 1:40:23, 3.49 it/s, Epoch 4.23/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.359200</td>\n",
       "      <td>1.379263</td>\n",
       "      <td>0.538239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>1.203274</td>\n",
       "      <td>0.568286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.077400</td>\n",
       "      <td>1.244954</td>\n",
       "      <td>0.628035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.066500</td>\n",
       "      <td>1.141556</td>\n",
       "      <td>0.629707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:3698\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3697\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3700\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3702\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3703\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3704\u001b[39m ):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mCustomTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n\u001b[32m     12\u001b[39m labels = inputs.pop(\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m).long()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Extract logits assuming they are directly outputted by the model\u001b[39;00m\n\u001b[32m     18\u001b[39m logits = outputs.get(\u001b[33m'\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mLlamaForSequenceClassification2.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    111\u001b[39m     position_ids = cache_position.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m causal_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_update_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m#position_embeddings = self.rotary_emb(inputs_embeds, position_ids)\u001b[39;00m\n\u001b[32m    119\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:666\u001b[39m, in \u001b[36mLlamaModel._update_causal_mask\u001b[39m\u001b[34m(self, attention_mask, input_tensor, cache_position, past_key_values, output_attentions)\u001b[39m\n\u001b[32m    659\u001b[39m     target_length = (\n\u001b[32m    660\u001b[39m         attention_mask.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attention_mask, torch.Tensor)\n\u001b[32m    662\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m past_seen_tokens + sequence_length + \u001b[32m1\u001b[39m\n\u001b[32m    663\u001b[39m     )\n\u001b[32m    665\u001b[39m \u001b[38;5;66;03m# In case the provided `attention` mask is 2D, we generate a causal mask here (4D).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m causal_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_4d_causal_attention_mask_with_cache_position\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    677\u001b[39m     \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    683\u001b[39m     \u001b[38;5;66;03m# using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\u001b[39;00m\n\u001b[32m    684\u001b[39m     \u001b[38;5;66;03m# Details: https://github.com/pytorch/pytorch/issues/110213\u001b[39;00m\n\u001b[32m    685\u001b[39m     min_dtype = torch.finfo(dtype).min\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:690\u001b[39m, in \u001b[36mLlamaModel._prepare_4d_causal_attention_mask_with_cache_position\u001b[39m\u001b[34m(attention_mask, sequence_length, target_length, dtype, device, cache_position, batch_size, **kwargs)\u001b[39m\n\u001b[32m    686\u001b[39m         causal_mask = AttentionMaskConverter._unmask_unattended(causal_mask, min_dtype)\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m causal_mask\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_4d_causal_attention_mask_with_cache_position\u001b[39m(\n\u001b[32m    692\u001b[39m     attention_mask: torch.Tensor,\n\u001b[32m    693\u001b[39m     sequence_length: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    694\u001b[39m     target_length: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    695\u001b[39m     dtype: torch.dtype,\n\u001b[32m    696\u001b[39m     device: torch.device,\n\u001b[32m    697\u001b[39m     cache_position: torch.Tensor,\n\u001b[32m    698\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    699\u001b[39m     **kwargs,\n\u001b[32m    700\u001b[39m ):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    702\u001b[39m \u001b[33;03m    Creates a causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)` from a 2D mask of shape\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[33;03m    `(batch_size, key_value_length)`, or if the input `attention_mask` is already 4D, do nothing.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    721\u001b[39m \u001b[33;03m            Batch size.\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.dim() == \u001b[32m4\u001b[39m:\n\u001b[32m    724\u001b[39m         \u001b[38;5;66;03m# In this case we assume that the mask comes already in inverted form and requires no inversion or slicing.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7297' max='36480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7297/36480 30:07 < 2:00:29, 4.04 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>1.012215</td>\n",
       "      <td>0.680267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.997269</td>\n",
       "      <td>0.686252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:2639\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2636\u001b[39m     \u001b[38;5;28mself\u001b[39m.control.should_training_stop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2638\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_epoch_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2639\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DebugOption.TPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.debug:\n\u001b[32m   2642\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[32m   2643\u001b[39m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:3092\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[39m\n\u001b[32m   3089\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3092\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3093\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:3190\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3188\u001b[39m run_dir = \u001b[38;5;28mself\u001b[39m._get_output_dir(trial=trial)\n\u001b[32m   3189\u001b[39m output_dir = os.path.join(run_dir, checkpoint_folder)\n\u001b[32m-> \u001b[39m\u001b[32m3190\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3193\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m   3194\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_optimizer_and_scheduler(output_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:3860\u001b[39m, in \u001b[36mTrainer.save_model\u001b[39m\u001b[34m(self, output_dir, _internal_call)\u001b[39m\n\u001b[32m   3857\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_wrapped.save_checkpoint(output_dir)\n\u001b[32m   3859\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3860\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3862\u001b[39m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[32m   3863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.push_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/trainer.py:3964\u001b[39m, in \u001b[36mTrainer._save\u001b[39m\u001b[34m(self, output_dir, state_dict)\u001b[39m\n\u001b[32m   3962\u001b[39m             torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))\n\u001b[32m   3963\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3964\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_safetensors\u001b[49m\n\u001b[32m   3966\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.processing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3969\u001b[39m     \u001b[38;5;28mself\u001b[39m.processing_class.save_pretrained(output_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/transformers/modeling_utils.py:3032\u001b[39m, in \u001b[36mPreTrainedModel.save_pretrained\u001b[39m\u001b[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[39m\n\u001b[32m   3027\u001b[39m     gc.collect()\n\u001b[32m   3029\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[32m   3030\u001b[39m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[32m   3031\u001b[39m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3032\u001b[39m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3034\u001b[39m     save_function(shard, os.path.join(save_directory, shard_file))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv-llama/lib/python3.11/site-packages/safetensors/torch.py:286\u001b[39m, in \u001b[36msave_file\u001b[39m\u001b[34m(tensors, filename, metadata)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_file\u001b[39m(\n\u001b[32m    256\u001b[39m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor],\n\u001b[32m    257\u001b[39m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    258\u001b[39m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    259\u001b[39m ):\n\u001b[32m    260\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[32m    262\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msdfsdfrr\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kotech/workspace/webstudy/deep/llama/wandb/run-20250320_140440-qyt3m7eu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sdfsdfrr/huggingface/runs/qyt3m7eu' target=\"_blank\">sequence_classification</a></strong> to <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sdfsdfrr/huggingface/runs/qyt3m7eu' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface/runs/qyt3m7eu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7297' max='7296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7296/7296 26:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.131200</td>\n",
       "      <td>1.778230</td>\n",
       "      <td>0.561356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.015300</td>\n",
       "      <td>1.050993</td>\n",
       "      <td>0.662856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "gather": {
     "logged": 1720083063898
    },
    "id": "qLXOgM0FkaKE",
    "outputId": "790c4686-dfbe-47b3-f962-93b0f0819e5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msdfsdfrr\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kotech/workspace/webstudy/deep/llama/wandb/run-20250320_125650-jnxx72mr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sdfsdfrr/huggingface/runs/jnxx72mr' target=\"_blank\">sequence_classification</a></strong> to <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sdfsdfrr/huggingface' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sdfsdfrr/huggingface/runs/jnxx72mr' target=\"_blank\">https://wandb.ai/sdfsdfrr/huggingface/runs/jnxx72mr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7296' max='7296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7296/7296 32:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.310500</td>\n",
       "      <td>1.272402</td>\n",
       "      <td>0.505867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.118400</td>\n",
       "      <td>1.191806</td>\n",
       "      <td>0.541483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSTf1TMf8NpC"
   },
   "source": [
    "#### Let's check the results\n",
    "* I wrapped in a function a convenient way add the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "gather": {
     "logged": 1720086869288
    },
    "id": "uxIXBpIHeWKc"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, df):\n",
    "\n",
    "\n",
    "  # Convert summaries to a list\n",
    "  sentences = df.input.tolist()\n",
    "\n",
    "  # Define the batch size\n",
    "  batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "  # Initialize an empty list to store the model outputs\n",
    "  all_outputs = []\n",
    "\n",
    "  # Process the sentences in batches\n",
    "  for i in range(0, len(sentences), batch_size):\n",
    "      # Get the batch of sentences\n",
    "      batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "      # Tokenize the batch\n",
    "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "      # Perform inference and store the logits\n",
    "      with torch.no_grad():\n",
    "          outputs = model(**inputs)\n",
    "          all_outputs.append(outputs['logits'])\n",
    "\n",
    "  final_outputs = torch.cat(all_outputs, dim=0)\n",
    "  df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "  df['predictions']=df['predictions'].apply(lambda l:category_map[l])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPokM-op4ZZF"
   },
   "source": [
    "### Analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "gather": {
     "logged": 1720057866926
    },
    "id": "ZJ3eFsPz4Hd9"
   },
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "  y_test = df_test.score.round()\n",
    "  y_pred = df_test.predictions.round()\n",
    "  print(f\"comparing test {y_test} and pred {y_pred}\")\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "gather": {
     "logged": 1720088040819
    },
    "id": "hrPwJ-RSsTXd",
    "outputId": "d39716b6-81f3-4c11-ffb5-5652d7068c3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing test 33511    0.0\n",
      "18670    0.0\n",
      "18049    0.0\n",
      "31660    1.0\n",
      "15573    0.0\n",
      "        ... \n",
      "5040     0.0\n",
      "33907    1.0\n",
      "9090     0.0\n",
      "25999    0.0\n",
      "22135    0.0\n",
      "Name: score, Length: 7295, dtype: float64 and pred 33511    0.0\n",
      "18670    0.0\n",
      "18049    0.0\n",
      "31660    0.0\n",
      "15573    0.0\n",
      "        ... \n",
      "5040     0.0\n",
      "33907    1.0\n",
      "9090     0.0\n",
      "25999    0.0\n",
      "22135    0.0\n",
      "Name: predictions, Length: 7295, dtype: float64\n",
      "Confusion Matrix:\n",
      "[[5465  779]\n",
      " [ 306  745]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91      6244\n",
      "         1.0       0.49      0.71      0.58      1051\n",
      "\n",
      "    accuracy                           0.85      7295\n",
      "   macro avg       0.72      0.79      0.74      7295\n",
      "weighted avg       0.88      0.85      0.86      7295\n",
      "\n",
      "Balanced Accuracy Score: 0.7920444730652179\n",
      "Accuracy Score: 0.8512679917751885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>input</th>\n",
       "      <th>score_ascat</th>\n",
       "      <th>score_category</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>ed1c4e525eb105fe</td>\n",
       "      <td>transmit alarm</td>\n",
       "      <td>display indicator</td>\n",
       "      <td>G08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXT1: G08; TEXT2: display indicator; ANC1: tr...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>5386316f318f5221</td>\n",
       "      <td>locking formation</td>\n",
       "      <td>retaining element</td>\n",
       "      <td>B60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: B60; TEXT2: retaining element; ANC1: lo...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>1544ca6753fcbddd</td>\n",
       "      <td>lateral power</td>\n",
       "      <td>transducer</td>\n",
       "      <td>H01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: H01; TEXT2: transducer; ANC1: lateral p...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>f9d8979b94cec923</td>\n",
       "      <td>spreader body</td>\n",
       "      <td>spreader</td>\n",
       "      <td>A01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>TEXT1: A01; TEXT2: spreader; ANC1: spreader body</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15573</th>\n",
       "      <td>e151ca5ea5cc0f08</td>\n",
       "      <td>high gradient magnetic separators</td>\n",
       "      <td>magnetic filtration</td>\n",
       "      <td>B03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: B03; TEXT2: magnetic filtration; ANC1: ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>f297c5e94dd07e6e</td>\n",
       "      <td>cervical support</td>\n",
       "      <td>gel pack</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: A47; TEXT2: gel pack; ANC1: cervical su...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33907</th>\n",
       "      <td>06779da2bf614d00</td>\n",
       "      <td>trommel screen</td>\n",
       "      <td>trommel screen</td>\n",
       "      <td>B03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>TEXT1: B03; TEXT2: trommel screen; ANC1: tromm...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>ed6245a94e7e5a77</td>\n",
       "      <td>different conductivity</td>\n",
       "      <td>conductive</td>\n",
       "      <td>H03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: H03; TEXT2: conductive; ANC1: different...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25999</th>\n",
       "      <td>f93d71c0e9af4923</td>\n",
       "      <td>prolog</td>\n",
       "      <td>sliding window</td>\n",
       "      <td>H03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXT1: H03; TEXT2: sliding window; ANC1: prolog</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22135</th>\n",
       "      <td>063e67d59876e127</td>\n",
       "      <td>operator identification information</td>\n",
       "      <td>risk identification</td>\n",
       "      <td>H04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXT1: H04; TEXT2: risk identification; ANC1: ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7295 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                               anchor  \\\n",
       "33511  ed1c4e525eb105fe                       transmit alarm   \n",
       "18670  5386316f318f5221                    locking formation   \n",
       "18049  1544ca6753fcbddd                        lateral power   \n",
       "31660  f9d8979b94cec923                        spreader body   \n",
       "15573  e151ca5ea5cc0f08    high gradient magnetic separators   \n",
       "...                 ...                                  ...   \n",
       "5040   f297c5e94dd07e6e                     cervical support   \n",
       "33907  06779da2bf614d00                       trommel screen   \n",
       "9090   ed6245a94e7e5a77               different conductivity   \n",
       "25999  f93d71c0e9af4923                               prolog   \n",
       "22135  063e67d59876e127  operator identification information   \n",
       "\n",
       "                    target context  score  \\\n",
       "33511    display indicator     G08   0.00   \n",
       "18670    retaining element     B60   0.25   \n",
       "18049           transducer     H01   0.25   \n",
       "31660             spreader     A01   0.75   \n",
       "15573  magnetic filtration     B03   0.50   \n",
       "...                    ...     ...    ...   \n",
       "5040              gel pack     A47   0.25   \n",
       "33907       trommel screen     B03   1.00   \n",
       "9090            conductive     H03   0.50   \n",
       "25999       sliding window     H03   0.00   \n",
       "22135  risk identification     H04   0.00   \n",
       "\n",
       "                                                   input score_ascat  \\\n",
       "33511  TEXT1: G08; TEXT2: display indicator; ANC1: tr...        0.00   \n",
       "18670  TEXT1: B60; TEXT2: retaining element; ANC1: lo...        0.25   \n",
       "18049  TEXT1: H01; TEXT2: transducer; ANC1: lateral p...        0.25   \n",
       "31660   TEXT1: A01; TEXT2: spreader; ANC1: spreader body        0.75   \n",
       "15573  TEXT1: B03; TEXT2: magnetic filtration; ANC1: ...        0.50   \n",
       "...                                                  ...         ...   \n",
       "5040   TEXT1: A47; TEXT2: gel pack; ANC1: cervical su...        0.25   \n",
       "33907  TEXT1: B03; TEXT2: trommel screen; ANC1: tromm...        1.00   \n",
       "9090   TEXT1: H03; TEXT2: conductive; ANC1: different...        0.50   \n",
       "25999    TEXT1: H03; TEXT2: sliding window; ANC1: prolog        0.00   \n",
       "22135  TEXT1: H04; TEXT2: risk identification; ANC1: ...        0.00   \n",
       "\n",
       "       score_category  predictions  \n",
       "33511               0         0.50  \n",
       "18670               1         0.25  \n",
       "18049               1         0.25  \n",
       "31660               3         0.50  \n",
       "15573               2         0.50  \n",
       "...               ...          ...  \n",
       "5040                1         0.25  \n",
       "33907               4         1.00  \n",
       "9090                2         0.50  \n",
       "25999               0         0.50  \n",
       "22135               0         0.00  \n",
       "\n",
       "[7295 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predictions(model,df_val)\n",
    "\n",
    "get_performance_metrics(df_val)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZTHqTuPir_k"
   },
   "source": [
    "### Saving the model trainer state and model adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1720087097537
    },
    "id": "KnCfi0Z3W567",
    "outputId": "1d1bcae1-93f7-41d5-a0a3-ce68250a75a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        15.0\n",
      "  total_flos               = 387392093GF\n",
      "  train_loss               =      1.0205\n",
      "  train_runtime            =  4:13:36.48\n",
      "  train_samples            =       29178\n",
      "  train_samples_per_second =      28.763\n",
      "  train_steps_per_second   =       3.596\n"
     ]
    }
   ],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = len(dataset_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(dataset_train))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CArcZkf509Xq"
   },
   "source": [
    "#### Saving the adapter model\n",
    "* Note this doesn't save the entire model. It only saves the adapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "gather": {
     "logged": 1720087105908
    },
    "id": "AyDo4GzKaQTo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotech/venv-llama/lib/python3.11/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e8207c98-e5df-43c7-8a6b-0e072cbbaace)') - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B.\n",
      "  warnings.warn(\n",
      "/home/kotech/venv-llama/lib/python3.11/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33msequence_classification\u001b[0m at: \u001b[34mhttps://wandb.ai/sdfsdfrr/huggingface/runs/d0zscpin\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250317_171149-d0zscpin/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4JoRFNQbjxi"
   },
   "source": [
    "### Save to google drive\n",
    "Make sure before disconnecting and deleting the Colab runtime you save your model for future inference use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "5JLs0pfabl48",
    "outputId": "c849d8a7-f104-48a6-f9a2-0f2bb87e906a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7HaMw0xulhd"
   },
   "outputs": [],
   "source": [
    "!cp -r sequence_classification /content/drive/MyDrive/Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SU3i00QSuzDh"
   },
   "outputs": [],
   "source": [
    "!cp -r saved_model /content/drive/MyDrive/Colab"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernel_info": {
   "name": "custom_py311"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d3830727284700bb3d0027689683e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9dce19ac35441589f8bcee5f8c77f0f",
       "IPY_MODEL_6ac206dbfab94f5481384577c941b125",
       "IPY_MODEL_bc9c9c8c55834d95afa2ff1358dc5906"
      ],
      "layout": "IPY_MODEL_c83e62f823ef455eb45c35c5fce68dae"
     }
    },
    "031ad948be37418397f06cbf2f7eaa19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f18f2bf7ed5f4b4c9aacf141ae34d2a9",
      "placeholder": "​",
      "style": "IPY_MODEL_f209b3c55af54890b110e49760eaf6f0",
      "value": " 4.92G/4.92G [00:19&lt;00:00, 309MB/s]"
     }
    },
    "0330f298c23846ea8a606632b929ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_861899abe6ad46f4b68ddee5e430fd6d",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1e0f5cb31d34dfa91257da4a5a104df",
      "value": 20
     }
    },
    "0495f42403f440a5b589ed4b39c27e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0510e21ca4c14617a76b2f77f5683b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0560c42edd444e6cbf857665f24207b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05e24f26d03a4cd39473c16c48851afc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a2c6d42c43948acaec95f97de0cf7ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4097d35df75f42c38e60100f5ed5ba00",
      "max": 1168138808,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83f162c9af04440a93aa19aeb58efbde",
      "value": 1168138808
     }
    },
    "0bbee1644fd942ba84d79581cdbe16e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e614e25f1704d9695bc6f1abf253e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e7bfb272af3480e9384f56b892fec47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4eacc874a6049c38b1989b6229b5954",
      "placeholder": "​",
      "style": "IPY_MODEL_e0544d43054549af9272caafb43c1aaa",
      "value": "config.json: 100%"
     }
    },
    "11be9dd298754155ac5521ad4341d6a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12f2a80a725548e1b4a448ff5cf3c6b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9f48e5ed19140ec96b3681e30f71292",
      "placeholder": "​",
      "style": "IPY_MODEL_6e7cbd8115d645e292b219bb0bbf8fe1",
      "value": "model-00004-of-00004.safetensors: 100%"
     }
    },
    "1554cf5f5f84430abb74d6300a9cf6b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0510e21ca4c14617a76b2f77f5683b0c",
      "placeholder": "​",
      "style": "IPY_MODEL_e8d06ae113094a8e8f1946c60dc85a37",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "186ea7fd18a841bbaaed69d7881bac9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69299a0e13344310a70ea9529de8a04a",
      "max": 73,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae66c264b87e48d6a6fea43d5a08bee9",
      "value": 73
     }
    },
    "1d92eeaace3e41d3975b52aa03e374ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1b5c6e8419a4ff5ba14a17d990ac38e",
      "max": 50566,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8c8a96600d04722a75ea14a891fc194",
      "value": 50566
     }
    },
    "1e0e41b44dff40ba8f918fbf55a6f975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f534ef0bb5e4fcfb7398e1cb628ac42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21b77dc7dac245858176d38860ae10cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24c365ce42a2473ea86e9a3ff3b4bbdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf28511f878b4402a3d1ec95944ed38c",
      "max": 4915916176,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6280494fe6974847ad497587d378523e",
      "value": 4915916176
     }
    },
    "27cb423a33794a2fb329a0265856fce1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c7354a06a84f0faed3213ffcc40e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e16caa2c30754ad5ab09ef48438f9035",
      "placeholder": "​",
      "style": "IPY_MODEL_2c30f545c45345da861029e015ff9845",
      "value": "Map: 100%"
     }
    },
    "29d5da530e0d4f078dd2dd1967e9e6a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c016d643bf6480c9411f88e751063b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c30f545c45345da861029e015ff9845": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cbb7ecb92a64db89d59f0bbaada569c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_328e749dadc94bd689c5257716b1e267",
      "max": 4976698672,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9d266bc194c44dcbdbc12b51daff386",
      "value": 4976698672
     }
    },
    "2d0cab209a1d4b6195d72e5fc906567e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "328e749dadc94bd689c5257716b1e267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "368880e7312540b195eb1a6f06f6f910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af580ea95446412185d0c1d82c4efcaa",
      "placeholder": "​",
      "style": "IPY_MODEL_45b5c91a0747477aaf34b651a00bab9a",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 14.2MB/s]"
     }
    },
    "3b84c5d287db40a09845d2615fd18e10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ea6cac855db48aebdc66b0328486a7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f30159710bf490db518adc57c2cbf0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf84a617bc6b4f5dae1c0648f8c969b1",
      "placeholder": "​",
      "style": "IPY_MODEL_21b77dc7dac245858176d38860ae10cd",
      "value": " 4.98G/4.98G [00:17&lt;00:00, 346MB/s]"
     }
    },
    "4097d35df75f42c38e60100f5ed5ba00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42a51c892624492a866e464c097cbdaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49d7855e5b224ed6a4917b2a55815bbb",
       "IPY_MODEL_1d92eeaace3e41d3975b52aa03e374ca",
       "IPY_MODEL_e58dabd441b14f4aafda2830c9446ac6"
      ],
      "layout": "IPY_MODEL_0e614e25f1704d9695bc6f1abf253e02"
     }
    },
    "435eca0c7f604c1abbbbc71265571be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "437afb8ae45840d29e2e7aed5cdb88a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43cb89109de14d26a661110d29b08532": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44c0a61594fd49e79952d8543ac3ba0d",
      "placeholder": "​",
      "style": "IPY_MODEL_1e0e41b44dff40ba8f918fbf55a6f975",
      "value": "Map: 100%"
     }
    },
    "44c0a61594fd49e79952d8543ac3ba0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45b5c91a0747477aaf34b651a00bab9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49d7855e5b224ed6a4917b2a55815bbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c49cfcdeabb46ba873ca43542a3382c",
      "placeholder": "​",
      "style": "IPY_MODEL_ddd49b4c0b82453ebde671025ef535ab",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4a50cdc6ba00447e9a272e106cdf0b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c53d928e8444ceb88ce3baad0462aa7",
       "IPY_MODEL_9c6db2d631944b83a9ed1b3224de2d4a",
       "IPY_MODEL_7974731eb1c14344b82a78dad06f95a7"
      ],
      "layout": "IPY_MODEL_fca39da904da4d249964985162897242"
     }
    },
    "4bef9665443b4c468b262f2cbbdeef76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf4aae3a8bdd4129b120c50165b47995",
      "placeholder": "​",
      "style": "IPY_MODEL_dd450fadac8d4f0c8240fb2f481bb361",
      "value": " 20/20 [00:00&lt;00:00, 1008.21 examples/s]"
     }
    },
    "4c53d928e8444ceb88ce3baad0462aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77c8b02ac50d40b18bfb7e03995044b3",
      "placeholder": "​",
      "style": "IPY_MODEL_0bbee1644fd942ba84d79581cdbe16e1",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "4ca85e56a8064d0d8bc1740e2559827d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f958021df09474fbe60c8830ccc4810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9d5df847f5e40d5be45f7ad24ad23fb",
      "placeholder": "​",
      "style": "IPY_MODEL_4ca85e56a8064d0d8bc1740e2559827d",
      "value": "model-00003-of-00004.safetensors: 100%"
     }
    },
    "50c59fccba734f8b9de37b6f6ef28cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aeb45a4f8d14487bfd598eb071876dc",
      "placeholder": "​",
      "style": "IPY_MODEL_9622056982814fe48e3d1a23d6311011",
      "value": " 5.00G/5.00G [00:17&lt;00:00, 438MB/s]"
     }
    },
    "51c4812edc07486b83d4a386c79d1450": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "572b81f10a6d47e6bd8bff73c63c9880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a41053fd34243899f46b2dd76bcadcd",
      "max": 9085698,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69c134844e3f4ff7b04e6b7f6c646a82",
      "value": 9085698
     }
    },
    "5f0844fe920e458a8eaa1a7ee1c8dd71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60449fba179b4d86b48e0bb7b9022e2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60f421ee47854b37a58f0cbea78eb474": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc911804053e44f98215ae7bef27e206",
       "IPY_MODEL_86a059793efc4567a66a12277b7f5dc4",
       "IPY_MODEL_ae8454dfa7da4ac2a63a36eaddf04359"
      ],
      "layout": "IPY_MODEL_29d5da530e0d4f078dd2dd1967e9e6a2"
     }
    },
    "6280494fe6974847ad497587d378523e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "630d6c2edaa34ff4820b0f3cbc776eda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69299a0e13344310a70ea9529de8a04a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69c134844e3f4ff7b04e6b7f6c646a82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6ac206dbfab94f5481384577c941b125": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4fc63186a1741a192548b27ddcfa35b",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b000d0fa59b64669a1302972ac8fbbf7",
      "value": 4
     }
    },
    "6afd13779f44436fb28b35a3e493dc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28c7354a06a84f0faed3213ffcc40e6a",
       "IPY_MODEL_0330f298c23846ea8a606632b929ee21",
       "IPY_MODEL_4bef9665443b4c468b262f2cbbdeef76"
      ],
      "layout": "IPY_MODEL_05e24f26d03a4cd39473c16c48851afc"
     }
    },
    "6e7cbd8115d645e292b219bb0bbf8fe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f04b99a7732436c95a44819400de789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7cddf4af8ea485aa3e893af5dd365cb",
       "IPY_MODEL_2cbb7ecb92a64db89d59f0bbaada569c",
       "IPY_MODEL_3f30159710bf490db518adc57c2cbf0c"
      ],
      "layout": "IPY_MODEL_aecf9dd24860401e88f7f56b208bab46"
     }
    },
    "700206a3a8d845d6a08e2a2ae91aaedb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b35e68194ef64fcd8ecc99d05f3ed8fd",
      "placeholder": "​",
      "style": "IPY_MODEL_eb066f1351b24551a92e912a1a42a47b",
      "value": " 73.0/73.0 [00:00&lt;00:00, 6.33kB/s]"
     }
    },
    "711c5c0af6ef462c922f7cd89ca0e633": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77c8b02ac50d40b18bfb7e03995044b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7974731eb1c14344b82a78dad06f95a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f6760d652ec419f967c8f8f1fad471a",
      "placeholder": "​",
      "style": "IPY_MODEL_1f534ef0bb5e4fcfb7398e1cb628ac42",
      "value": " 23.9k/23.9k [00:00&lt;00:00, 1.35MB/s]"
     }
    },
    "7b66df957ac3466bb659e54319e0603f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c49cfcdeabb46ba873ca43542a3382c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83f162c9af04440a93aa19aeb58efbde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83f3dfc8d5984267b224c27f489177e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f350094d1347e2b55b8a37331997cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "861899abe6ad46f4b68ddee5e430fd6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "868ae5fcd4b3449297a6596de8cf892e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_edebaac0cf86431aa2ac5b24748a50d7",
       "IPY_MODEL_bad280c1f832422dbe2e7d3ce8bfe205",
       "IPY_MODEL_50c59fccba734f8b9de37b6f6ef28cfd"
      ],
      "layout": "IPY_MODEL_bc6647483e594a8e95def8964b058768"
     }
    },
    "86a059793efc4567a66a12277b7f5dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b84c5d287db40a09845d2615fd18e10",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4b5d7f6495c4444864ae0aa591b8bcd",
      "value": 4
     }
    },
    "89469d75cb0c45549c3b03a1984f898a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aeb45a4f8d14487bfd598eb071876dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c130497475546e685db1b7d193e3258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43cb89109de14d26a661110d29b08532",
       "IPY_MODEL_e2c473a3ac8b4d369256ab0b7184043d",
       "IPY_MODEL_e7f583fe5f6640799ba5686fc3d7f7c4"
      ],
      "layout": "IPY_MODEL_7b66df957ac3466bb659e54319e0603f"
     }
    },
    "8cec5b1b342e432f942dfe0c07bdbc55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad5633fc3e094227800f7d14b9902b76",
      "placeholder": "​",
      "style": "IPY_MODEL_ba80ab2b7ad643e0b509f94450c072c9",
      "value": " 654/654 [00:00&lt;00:00, 51.8kB/s]"
     }
    },
    "8e24192905cb44a2808fd02c71bb4909": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9189bc0b83b14ce6b3b216092aa25978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c4812edc07486b83d4a386c79d1450",
      "placeholder": "​",
      "style": "IPY_MODEL_e76203fdd5f8498aa20e46de395b6880",
      "value": "tokenizer.json: 100%"
     }
    },
    "9325e3aa39f04ea289bcb9b524a1912e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9622056982814fe48e3d1a23d6311011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96ee1cf007c746219beefd1133beb0ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a41053fd34243899f46b2dd76bcadcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c6db2d631944b83a9ed1b3224de2d4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c86d5ce5126e493d8ed5068285ee04c1",
      "max": 23950,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ea6cac855db48aebdc66b0328486a7e",
      "value": 23950
     }
    },
    "9c98a0d7f1f34e438d116fdec59292f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f958021df09474fbe60c8830ccc4810",
       "IPY_MODEL_24c365ce42a2473ea86e9a3ff3b4bbdb",
       "IPY_MODEL_031ad948be37418397f06cbf2f7eaa19"
      ],
      "layout": "IPY_MODEL_27cb423a33794a2fb329a0265856fce1"
     }
    },
    "9f6760d652ec419f967c8f8f1fad471a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fb6e17fb523419fa868703cc1633efa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ee890dd2e94e21989bb30ad3ff50fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9d5df847f5e40d5be45f7ad24ad23fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad5633fc3e094227800f7d14b9902b76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae66c264b87e48d6a6fea43d5a08bee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae8454dfa7da4ac2a63a36eaddf04359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0560c42edd444e6cbf857665f24207b5",
      "placeholder": "​",
      "style": "IPY_MODEL_f9714a9508e2460586f1c12a9caaba21",
      "value": " 4/4 [00:09&lt;00:00,  2.02s/it]"
     }
    },
    "aecf9dd24860401e88f7f56b208bab46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af580ea95446412185d0c1d82c4efcaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b000d0fa59b64669a1302972ac8fbbf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1b5c6e8419a4ff5ba14a17d990ac38e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3076d10a2d64e89a199946fadefbea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83f3dfc8d5984267b224c27f489177e1",
      "placeholder": "​",
      "style": "IPY_MODEL_11be9dd298754155ac5521ad4341d6a1",
      "value": " 1.17G/1.17G [00:04&lt;00:00, 170MB/s]"
     }
    },
    "b35e68194ef64fcd8ecc99d05f3ed8fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8c8a96600d04722a75ea14a891fc194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba80ab2b7ad643e0b509f94450c072c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bad280c1f832422dbe2e7d3ce8bfe205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd012db000204884bf6e17c9d17664a6",
      "max": 4999802720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5ee890dd2e94e21989bb30ad3ff50fb",
      "value": 4999802720
     }
    },
    "bc6647483e594a8e95def8964b058768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc9c9c8c55834d95afa2ff1358dc5906": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e24192905cb44a2808fd02c71bb4909",
      "placeholder": "​",
      "style": "IPY_MODEL_96ee1cf007c746219beefd1133beb0ab",
      "value": " 4/4 [00:59&lt;00:00, 13.10s/it]"
     }
    },
    "be6f22366fc8438dbbccf600149d6f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9189bc0b83b14ce6b3b216092aa25978",
       "IPY_MODEL_572b81f10a6d47e6bd8bff73c63c9880",
       "IPY_MODEL_368880e7312540b195eb1a6f06f6f910"
      ],
      "layout": "IPY_MODEL_437afb8ae45840d29e2e7aed5cdb88a1"
     }
    },
    "bf58bc0260724bfcbe97be7e8602c89b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a75440ec6243bba1f5134844f735ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5f372bb9112428293bb7fd895dc9280": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1554cf5f5f84430abb74d6300a9cf6b1",
       "IPY_MODEL_186ea7fd18a841bbaaed69d7881bac9f",
       "IPY_MODEL_700206a3a8d845d6a08e2a2ae91aaedb"
      ],
      "layout": "IPY_MODEL_711c5c0af6ef462c922f7cd89ca0e633"
     }
    },
    "c63262ee29ec4a17b1d976643512ac72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c83e62f823ef455eb45c35c5fce68dae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86d5ce5126e493d8ed5068285ee04c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9dce19ac35441589f8bcee5f8c77f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb2194b7d8244247bf369d11ad165f64",
      "placeholder": "​",
      "style": "IPY_MODEL_9325e3aa39f04ea289bcb9b524a1912e",
      "value": "Downloading shards: 100%"
     }
    },
    "c9f48e5ed19140ec96b3681e30f71292": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf28511f878b4402a3d1ec95944ed38c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4aae3a8bdd4129b120c50165b47995": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf84a617bc6b4f5dae1c0648f8c969b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18bf0ecca7643319d7d8a43fd31973d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4fc63186a1741a192548b27ddcfa35b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae6e96c41c549ffbc6d53e9b6e4d176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c63262ee29ec4a17b1d976643512ac72",
      "max": 654,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c016d643bf6480c9411f88e751063b1",
      "value": 654
     }
    },
    "dd012db000204884bf6e17c9d17664a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd450fadac8d4f0c8240fb2f481bb361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddd49b4c0b82453ebde671025ef535ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0544d43054549af9272caafb43c1aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e16caa2c30754ad5ab09ef48438f9035": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c473a3ac8b4d369256ab0b7184043d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60449fba179b4d86b48e0bb7b9022e2b",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_435eca0c7f604c1abbbbc71265571be6",
      "value": 80
     }
    },
    "e3541a1ff2b14488b765c368d1df8664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12f2a80a725548e1b4a448ff5cf3c6b8",
       "IPY_MODEL_0a2c6d42c43948acaec95f97de0cf7ac",
       "IPY_MODEL_b3076d10a2d64e89a199946fadefbea0"
      ],
      "layout": "IPY_MODEL_f550c3b95d134de9b7937bc6b3d775d3"
     }
    },
    "e4b5d7f6495c4444864ae0aa591b8bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4eacc874a6049c38b1989b6229b5954": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58dabd441b14f4aafda2830c9446ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f0844fe920e458a8eaa1a7ee1c8dd71",
      "placeholder": "​",
      "style": "IPY_MODEL_89469d75cb0c45549c3b03a1984f898a",
      "value": " 50.6k/50.6k [00:00&lt;00:00, 3.55MB/s]"
     }
    },
    "e76203fdd5f8498aa20e46de395b6880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7cddf4af8ea485aa3e893af5dd365cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebc4adc1f2ef48ddba5aafcc93f48477",
      "placeholder": "​",
      "style": "IPY_MODEL_9fb6e17fb523419fa868703cc1633efa",
      "value": "model-00001-of-00004.safetensors: 100%"
     }
    },
    "e7f583fe5f6640799ba5686fc3d7f7c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf58bc0260724bfcbe97be7e8602c89b",
      "placeholder": "​",
      "style": "IPY_MODEL_c5a75440ec6243bba1f5134844f735ca",
      "value": " 80/80 [00:00&lt;00:00, 2684.38 examples/s]"
     }
    },
    "e8d06ae113094a8e8f1946c60dc85a37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb066f1351b24551a92e912a1a42a47b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb2194b7d8244247bf369d11ad165f64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebc4adc1f2ef48ddba5aafcc93f48477": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edebaac0cf86431aa2ac5b24748a50d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d18bf0ecca7643319d7d8a43fd31973d",
      "placeholder": "​",
      "style": "IPY_MODEL_0495f42403f440a5b589ed4b39c27e26",
      "value": "model-00002-of-00004.safetensors: 100%"
     }
    },
    "efcd9b2d530c4a7d842c4985acb201d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e7bfb272af3480e9384f56b892fec47",
       "IPY_MODEL_dae6e96c41c549ffbc6d53e9b6e4d176",
       "IPY_MODEL_8cec5b1b342e432f942dfe0c07bdbc55"
      ],
      "layout": "IPY_MODEL_630d6c2edaa34ff4820b0f3cbc776eda"
     }
    },
    "f18f2bf7ed5f4b4c9aacf141ae34d2a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1e0f5cb31d34dfa91257da4a5a104df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f209b3c55af54890b110e49760eaf6f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f550c3b95d134de9b7937bc6b3d775d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9714a9508e2460586f1c12a9caaba21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9d266bc194c44dcbdbc12b51daff386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc911804053e44f98215ae7bef27e206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85f350094d1347e2b55b8a37331997cb",
      "placeholder": "​",
      "style": "IPY_MODEL_2d0cab209a1d4b6195d72e5fc906567e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "fca39da904da4d249964985162897242": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
