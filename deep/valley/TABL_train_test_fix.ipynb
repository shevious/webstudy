{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original source  \n",
    "https://github.com/LeonardoBerti00/TABL-Temporal-Attention-Augmented-Bilinear-Network-for-Financial-Time-Series-Data-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-PVsZeWjCiw"
   },
   "source": [
    "### **TABL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AVPONVeVw0nh"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNdy1u5zjMaw"
   },
   "source": [
    "### **Data**\n",
    "The dataset in the folder Dataset is the FI-2010 dataset zipped and normalized. \n",
    "\n",
    "As in the original paper I used the firs 7 days to train and to validate, and the rest 3 days to do the the testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ls5u0jngxkjl"
   },
   "outputs": [],
   "source": [
    "# please change the data_path to your local path and download the files you need from the web site of the dataset\n",
    "\n",
    "#dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "#dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Training/Train_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(dec_data.shape[1] * 0.8)]\n",
    "dec_val = dec_data[:, int(dec_data.shape[1] * 0.8):]\n",
    "\n",
    "#dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "#dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt')\n",
    "#dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt')\n",
    "dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_9.txt')\n",
    "#dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_7.txt')\n",
    "#dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_8.txt')\n",
    "#dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "# dec_train.shape = (149, 203800)\n",
    "\n",
    "h = 2        #if h = 2, than horizon = 50\n",
    "T = 50      #horizon \n",
    "dim = 10\n",
    "k = T//10    #horizon\n",
    "\n",
    "y_train = dec_train[-h, :].flatten()\n",
    "# y_train.shape = (203800,)\n",
    "y_val = dec_val[-h, :].flatten()\n",
    "y_test = dec_test[-h, :].flatten()\n",
    "\n",
    "# 10-1: 10 means the length of inputs\n",
    "# second -1 means [1,2,3] to [0,1,2] conversion of class id\n",
    "#y_train = y_train[dim-1+(k-1):] - 1\n",
    "y_train = y_train[dim-1:] - 1\n",
    "# y_train.shape = (203791,) # 203791 = 203800-(10+1)\n",
    "#y_val = y_val[dim-1+(k-1):] - 1\n",
    "y_val = y_val[dim-1:] - 1\n",
    "#y_test = y_test[dim-1+(k-1):] - 1 \n",
    "y_test = y_test[dim-1:] - 1 \n",
    "\n",
    "# First 40 features = 10*4 features\n",
    "dec_train = dec_train[:40, :].T\n",
    "# dec_train.shape = (203800, 40)\n",
    "dec_val = dec_val[:40, :].T\n",
    "dec_test = dec_test[:40, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 124139)\n"
     ]
    }
   ],
   "source": [
    "#decpre_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "# Auction\n",
    "#decpre_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Training/Train_Dst_Auction_DecPre_CF_7.txt')\n",
    "#decpre_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_7.txt')\n",
    "decpre_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_7.txt')\n",
    "decpre_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_8.txt')\n",
    "decpre_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_9.txt')\n",
    "decpre_data = np.hstack((decpre_test1, decpre_test2, decpre_test3))\n",
    "#decpre_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "decpre_train = decpre_data[:, :int(decpre_data.shape[1] * 0.8)]\n",
    "decpre_val = decpre_data[:, int(decpre_data.shape[1] * 0.8):]\n",
    "print(decpre_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_decpre_train = decpre_train[-h, :].flatten()\n",
    "# y_train.shape = (203800,)\n",
    "y_decpre_val = decpre_val[-h, :].flatten()\n",
    "y_decpre_train = y_decpre_train - 1\n",
    "\n",
    "decpre_all_train = decpre_train.T\n",
    "# First 40 features = 10*4 features\n",
    "decpre_train = decpre_train[:40, :].T\n",
    "# dec_train.shape = (203800, 40)\n",
    "decpre_val = decpre_val[:40, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124139, 149), (124139, 40), (124139,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decpre_all_train.shape, decpre_train.shape, y_decpre_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = (decpre_all_train[:, 0]+decpre_all_train[:, 2])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = decpre_all_train[:, -h] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizon = 5, matching ratio = 0.903653\n"
     ]
    }
   ],
   "source": [
    "thres = 0.00002\n",
    "thres1 = thres\n",
    "thres2 = thres\n",
    "\n",
    "#thres1 = 0.00002\n",
    "#thres2 = 0.00002\n",
    "\n",
    "k = 5\n",
    "\n",
    "n = mid.shape[0] - k\n",
    "\n",
    "offset = k-1\n",
    "#for i in range(30):\n",
    "#    y_label[i] = i\n",
    "y_label_shift = y_label[offset:]\n",
    "\n",
    "matching_cnt = 0\n",
    "total_cnt = 0\n",
    "for i in range(n):\n",
    "    total_cnt += 1\n",
    "    #m_i = np.mean(mid0[i-k+1:i+1])\n",
    "    m_i = mid[i]\n",
    "    l_i = (np.mean(mid[i+1:i+1+(k-1)])-m_i)/m_i\n",
    "    if l_i >= thres1:\n",
    "        y = 0\n",
    "    elif l_i <= -thres2:\n",
    "        y = 2\n",
    "    else:\n",
    "        y = 1\n",
    "    #if i < 100:\n",
    "        #print(y, int(y_label_shift[i]), l_i)\n",
    "    if y == int(y_label_shift[i]):\n",
    "        matching_cnt += 1\n",
    "\n",
    "print('horizon = %d, matching ratio = %f'%(k, matching_cnt/total_cnt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the weights for the weighted cross entropy loss\n",
    "def compute_weights(y):\n",
    "  cont_0 = 0\n",
    "  cont_1 = 0\n",
    "  cont_2 = 0\n",
    "  for i in range(y.shape[0]):\n",
    "    if (y[i] == 0):\n",
    "      cont_0 += 1\n",
    "    elif (y[i] == 1):\n",
    "      cont_1 += 1\n",
    "    elif (y[i] == 2):\n",
    "      cont_2 += 2\n",
    "    else: \n",
    "      raise Exception(\"wrong labels\")\n",
    "  return torch.Tensor([1e6/cont_0, 1e6/cont_1, 1e6/cont_2]).to(device)\n",
    "\n",
    "y_total = np.concatenate((y_train, y_val, y_test))\n",
    "weights = compute_weights(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8x7PAu1LySOZ"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x, y, num_classes, dim):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.num_classes = num_classes\n",
    "        self.dim = dim\n",
    "        self.x = x   \n",
    "        self.y = y\n",
    "\n",
    "        self.length = x.shape[0] - (T/10) -self.dim + 1\n",
    "        print(self.length)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return int(self.length)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input = self.x[i:i+self.dim, :]\n",
    "        input = input.permute(1, 2, 0)\n",
    "        input = torch.squeeze(input)\n",
    "\n",
    "        return input, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ndByE-Ajmq8",
    "outputId": "9b68ee43-4e8d-4483-c284-512fb31797e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60577.0\n",
      "155160.0\n",
      "242346.0\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "   \n",
    "lr = 0.01\n",
    "num_classes = 3\n",
    "dim = 10\n",
    "\n",
    "dataset_val = Dataset(dec_val, y_val, num_classes, dim)\n",
    "dataset_test = Dataset(dec_test, y_test, num_classes, dim)\n",
    "dataset_train = Dataset(dec_train, y_train, num_classes, dim)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35983073"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 10]) torch.Size([])\n",
      "tensor([0.3543, 0.3688, 0.3688, 0.3688, 0.3688, 0.3708, 0.3673, 0.3673, 0.3688,\n",
      "        0.3673], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(dataset_train):\n",
    "    print(x.shape, y.shape)\n",
    "    n = x.shape[0]\n",
    "    mids = (x[0, :] + x[2, :])/2\n",
    "    print(mids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEIIi2NwjtgC"
   },
   "source": [
    "### **Model Architecture**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lhA2p2kcUj2q"
   },
   "outputs": [],
   "source": [
    "class TABL_layer(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "\n",
    "        weight = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "        \n",
    "        weight2 = torch.Tensor(t1, t1)\n",
    "        self.W = nn.Parameter(weight2)\n",
    "        nn.init.constant_(self.W, 1/t1)\n",
    " \n",
    "        weight3 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight3)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.Tensor(d2, t2)\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        l = torch.Tensor(1,)\n",
    "        self.l = nn.Parameter(l)\n",
    "        nn.init.constant_(self.l, 0.5)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        #maintaining the weight parameter between 0 and 1.\n",
    "        if (self.l[0] < 0): \n",
    "          l = torch.Tensor(1,)\n",
    "          self.l = nn.Parameter(l)\n",
    "          nn.init.constant_(self.l, 0.0)\n",
    "\n",
    "        if (self.l[0] > 1): \n",
    "          l = torch.Tensor(1,)\n",
    "          self.l = nn.Parameter(l)\n",
    "          nn.init.constant_(self.l, 1.0)\n",
    "     \n",
    "        #modelling the dependence along the first mode of X while keeping the temporal order intact (7)\n",
    "        X = self.W1 @ X\n",
    "\n",
    "        #enforcing constant (1) on the diagonal\n",
    "        W = self.W -self.W *torch.eye(self.t1,dtype=torch.float32).to(device)+torch.eye(self.t1,dtype=torch.float32).to(device)/self.t1\n",
    "\n",
    "        #attention, the aim of the second step is to learn how important the temporal instances are to each other (8)\n",
    "        E = X @ W\n",
    "\n",
    "        #computing the attention mask  (9)\n",
    "        A = torch.softmax(E, dim=-1)\n",
    "\n",
    "        #applying a soft attention mechanism  (10)\n",
    "        #he attention mask A obtained from the third step is used to zero out the effect of unimportant elements\n",
    "        X = self.l[0] * (X) + (1.0 - self.l[0])*X*A\n",
    "\n",
    "        #the final step of the proposed layer estimates the temporal mapping W2, after the bias shift (11)\n",
    "        y = X @ self.W2 + self.B\n",
    "        return y\n",
    "\n",
    "class BL_layer(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        weight1 = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight1)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight2)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.zeros((d2, t2))\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.activation(self.W1 @ x @ self.W2 + self.B)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class BTABL(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2, d3, t3):\n",
    "    super().__init__()\n",
    "\n",
    "    self.BL = BL_layer(d2, d1, t1, t2)\n",
    "    self.TABL = TABL_layer(d3, d2, t2, t3)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    self.max_norm_(self.BL.W1.data)\n",
    "    self.max_norm_(self.BL.W2.data)\n",
    "    x = self.BL(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.TABL.W1.data)\n",
    "    self.max_norm_(self.TABL.W.data)\n",
    "    self.max_norm_(self.TABL.W2.data)\n",
    "    x = self.TABL(x)\n",
    "    x = torch.squeeze(x)\n",
    "    x = torch.softmax(x, 1)\n",
    "    return x\n",
    "\n",
    "  def max_norm_(self, w):\n",
    "    with torch.no_grad():\n",
    "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "        norm = torch.linalg.matrix_norm(w)\n",
    "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "        w *= (desired / (1e-8 + norm))\n",
    "\n",
    "\n",
    "\n",
    "class CTABL(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2, d3, t3, d4, t4):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.BL = BL_layer(d2, d1, t1, t2)\n",
    "    self.BL2 = BL_layer(d3, d2, t2, t3)\n",
    "    self.TABL = TABL_layer(d4, d3, t3, t4)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    " \n",
    "    self.max_norm_(self.BL.W1.data)\n",
    "    self.max_norm_(self.BL.W2.data)\n",
    "    x = self.BL(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.BL2.W1.data)\n",
    "    self.max_norm_(self.BL2.W2.data)\n",
    "    x = self.BL2(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.TABL.W1.data)\n",
    "    self.max_norm_(self.TABL.W.data)\n",
    "    self.max_norm_(self.TABL.W2.data)\n",
    "    x = self.TABL(x)\n",
    "    x = torch.squeeze(x)\n",
    "    x = torch.softmax(x, 1)\n",
    "    return x\n",
    "\n",
    "  def max_norm_(self, w):\n",
    "    with torch.no_grad():\n",
    "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "        norm = torch.linalg.matrix_norm(w)\n",
    "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "        w *= (desired / (1e-8 + norm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiN(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "        self.d1 = d1\n",
    "        self.t2 = t2\n",
    "        self.d2 = d2\n",
    "\n",
    "        bias1 = torch.Tensor(t1, 1)\n",
    "        self.B1 = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B1, 0)\n",
    "\n",
    "        l1 = torch.Tensor(t1, 1)\n",
    "        self.l1 = nn.Parameter(l1)\n",
    "        nn.init.xavier_normal_(self.l1)\n",
    "\n",
    "        bias2 = torch.Tensor(d1, 1)\n",
    "        self.B2 = nn.Parameter(bias2)\n",
    "        nn.init.constant_(self.B2, 0)\n",
    "\n",
    "        l2 = torch.Tensor(d1, 1)\n",
    "        self.l2 = nn.Parameter(l2)\n",
    "        nn.init.xavier_normal_(self.l2)\n",
    "\n",
    "        y1 = torch.Tensor(1, )\n",
    "        self.y1 = nn.Parameter(y1)\n",
    "        nn.init.constant_(self.y1, 0.5)\n",
    "\n",
    "        y2 = torch.Tensor(1, )\n",
    "        self.y2 = nn.Parameter(y2)\n",
    "        nn.init.constant_(self.y2, 0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # if the two scalars are negative then we setting them to 0\n",
    "        if (self.y1[0] < 0):\n",
    "            y1 = torch.cuda.FloatTensor(1, )\n",
    "            self.y1 = nn.Parameter(y1)\n",
    "            nn.init.constant_(self.y1, 0.01)\n",
    "\n",
    "        if (self.y2[0] < 0):\n",
    "            y2 = torch.cuda.FloatTensor(1, )\n",
    "            self.y2 = nn.Parameter(y2)\n",
    "            nn.init.constant_(self.y2, 0.01)\n",
    "\n",
    "        # normalization along the temporal dimensione\n",
    "        #T2 = torch.ones([self.t1, 1], device=cst.DEVICE_TYPE)\n",
    "        T2 = torch.ones([self.t1, 1], device=device)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x2 = torch.reshape(x2, (x2.shape[0], x2.shape[1], 1))\n",
    "\n",
    "        std = torch.std(x, dim=2)\n",
    "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
    "        # it can be possible that the std of some temporal slices is 0, and this produces inf values, so we have to set them to one\n",
    "        std[std < 1e-4] = 1\n",
    "\n",
    "        diff = x - (x2 @ (T2.T))\n",
    "        Z2 = diff / (std @ (T2.T))\n",
    "\n",
    "        X2 = self.l2 @ T2.T\n",
    "        X2 = X2 * Z2\n",
    "        X2 = X2 + (self.B2 @ T2.T)\n",
    "\n",
    "        # normalization along the feature dimension\n",
    "        #T1 = torch.ones([self.d1, 1], device=cst.DEVICE_TYPE)\n",
    "        T1 = torch.ones([self.d1, 1], device=device)\n",
    "        x1 = torch.mean(x, dim=1)\n",
    "        x1 = torch.reshape(x1, (x1.shape[0], x1.shape[1], 1))\n",
    "\n",
    "        std = torch.std(x, dim=1)\n",
    "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
    "\n",
    "        op1 = x1 @ T1.T\n",
    "        op1 = torch.permute(op1, (0, 2, 1))\n",
    "\n",
    "        op2 = std @ T1.T\n",
    "        op2 = torch.permute(op2, (0, 2, 1))\n",
    "\n",
    "        z1 = (x - op1) / (op2)\n",
    "        X1 = (T1 @ self.l1.T)\n",
    "        X1 = X1 * z1\n",
    "        X1 = X1 + (T1 @ self.B1.T)\n",
    "\n",
    "        # weighing the imporance of temporal and feature normalization\n",
    "        x = self.y1 * X1 + self.y2 * X2\n",
    "\n",
    "        return x\n",
    "        \n",
    "class BL_layer(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        weight1 = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight1)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight2)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.zeros((d2, t2))\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.activation(self.W1 @ x @ self.W2 + self.B)\n",
    "\n",
    "    return x\n",
    "\n",
    "class TABL_layer(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "\n",
    "        weight = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t1)\n",
    "        self.W = nn.Parameter(weight2)\n",
    "        nn.init.constant_(self.W, 1 / t1)\n",
    "\n",
    "        weight3 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight3)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.Tensor(d2, t2)\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        l = torch.Tensor(1, )\n",
    "        self.l = nn.Parameter(l)\n",
    "        nn.init.constant_(self.l, 0.5)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # maintaining the weight parameter between 0 and 1.\n",
    "        if (self.l[0] < 0):\n",
    "            l = torch.Tensor(1, )\n",
    "            self.l = nn.Parameter(l)\n",
    "            nn.init.constant_(self.l, 0.0)\n",
    "\n",
    "        if (self.l[0] > 1):\n",
    "            l = torch.Tensor(1, )\n",
    "            self.l = nn.Parameter(l)\n",
    "            nn.init.constant_(self.l, 1.0)\n",
    "\n",
    "        # modelling the dependence along the first mode of X while keeping the temporal order intact (7)\n",
    "        X = self.W1 @ X\n",
    "\n",
    "        # enforcing constant (1) on the diagonal\n",
    "        #W = self.W - self.W * torch.eye(self.t1, dtype=torch.float32, device=cst.DEVICE_TYPE) + torch.eye(self.t1, dtype=torch.float32, device=cst.DEVICE_TYPE) / self.t1\n",
    "        W = self.W - self.W * torch.eye(self.t1, dtype=torch.float32, device=device) + torch.eye(self.t1, dtype=torch.float32, device=device) / self.t1\n",
    "\n",
    "        # attention, the aim of the second step is to learn how important the temporal instances are to each other (8)\n",
    "        E = X @ W\n",
    "\n",
    "        # computing the attention mask  (9)\n",
    "        A = torch.softmax(E, dim=-1)\n",
    "\n",
    "        # applying a soft attention mechanism  (10)\n",
    "        # he attention mask A obtained from the third step is used to zero out the effect of unimportant elements\n",
    "        X = self.l[0] * (X) + (1.0 - self.l[0]) * X * A\n",
    "\n",
    "        # the final step of the proposed layer estimates the temporal mapping W2, after the bias shift (11)\n",
    "        y = X @ self.W2 + self.B\n",
    "        return y\n",
    "\n",
    "\n",
    "class BiN_CTABL(nn.Module):\n",
    "    # d2=60, d1=40, t1=10, t2=10, d3=120, t3=5, d4=3, t4=1\n",
    "    def __init__(self, d2, d1, t1, t2, d3, t3, d4, t4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BiN = BiN(d2, d1, t1, t2)\n",
    "        self.BL = BL_layer(d2, d1, t1, t2)\n",
    "        self.BL2 = BL_layer(d3, d2, t2, t3)\n",
    "        # d4=3, d3=120, t3=5, t4=1\n",
    "        self.TABL = TABL_layer(d4, d3, t3, t4)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x.shape = (32, 40, 10)\n",
    "        # first of all we pass the input to the BiN layer, then we use the C(TABL) architecture\n",
    "        #x = torch.permute(x, (0, 2, 1))\n",
    "\n",
    "        x = self.BiN(x)\n",
    "\n",
    "        self.max_norm_(self.BL.W1.data)\n",
    "        self.max_norm_(self.BL.W2.data)\n",
    "        x = self.BL(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        self.max_norm_(self.BL2.W1.data)\n",
    "        self.max_norm_(self.BL2.W2.data)\n",
    "        x = self.BL2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        self.max_norm_(self.TABL.W1.data)\n",
    "        self.max_norm_(self.TABL.W.data)\n",
    "        self.max_norm_(self.TABL.W2.data)\n",
    "        x = self.TABL(x)\n",
    "        # x.shape = (32, 3, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        # x.shape = (32, 3)\n",
    "        x = torch.softmax(x, 1)\n",
    "        # x.shape = (32, 3)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def max_norm_(self, w):\n",
    "        with torch.no_grad():\n",
    "            if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "                norm = torch.linalg.matrix_norm(w)\n",
    "                desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "                w *= (desired / (1e-8 + norm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bejZgDmCkkHi"
   },
   "source": [
    "### **Model Training**\n",
    "\n",
    "I implemented the second setting of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s_u5esKfTT-S"
   },
   "outputs": [],
   "source": [
    "#Choose between B(TABL) and C(TABL)\n",
    "\n",
    "#model = BTABL(120, 40, 10, 5, 3, 1)\n",
    "#model = CTABL(60, 40, 10, 10, 120, 5, 3, 1)\n",
    "model = BiN_CTABL(60, 40, 10, 10, 120, 5, 3, 1)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def batch_gd(model, criterion, optimizer, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "    SC = [0.005, 0.001, 0.0005, 0.0001]\n",
    "    i = 0\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print('### debug 22')\n",
    "            #print(outputs.shape)\n",
    "            #print(targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "        \n",
    "        if (train_losses[it-1] <= train_loss and i < 4 and it != 0):\n",
    "              for g in optimizer.param_groups:\n",
    "                g['lr'] = SC[i]\n",
    "              i += 1\n",
    "              \n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            #outputs = torch.squeeze(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        #We save the best model\n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(model, './best_model_CTABL')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "        \n",
    "    #torch.save(model, '/content/drive/MyDrive/Output/best_model_translob_FI')\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x9vq-ZAzTb6K",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- List Hyper Parameters -------\n",
      "epochs   ->   200\n",
      "learningRate   ->   0.01\n",
      "horizon    ->     50\n",
      "batch size   ->    256\n",
      "Optimizer   ->    SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                            | 1/200 [00:09<32:02,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/200, Train Loss: 0.8035,           Validation Loss: 0.6767, Duration: 0:00:09.658602, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                            | 2/200 [00:19<31:28,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/200, Train Loss: 0.6732,           Validation Loss: 0.6630, Duration: 0:00:09.452402, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                           | 3/200 [00:29<32:04,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/200, Train Loss: 0.6701,           Validation Loss: 0.6614, Duration: 0:00:10.046377, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                           | 4/200 [00:39<32:30,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/200, Train Loss: 0.6696,           Validation Loss: 0.6612, Duration: 0:00:10.233973, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                           | 5/200 [00:48<31:40,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.6693,           Validation Loss: 0.6621, Duration: 0:00:09.376620, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                          | 6/200 [00:58<31:21,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 6/200, Train Loss: 0.6690,           Validation Loss: 0.6611, Duration: 0:00:09.611008, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▋                                                                          | 7/200 [01:07<31:01,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 7/200, Train Loss: 0.6686,           Validation Loss: 0.6610, Duration: 0:00:09.536598, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                          | 8/200 [01:18<31:34,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 8/200, Train Loss: 0.6686,           Validation Loss: 0.6607, Duration: 0:00:10.331105, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                         | 9/200 [01:28<31:18,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.6684,           Validation Loss: 0.6607, Duration: 0:00:09.759938, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                        | 10/200 [01:38<31:23,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 10/200, Train Loss: 0.6681,           Validation Loss: 0.6605, Duration: 0:00:10.090426, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▏                                                                       | 11/200 [01:48<31:25,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 11/200, Train Loss: 0.6683,           Validation Loss: 0.6604, Duration: 0:00:10.126583, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▌                                                                       | 12/200 [01:58<31:09,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 12/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.857413, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                       | 13/200 [02:07<30:33,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 0.6680,           Validation Loss: 0.6603, Duration: 0:00:09.490254, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                      | 14/200 [02:17<30:20,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 0.6679,           Validation Loss: 0.6603, Duration: 0:00:09.753200, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▋                                                                      | 15/200 [02:27<30:36,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 0.6678,           Validation Loss: 0.6603, Duration: 0:00:10.250190, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                      | 16/200 [02:37<30:23,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Train Loss: 0.6679,           Validation Loss: 0.6604, Duration: 0:00:09.862834, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                     | 17/200 [02:47<30:02,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 0.6678,           Validation Loss: 0.6604, Duration: 0:00:09.710092, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▊                                                                     | 18/200 [02:56<29:33,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 0.6678,           Validation Loss: 0.6604, Duration: 0:00:09.497874, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▏                                                                    | 19/200 [03:06<29:27,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 0.6680,           Validation Loss: 0.6604, Duration: 0:00:09.807485, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 20/200 [03:16<29:25,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 0.6678,           Validation Loss: 0.6604, Duration: 0:00:09.919963, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                    | 21/200 [03:26<29:07,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 0.6678,           Validation Loss: 0.6604, Duration: 0:00:09.652712, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▎                                                                   | 22/200 [03:36<29:17,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 0.6678,           Validation Loss: 0.6604, Duration: 0:00:10.129957, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▋                                                                   | 23/200 [03:46<29:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 0.6678,           Validation Loss: 0.6603, Duration: 0:00:10.277495, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████                                                                   | 24/200 [03:56<29:15,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 0.6677,           Validation Loss: 0.6603, Duration: 0:00:09.921588, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                  | 25/200 [04:05<28:42,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 0.6677,           Validation Loss: 0.6603, Duration: 0:00:09.537372, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▉                                                                  | 26/200 [04:16<28:53,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 0.6678,           Validation Loss: 0.6603, Duration: 0:00:10.235527, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▎                                                                 | 27/200 [04:26<28:43,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Train Loss: 0.6676,           Validation Loss: 0.6603, Duration: 0:00:09.967810, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▋                                                                 | 28/200 [04:36<28:57, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.6677,           Validation Loss: 0.6603, Duration: 0:00:10.422366, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████                                                                 | 29/200 [04:46<28:21,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 0.6677,           Validation Loss: 0.6603, Duration: 0:00:09.605258, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▍                                                                | 30/200 [04:55<27:41,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 0.6676,           Validation Loss: 0.6603, Duration: 0:00:09.360035, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▊                                                                | 31/200 [05:05<27:32,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.6678,           Validation Loss: 0.6603, Duration: 0:00:09.780915, Best Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▏                                                               | 32/200 [05:14<27:14,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 32/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.617865, Best Val Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                               | 33/200 [05:24<27:01,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.660829, Best Val Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▉                                                               | 34/200 [05:34<27:03,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.954136, Best Val Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▎                                                              | 35/200 [05:44<27:03,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 35/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.962377, Best Val Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▋                                                              | 36/200 [05:54<26:57,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.917785, Best Val Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████                                                              | 37/200 [06:04<27:01,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 37/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.148382, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                             | 38/200 [06:14<26:38,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.673088, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▊                                                             | 39/200 [06:23<26:23,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.756825, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 40/200 [06:33<26:15,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.874987, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▌                                                            | 41/200 [06:43<25:49,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.512350, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▉                                                            | 42/200 [06:53<25:41,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.784099, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▎                                                           | 43/200 [07:03<25:38,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.899899, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▋                                                           | 44/200 [07:13<25:44,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.124200, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████                                                           | 45/200 [07:22<25:24,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Train Loss: 0.6678,           Validation Loss: 0.6603, Duration: 0:00:09.690530, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▍                                                          | 46/200 [07:32<25:13,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.804867, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▊                                                          | 47/200 [07:42<25:20,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.190451, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▏                                                         | 48/200 [07:52<24:55,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.610494, Best Val Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▌                                                         | 49/200 [08:02<24:52,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 49/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:10.000171, Best Val Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                         | 50/200 [08:12<24:33,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 50/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.679458, Best Val Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▍                                                        | 51/200 [08:22<24:41,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.220737, Best Val Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▊                                                        | 52/200 [08:32<24:20,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.689682, Best Val Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                       | 53/200 [08:42<24:36, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.461092, Best Val Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▌                                                       | 54/200 [08:52<24:28, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 54/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.092141, Best Val Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▉                                                       | 55/200 [09:02<24:24, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 55/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.189955, Best Val Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▎                                                      | 56/200 [09:12<24:08, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.970875, Best Val Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▋                                                      | 57/200 [09:22<23:55, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.978725, Best Val Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████                                                      | 58/200 [09:32<23:38,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.875678, Best Val Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▍                                                     | 59/200 [09:42<23:24,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.897563, Best Val Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 60/200 [09:53<23:40, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 60/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.576604, Best Val Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▏                                                    | 61/200 [10:03<23:18, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 61/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.867863, Best Val Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▌                                                    | 62/200 [10:13<23:30, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 62/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.576944, Best Val Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████▉                                                    | 63/200 [10:23<22:58, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.701700, Best Val Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▎                                                   | 64/200 [10:33<22:44, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 64/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.971622, Best Val Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                   | 65/200 [10:43<22:23,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 65/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.766478, Best Val Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████                                                   | 66/200 [10:52<22:07,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.791375, Best Val Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▍                                                  | 67/200 [11:02<21:59,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 67/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.952847, Best Val Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▊                                                  | 68/200 [11:13<22:16, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 68/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.603559, Best Val Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▏                                                 | 69/200 [11:23<22:06, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.136829, Best Val Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▌                                                 | 70/200 [11:33<21:52, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 70/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.006713, Best Val Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████▉                                                 | 71/200 [11:43<21:35, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 71/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.934278, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▎                                                | 72/200 [11:53<21:10,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.633259, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▋                                                | 73/200 [12:03<21:13, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.269072, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████                                                | 74/200 [12:13<21:14, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.314415, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▌                                               | 75/200 [12:23<20:50, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.759523, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▉                                               | 76/200 [12:33<20:40, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.989075, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▎                                              | 77/200 [12:43<20:34, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.129780, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████▋                                              | 78/200 [12:53<20:15,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.771297, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████                                              | 79/200 [13:03<19:58,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200, Train Loss: 0.6679,           Validation Loss: 0.6602, Duration: 0:00:09.781260, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 80/200 [13:13<19:50,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.946300, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                             | 81/200 [13:22<19:40,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.916940, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▏                                            | 82/200 [13:32<19:12,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.421191, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████▌                                            | 83/200 [13:41<18:54,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.531368, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████▉                                            | 84/200 [13:52<19:05,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.287825, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▎                                           | 85/200 [14:02<18:56,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.902643, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████▋                                           | 86/200 [14:12<18:55,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:10.140013, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████                                           | 87/200 [14:21<18:29,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.491847, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▍                                          | 88/200 [14:32<18:43, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.513780, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▊                                          | 89/200 [14:42<18:50, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.533755, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▏                                         | 90/200 [14:52<18:24, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.700352, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▌                                         | 91/200 [15:02<18:07,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.825037, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▉                                         | 92/200 [15:11<17:46,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.656302, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████▎                                        | 93/200 [15:22<17:56, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.491303, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████▋                                        | 94/200 [15:32<17:39,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.831689, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████▋                                    | 103/200 [17:01<16:00,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.845784, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████                                    | 104/200 [17:11<15:49,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.869674, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████▍                                   | 105/200 [17:21<15:53, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.385646, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████▊                                   | 106/200 [17:31<15:50, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.278405, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▏                                  | 107/200 [17:41<15:38, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.042400, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▌                                  | 108/200 [17:52<15:31, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.199768, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████▉                                  | 109/200 [18:02<15:15, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.906489, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▎                                 | 110/200 [18:11<14:53,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.638047, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████▋                                 | 111/200 [18:21<14:34,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.589076, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████                                 | 112/200 [18:31<14:27,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.914171, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████▎                                | 113/200 [18:40<14:11,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.625009, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████▋                                | 114/200 [18:50<13:55,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.539057, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████▏                               | 115/200 [19:00<13:44,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.686400, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████▌                               | 116/200 [19:09<13:40,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.897091, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████▉                               | 117/200 [19:19<13:35,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.954938, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████▎                              | 118/200 [19:29<13:25,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.807809, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████▋                              | 119/200 [19:39<13:08,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.552148, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████                              | 120/200 [19:49<13:18,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.548498, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▍                             | 121/200 [19:59<13:08,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.965266, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████▊                             | 122/200 [20:10<13:04, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.242693, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▏                            | 123/200 [20:19<12:50, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.876521, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▌                            | 124/200 [20:30<12:46, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.276328, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▉                            | 125/200 [20:39<12:28,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.725223, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████▎                           | 126/200 [20:50<12:26, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:10.363657, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████▋                           | 127/200 [21:00<12:12, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.902604, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████                           | 128/200 [21:09<11:54,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.672434, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████▍                          | 129/200 [21:20<12:03, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.804276, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████▊                          | 130/200 [21:30<11:43, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.739362, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▏                         | 131/200 [21:40<11:23,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.575115, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▌                         | 132/200 [21:50<11:23, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.366787, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▉                         | 133/200 [22:00<11:07,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.759207, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████▎                        | 134/200 [22:10<10:57,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.984817, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████▋                        | 135/200 [22:20<10:47,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.926810, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████                        | 136/200 [22:29<10:26,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.416564, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████▍                       | 137/200 [22:39<10:19,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.947131, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▋                       | 138/200 [22:49<10:18,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.302320, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████                       | 139/200 [22:59<10:10, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.077294, Best Val Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▌                      | 140/200 [23:10<10:11, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 140/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.593895, Best Val Epoch: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▉                      | 141/200 [23:20<09:58, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.070416, Best Val Epoch: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████▎                     | 142/200 [23:30<09:50, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 142/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:10.264300, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████▋                     | 143/200 [23:41<09:43, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.334079, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████                     | 144/200 [23:51<09:30, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.092297, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████▍                    | 145/200 [24:01<09:17, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.040940, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████▊                    | 146/200 [24:11<09:13, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:10.505313, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▏                   | 147/200 [24:21<08:59, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.008633, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▌                   | 148/200 [24:31<08:42, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:09.723411, Best Val Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▉                   | 149/200 [24:41<08:39, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 149/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.542722, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▎                  | 150/200 [24:51<08:17,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.411109, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████▋                  | 151/200 [25:01<08:06,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.835880, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████                  | 152/200 [25:11<08:01, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:10.301985, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████▍                 | 153/200 [25:22<07:59, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:10.614204, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████▊                 | 154/200 [25:31<07:40, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.575491, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████▏                | 155/200 [25:41<07:32, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.130659, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████▌                | 156/200 [25:52<07:23, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:10.144124, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████▉                | 157/200 [26:01<07:07,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.601442, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▎               | 158/200 [26:11<06:53,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.658902, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████▋               | 159/200 [26:21<06:44,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:09.857160, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████               | 160/200 [26:30<06:33,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.762076, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▍              | 161/200 [26:40<06:25,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.029664, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████▊              | 162/200 [26:50<06:16,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:09.980377, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████              | 163/200 [27:00<06:08,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:10.024312, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████▍             | 164/200 [27:10<05:57,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.875097, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████▉             | 165/200 [27:20<05:44,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.620263, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████▎            | 166/200 [27:30<05:35,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.901792, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████▋            | 167/200 [27:39<05:21,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200, Train Loss: 0.6674,           Validation Loss: 0.6602, Duration: 0:00:09.446222, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████            | 168/200 [27:49<05:12,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.795309, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████▍           | 169/200 [27:59<05:03,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200, Train Loss: 0.6675,           Validation Loss: 0.6602, Duration: 0:00:09.915325, Best Val Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▊           | 170/200 [28:09<04:53,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 170/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.735598, Best Val Epoch: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████▏          | 171/200 [28:19<04:46,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 171/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.122821, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████▌          | 172/200 [28:29<04:36,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.834416, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████▉          | 173/200 [28:39<04:29,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:10.205325, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████▎         | 174/200 [28:49<04:22, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.363912, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████▋         | 175/200 [28:59<04:11, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:09.974108, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████         | 176/200 [29:09<03:58,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.620087, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████▍        | 177/200 [29:19<03:47,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200, Train Loss: 0.6678,           Validation Loss: 0.6602, Duration: 0:00:09.820200, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████▊        | 178/200 [29:29<03:39, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.236029, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▏       | 179/200 [29:40<03:34, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200, Train Loss: 0.6676,           Validation Loss: 0.6602, Duration: 0:00:10.663724, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▌       | 180/200 [29:49<03:20, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Train Loss: 0.6677,           Validation Loss: 0.6602, Duration: 0:00:09.653191, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▉       | 181/200 [29:59<03:11, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:10.141863, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████▎      | 182/200 [30:09<02:59,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:09.823260, Best Val Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████▋      | 183/200 [30:19<02:49, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 183/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.004585, Best Val Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████      | 184/200 [30:29<02:39,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.851965, Best Val Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████▍     | 185/200 [30:39<02:31, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:10.361655, Best Val Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████▊     | 186/200 [30:50<02:22, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:10.350349, Best Val Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▏    | 187/200 [31:00<02:13, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.577725, Best Val Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▌    | 188/200 [31:10<02:01, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 188/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:09.800920, Best Val Epoch: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▉    | 189/200 [31:20<01:49,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 189/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:09.636415, Best Val Epoch: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████▎   | 190/200 [31:29<01:38,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 190/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:09.492725, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████▋   | 191/200 [31:39<01:27,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.451770, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████   | 192/200 [31:48<01:17,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.511537, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████▍  | 193/200 [31:58<01:07,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.733455, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████▊  | 194/200 [32:08<00:58,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:09.843877, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████▏ | 195/200 [32:18<00:49,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.191782, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████▌ | 196/200 [32:29<00:40, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:10.533750, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████▉ | 197/200 [32:38<00:29,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:09.726714, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████▎| 198/200 [32:49<00:20, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200, Train Loss: 0.6676,           Validation Loss: 0.6601, Duration: 0:00:10.472145, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▋| 199/200 [32:58<00:09,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200, Train Loss: 0.6677,           Validation Loss: 0.6601, Duration: 0:00:09.649677, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 200/200 [33:08<00:00,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Train Loss: 0.6675,           Validation Loss: 0.6601, Duration: 0:00:09.582128, Best Val Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fea3f1c7430>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"------- List Hyper Parameters -------\")\n",
    "print(\"epochs   ->   \" + str(epochs))\n",
    "print(\"learningRate   ->   \" + str(lr))\n",
    "print(\"horizon    ->     \" + str(T))\n",
    "print(\"batch size   ->    \" + str(batch_size))\n",
    "print(\"Optimizer   ->    \" + str(optimizer))\n",
    "\n",
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                     epochs)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7CF2CwUkn4G"
   },
   "source": [
    "### **Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TFg5d6CzTgWS",
    "outputId": "8d1c2dfd-ecff-4f59-e1dd-45504c121328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9004\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./best_model_CTABL')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    #print(outputs)\n",
    "    #print(predictions)\n",
    "    #print(targets)\n",
    "    #print((predictions == targets).sum().item(), targets.shape[0])\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "  \n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0oOu5lwf6zw0",
    "outputId": "a7f1be3e-e874-4733-cead-ca3651a170cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9004253673627224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9268    0.8516    0.8876     42518\n",
      "           1     0.8656    0.9658    0.9130     73154\n",
      "           2     0.9530    0.8319    0.8883     39488\n",
      "\n",
      "    accuracy                         0.9004    155160\n",
      "   macro avg     0.9151    0.8831    0.8963    155160\n",
      "weighted avg     0.9046    0.9004    0.8997    155160\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))\n",
    "\n",
    "c = confusion_matrix(all_targets, all_predictions, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(c)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
