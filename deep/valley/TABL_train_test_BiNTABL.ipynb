{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original source  \n",
    "https://github.com/LeonardoBerti00/TABL-Temporal-Attention-Augmented-Bilinear-Network-for-Financial-Time-Series-Data-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-PVsZeWjCiw"
   },
   "source": [
    "### **TABL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AVPONVeVw0nh"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNdy1u5zjMaw"
   },
   "source": [
    "### **Data**\n",
    "The dataset in the folder Dataset is the FI-2010 dataset zipped and normalized. \n",
    "\n",
    "As in the original paper I used the firs 7 days to train and to validate, and the rest 3 days to do the the testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ls5u0jngxkjl"
   },
   "outputs": [],
   "source": [
    "# please change the data_path to your local path and download the files you need from the web site of the dataset\n",
    "\n",
    "#dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "#dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "dec_data = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Training/Train_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(dec_data.shape[1] * 0.8)]\n",
    "dec_val = dec_data[:, int(dec_data.shape[1] * 0.8):]\n",
    "\n",
    "#dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "#dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt')\n",
    "#dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt')\n",
    "dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_9.txt')\n",
    "#dec_test1 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_7.txt')\n",
    "#dec_test2 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_8.txt')\n",
    "#dec_test3 = np.loadtxt('data/FI-2010/BenchmarkDatasets/Auction/3.Auction_DecPre/Auction_DecPre_Testing/Test_Dst_Auction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "# dec_train.shape = (149, 203800)\n",
    "\n",
    "h = 2        #if h = 2, than horizon = 50\n",
    "T = 50      #horizon \n",
    "dim = 10\n",
    "k = T//10    #horizon\n",
    "\n",
    "#t_offset = 0   # original label\n",
    "t_offset = k-1 # fixed label. temporal shifted\n",
    "\n",
    "y_train = dec_train[-h, :].flatten()\n",
    "# y_train.shape = (203800,)\n",
    "y_val = dec_val[-h, :].flatten()\n",
    "y_test = dec_test[-h, :].flatten()\n",
    "\n",
    "# 10-1: 10 means the length of inputs\n",
    "# second -1 means [1,2,3] to [0,1,2] conversion of class id\n",
    "y_train = y_train[dim-1+t_offset:] - 1\n",
    "#y_train = y_train[dim-1:] - 1\n",
    "# y_train.shape = (203791,) # 203791 = 203800-(10+1)\n",
    "y_val = y_val[dim-1+t_offset:] - 1\n",
    "#y_val = y_val[dim-1:] - 1\n",
    "y_test = y_test[dim-1+t_offset:] - 1 \n",
    "#y_test = y_test[dim-1:] - 1 \n",
    "\n",
    "# First 40 features = 10*4 features\n",
    "dec_train = dec_train[:40, :].T\n",
    "# dec_train.shape = (203800, 40)\n",
    "dec_val = dec_val[:40, :].T\n",
    "dec_test = dec_test[:40, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the weights for the weighted cross entropy loss\n",
    "def compute_weights(y):\n",
    "  cont_0 = 0\n",
    "  cont_1 = 0\n",
    "  cont_2 = 0\n",
    "  for i in range(y.shape[0]):\n",
    "    if (y[i] == 0):\n",
    "      cont_0 += 1\n",
    "    elif (y[i] == 1):\n",
    "      cont_1 += 1\n",
    "    elif (y[i] == 2):\n",
    "      cont_2 += 2\n",
    "    else: \n",
    "      raise Exception(\"wrong labels\")\n",
    "  return torch.Tensor([1e6/cont_0, 1e6/cont_1, 1e6/cont_2]).to(device)\n",
    "\n",
    "y_total = np.concatenate((y_train, y_val, y_test))\n",
    "weights = compute_weights(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8x7PAu1LySOZ"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x, y, num_classes, dim):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.num_classes = num_classes\n",
    "        self.dim = dim\n",
    "        self.x = x   \n",
    "        self.y = y\n",
    "\n",
    "        #self.length = x.shape[0] - (T/10) -self.dim + 1\n",
    "        self.length = x.shape[0] - ((T//10)-1) -self.dim + 1\n",
    "        print(self.length)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return int(self.length)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input = self.x[i:i+self.dim, :]\n",
    "        input = input.permute(1, 2, 0)\n",
    "        input = torch.squeeze(input)\n",
    "\n",
    "        return input, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ndByE-Ajmq8",
    "outputId": "9b68ee43-4e8d-4483-c284-512fb31797e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60578\n",
      "155161\n",
      "242347\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "   \n",
    "lr = 0.01\n",
    "num_classes = 3\n",
    "#dim = 10\n",
    "\n",
    "dataset_val = Dataset(dec_val, y_val, num_classes, dim)\n",
    "dataset_test = Dataset(dec_test, y_test, num_classes, dim)\n",
    "dataset_train = Dataset(dec_train, y_train, num_classes, dim)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35983073"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 10]) torch.Size([])\n",
      "tensor([0.3543, 0.3688, 0.3688, 0.3688, 0.3688, 0.3708, 0.3673, 0.3673, 0.3688,\n",
      "        0.3673], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(dataset_train):\n",
    "    print(x.shape, y.shape)\n",
    "    n = x.shape[0]\n",
    "    mids = (x[0, :] + x[2, :])/2\n",
    "    print(mids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEIIi2NwjtgC"
   },
   "source": [
    "### **Model Architecture**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lhA2p2kcUj2q"
   },
   "outputs": [],
   "source": [
    "class TABL_layer(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "\n",
    "        weight = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "        \n",
    "        weight2 = torch.Tensor(t1, t1)\n",
    "        self.W = nn.Parameter(weight2)\n",
    "        nn.init.constant_(self.W, 1/t1)\n",
    " \n",
    "        weight3 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight3)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.Tensor(d2, t2)\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        l = torch.Tensor(1,)\n",
    "        self.l = nn.Parameter(l)\n",
    "        nn.init.constant_(self.l, 0.5)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        #maintaining the weight parameter between 0 and 1.\n",
    "        if (self.l[0] < 0): \n",
    "          l = torch.Tensor(1,)\n",
    "          self.l = nn.Parameter(l)\n",
    "          nn.init.constant_(self.l, 0.0)\n",
    "\n",
    "        if (self.l[0] > 1): \n",
    "          l = torch.Tensor(1,)\n",
    "          self.l = nn.Parameter(l)\n",
    "          nn.init.constant_(self.l, 1.0)\n",
    "     \n",
    "        #modelling the dependence along the first mode of X while keeping the temporal order intact (7)\n",
    "        X = self.W1 @ X\n",
    "\n",
    "        #enforcing constant (1) on the diagonal\n",
    "        W = self.W -self.W *torch.eye(self.t1,dtype=torch.float32).to(device)+torch.eye(self.t1,dtype=torch.float32).to(device)/self.t1\n",
    "\n",
    "        #attention, the aim of the second step is to learn how important the temporal instances are to each other (8)\n",
    "        E = X @ W\n",
    "\n",
    "        #computing the attention mask  (9)\n",
    "        A = torch.softmax(E, dim=-1)\n",
    "\n",
    "        #applying a soft attention mechanism  (10)\n",
    "        #he attention mask A obtained from the third step is used to zero out the effect of unimportant elements\n",
    "        X = self.l[0] * (X) + (1.0 - self.l[0])*X*A\n",
    "\n",
    "        #the final step of the proposed layer estimates the temporal mapping W2, after the bias shift (11)\n",
    "        y = X @ self.W2 + self.B\n",
    "        return y\n",
    "\n",
    "class BL_layer(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        weight1 = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight1)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight2)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.zeros((d2, t2))\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.activation(self.W1 @ x @ self.W2 + self.B)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class BTABL(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2, d3, t3):\n",
    "    super().__init__()\n",
    "\n",
    "    self.BL = BL_layer(d2, d1, t1, t2)\n",
    "    self.TABL = TABL_layer(d3, d2, t2, t3)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    self.max_norm_(self.BL.W1.data)\n",
    "    self.max_norm_(self.BL.W2.data)\n",
    "    x = self.BL(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.TABL.W1.data)\n",
    "    self.max_norm_(self.TABL.W.data)\n",
    "    self.max_norm_(self.TABL.W2.data)\n",
    "    x = self.TABL(x)\n",
    "    x = torch.squeeze(x)\n",
    "    x = torch.softmax(x, 1)\n",
    "    return x\n",
    "\n",
    "  def max_norm_(self, w):\n",
    "    with torch.no_grad():\n",
    "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "        norm = torch.linalg.matrix_norm(w)\n",
    "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "        w *= (desired / (1e-8 + norm))\n",
    "\n",
    "\n",
    "\n",
    "class CTABL(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2, d3, t3, d4, t4):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.BL = BL_layer(d2, d1, t1, t2)\n",
    "    self.BL2 = BL_layer(d3, d2, t2, t3)\n",
    "    self.TABL = TABL_layer(d4, d3, t3, t4)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    " \n",
    "    self.max_norm_(self.BL.W1.data)\n",
    "    self.max_norm_(self.BL.W2.data)\n",
    "    x = self.BL(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.BL2.W1.data)\n",
    "    self.max_norm_(self.BL2.W2.data)\n",
    "    x = self.BL2(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    self.max_norm_(self.TABL.W1.data)\n",
    "    self.max_norm_(self.TABL.W.data)\n",
    "    self.max_norm_(self.TABL.W2.data)\n",
    "    x = self.TABL(x)\n",
    "    x = torch.squeeze(x)\n",
    "    x = torch.softmax(x, 1)\n",
    "    return x\n",
    "\n",
    "  def max_norm_(self, w):\n",
    "    with torch.no_grad():\n",
    "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "        norm = torch.linalg.matrix_norm(w)\n",
    "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "        w *= (desired / (1e-8 + norm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiN(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "        self.d1 = d1\n",
    "        self.t2 = t2\n",
    "        self.d2 = d2\n",
    "\n",
    "        bias1 = torch.Tensor(t1, 1)\n",
    "        self.B1 = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B1, 0)\n",
    "\n",
    "        l1 = torch.Tensor(t1, 1)\n",
    "        self.l1 = nn.Parameter(l1)\n",
    "        nn.init.xavier_normal_(self.l1)\n",
    "\n",
    "        bias2 = torch.Tensor(d1, 1)\n",
    "        self.B2 = nn.Parameter(bias2)\n",
    "        nn.init.constant_(self.B2, 0)\n",
    "\n",
    "        l2 = torch.Tensor(d1, 1)\n",
    "        self.l2 = nn.Parameter(l2)\n",
    "        nn.init.xavier_normal_(self.l2)\n",
    "\n",
    "        y1 = torch.Tensor(1, )\n",
    "        self.y1 = nn.Parameter(y1)\n",
    "        nn.init.constant_(self.y1, 0.5)\n",
    "\n",
    "        y2 = torch.Tensor(1, )\n",
    "        self.y2 = nn.Parameter(y2)\n",
    "        nn.init.constant_(self.y2, 0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # if the two scalars are negative then we setting them to 0\n",
    "        if (self.y1[0] < 0):\n",
    "            y1 = torch.cuda.FloatTensor(1, )\n",
    "            self.y1 = nn.Parameter(y1)\n",
    "            nn.init.constant_(self.y1, 0.01)\n",
    "\n",
    "        if (self.y2[0] < 0):\n",
    "            y2 = torch.cuda.FloatTensor(1, )\n",
    "            self.y2 = nn.Parameter(y2)\n",
    "            nn.init.constant_(self.y2, 0.01)\n",
    "\n",
    "        # normalization along the temporal dimensione\n",
    "        #T2 = torch.ones([self.t1, 1], device=cst.DEVICE_TYPE)\n",
    "        T2 = torch.ones([self.t1, 1], device=device)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x2 = torch.reshape(x2, (x2.shape[0], x2.shape[1], 1))\n",
    "\n",
    "        std = torch.std(x, dim=2)\n",
    "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
    "        # it can be possible that the std of some temporal slices is 0, and this produces inf values, so we have to set them to one\n",
    "        std[std < 1e-4] = 1\n",
    "\n",
    "        diff = x - (x2 @ (T2.T))\n",
    "        Z2 = diff / (std @ (T2.T))\n",
    "\n",
    "        X2 = self.l2 @ T2.T\n",
    "        X2 = X2 * Z2\n",
    "        X2 = X2 + (self.B2 @ T2.T)\n",
    "\n",
    "        # normalization along the feature dimension\n",
    "        #T1 = torch.ones([self.d1, 1], device=cst.DEVICE_TYPE)\n",
    "        T1 = torch.ones([self.d1, 1], device=device)\n",
    "        x1 = torch.mean(x, dim=1)\n",
    "        x1 = torch.reshape(x1, (x1.shape[0], x1.shape[1], 1))\n",
    "\n",
    "        std = torch.std(x, dim=1)\n",
    "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
    "\n",
    "        op1 = x1 @ T1.T\n",
    "        op1 = torch.permute(op1, (0, 2, 1))\n",
    "\n",
    "        op2 = std @ T1.T\n",
    "        op2 = torch.permute(op2, (0, 2, 1))\n",
    "\n",
    "        z1 = (x - op1) / (op2)\n",
    "        X1 = (T1 @ self.l1.T)\n",
    "        X1 = X1 * z1\n",
    "        X1 = X1 + (T1 @ self.B1.T)\n",
    "\n",
    "        # weighing the imporance of temporal and feature normalization\n",
    "        x = self.y1 * X1 + self.y2 * X2\n",
    "\n",
    "        return x\n",
    "        \n",
    "class BL_layer(nn.Module):\n",
    "  def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        weight1 = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight1)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight2)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.zeros((d2, t2))\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.activation(self.W1 @ x @ self.W2 + self.B)\n",
    "\n",
    "    return x\n",
    "\n",
    "class TABL_layer(nn.Module):\n",
    "    def __init__(self, d2, d1, t1, t2):\n",
    "        super().__init__()\n",
    "        self.t1 = t1\n",
    "\n",
    "        weight = torch.Tensor(d2, d1)\n",
    "        self.W1 = nn.Parameter(weight)\n",
    "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
    "\n",
    "        weight2 = torch.Tensor(t1, t1)\n",
    "        self.W = nn.Parameter(weight2)\n",
    "        nn.init.constant_(self.W, 1 / t1)\n",
    "\n",
    "        weight3 = torch.Tensor(t1, t2)\n",
    "        self.W2 = nn.Parameter(weight3)\n",
    "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
    "\n",
    "        bias1 = torch.Tensor(d2, t2)\n",
    "        self.B = nn.Parameter(bias1)\n",
    "        nn.init.constant_(self.B, 0)\n",
    "\n",
    "        l = torch.Tensor(1, )\n",
    "        self.l = nn.Parameter(l)\n",
    "        nn.init.constant_(self.l, 0.5)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # maintaining the weight parameter between 0 and 1.\n",
    "        if (self.l[0] < 0):\n",
    "            l = torch.Tensor(1, )\n",
    "            self.l = nn.Parameter(l)\n",
    "            nn.init.constant_(self.l, 0.0)\n",
    "\n",
    "        if (self.l[0] > 1):\n",
    "            l = torch.Tensor(1, )\n",
    "            self.l = nn.Parameter(l)\n",
    "            nn.init.constant_(self.l, 1.0)\n",
    "\n",
    "        # modelling the dependence along the first mode of X while keeping the temporal order intact (7)\n",
    "        X = self.W1 @ X\n",
    "\n",
    "        # enforcing constant (1) on the diagonal\n",
    "        #W = self.W - self.W * torch.eye(self.t1, dtype=torch.float32, device=cst.DEVICE_TYPE) + torch.eye(self.t1, dtype=torch.float32, device=cst.DEVICE_TYPE) / self.t1\n",
    "        W = self.W - self.W * torch.eye(self.t1, dtype=torch.float32, device=device) + torch.eye(self.t1, dtype=torch.float32, device=device) / self.t1\n",
    "\n",
    "        # attention, the aim of the second step is to learn how important the temporal instances are to each other (8)\n",
    "        E = X @ W\n",
    "\n",
    "        # computing the attention mask  (9)\n",
    "        A = torch.softmax(E, dim=-1)\n",
    "\n",
    "        # applying a soft attention mechanism  (10)\n",
    "        # he attention mask A obtained from the third step is used to zero out the effect of unimportant elements\n",
    "        X = self.l[0] * (X) + (1.0 - self.l[0]) * X * A\n",
    "\n",
    "        # the final step of the proposed layer estimates the temporal mapping W2, after the bias shift (11)\n",
    "        y = X @ self.W2 + self.B\n",
    "        return y\n",
    "\n",
    "\n",
    "class BiN_CTABL(nn.Module):\n",
    "    # d2=60, d1=40, t1=10, t2=10, d3=120, t3=5, d4=3, t4=1\n",
    "    def __init__(self, d2, d1, t1, t2, d3, t3, d4, t4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BiN = BiN(d2, d1, t1, t2)\n",
    "        self.BL = BL_layer(d2, d1, t1, t2)\n",
    "        self.BL2 = BL_layer(d3, d2, t2, t3)\n",
    "        # d4=3, d3=120, t3=5, t4=1\n",
    "        self.TABL = TABL_layer(d4, d3, t3, t4)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x.shape = (32, 40, 10)\n",
    "        # first of all we pass the input to the BiN layer, then we use the C(TABL) architecture\n",
    "        #x = torch.permute(x, (0, 2, 1))\n",
    "\n",
    "        x = self.BiN(x)\n",
    "\n",
    "        self.max_norm_(self.BL.W1.data)\n",
    "        self.max_norm_(self.BL.W2.data)\n",
    "        x = self.BL(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        self.max_norm_(self.BL2.W1.data)\n",
    "        self.max_norm_(self.BL2.W2.data)\n",
    "        x = self.BL2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        self.max_norm_(self.TABL.W1.data)\n",
    "        self.max_norm_(self.TABL.W.data)\n",
    "        self.max_norm_(self.TABL.W2.data)\n",
    "        x = self.TABL(x)\n",
    "        # x.shape = (32, 3, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        # x.shape = (32, 3)\n",
    "        x = torch.softmax(x, 1)\n",
    "        # x.shape = (32, 3)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def max_norm_(self, w):\n",
    "        with torch.no_grad():\n",
    "            if (torch.linalg.matrix_norm(w) > 10.0):\n",
    "                norm = torch.linalg.matrix_norm(w)\n",
    "                desired = torch.clamp(norm, min=0.0, max=10.0)\n",
    "                w *= (desired / (1e-8 + norm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bejZgDmCkkHi"
   },
   "source": [
    "### **Model Training**\n",
    "\n",
    "I implemented the second setting of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "s_u5esKfTT-S"
   },
   "outputs": [],
   "source": [
    "#Choose between B(TABL) and C(TABL)\n",
    "\n",
    "#model = BTABL(120, 40, 10, 5, 3, 1)\n",
    "#model = CTABL(60, 40, 10, 10, 120, 5, 3, 1)\n",
    "#model = BiN_CTABL(60, 40, 10, 10, 120, 5, 3, 1)\n",
    "model = BiN_CTABL(60, 40, dim, 10, 120, 5, 3, 1)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def batch_gd(model, criterion, optimizer, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "    SC = [0.005, 0.001, 0.0005, 0.0001]\n",
    "    i = 0\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print('### debug 22')\n",
    "            #print(outputs.shape)\n",
    "            #print(targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "        \n",
    "        if (train_losses[it-1] <= train_loss and i < 4 and it != 0):\n",
    "              for g in optimizer.param_groups:\n",
    "                g['lr'] = SC[i]\n",
    "              i += 1\n",
    "              \n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            #outputs = torch.squeeze(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        #We save the best model\n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(model, './best_model_CTABL')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "        \n",
    "    #torch.save(model, '/content/drive/MyDrive/Output/best_model_translob_FI')\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x9vq-ZAzTb6K",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- List Hyper Parameters -------\n",
      "epochs   ->   200\n",
      "learningRate   ->   0.01\n",
      "horizon    ->     50\n",
      "batch size   ->    256\n",
      "Optimizer   ->    Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                            | 1/200 [00:10<35:09, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/200, Train Loss: 1.0169,           Validation Loss: 0.9720, Duration: 0:00:10.601151, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                            | 2/200 [00:20<33:24, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/200, Train Loss: 0.9874,           Validation Loss: 0.9647, Duration: 0:00:09.789578, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                           | 3/200 [00:30<33:39, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/200, Train Loss: 0.9814,           Validation Loss: 0.9604, Duration: 0:00:10.401138, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                           | 4/200 [00:40<33:24, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/200, Train Loss: 0.9777,           Validation Loss: 0.9582, Duration: 0:00:10.184590, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                           | 5/200 [00:51<33:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 5/200, Train Loss: 0.9747,           Validation Loss: 0.9573, Duration: 0:00:10.032187, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                          | 6/200 [01:00<32:29, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.9726,           Validation Loss: 0.9592, Duration: 0:00:09.833035, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▋                                                                          | 7/200 [01:10<31:37,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.9703,           Validation Loss: 0.9589, Duration: 0:00:09.383289, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                          | 8/200 [01:20<31:27,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 8/200, Train Loss: 0.9684,           Validation Loss: 0.9548, Duration: 0:00:09.837581, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                         | 9/200 [01:30<31:42,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.9674,           Validation Loss: 0.9558, Duration: 0:00:10.243160, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                        | 10/200 [01:40<31:23,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.9659,           Validation Loss: 0.9566, Duration: 0:00:09.807918, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▏                                                                       | 11/200 [01:49<31:06,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.9641,           Validation Loss: 0.9557, Duration: 0:00:09.789860, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▌                                                                       | 12/200 [01:59<30:51,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.9628,           Validation Loss: 0.9578, Duration: 0:00:09.781703, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                       | 13/200 [02:09<30:57,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 0.9623,           Validation Loss: 0.9560, Duration: 0:00:10.131873, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                      | 14/200 [02:19<30:08,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 0.9612,           Validation Loss: 0.9561, Duration: 0:00:09.230435, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▋                                                                      | 15/200 [02:28<29:47,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 15/200, Train Loss: 0.9596,           Validation Loss: 0.9545, Duration: 0:00:09.519766, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                      | 16/200 [02:38<29:35,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Train Loss: 0.9588,           Validation Loss: 0.9548, Duration: 0:00:09.619350, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                     | 17/200 [02:48<29:41,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 0.9582,           Validation Loss: 0.9552, Duration: 0:00:09.942463, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▊                                                                     | 18/200 [02:57<29:28,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 0.9564,           Validation Loss: 0.9608, Duration: 0:00:09.666208, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▏                                                                    | 19/200 [03:07<29:24,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 0.9560,           Validation Loss: 0.9571, Duration: 0:00:09.819899, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 20/200 [03:17<29:33,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 0.9548,           Validation Loss: 0.9577, Duration: 0:00:10.098001, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                    | 21/200 [03:27<29:07,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 0.9539,           Validation Loss: 0.9549, Duration: 0:00:09.543338, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▎                                                                   | 22/200 [03:37<29:09,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 0.9532,           Validation Loss: 0.9549, Duration: 0:00:09.992382, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▋                                                                   | 23/200 [03:47<28:56,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 0.9521,           Validation Loss: 0.9573, Duration: 0:00:09.765869, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████                                                                   | 24/200 [03:56<28:30,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 0.9523,           Validation Loss: 0.9594, Duration: 0:00:09.504396, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                  | 25/200 [04:06<28:32,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 0.9693,           Validation Loss: 0.9639, Duration: 0:00:09.931176, Best Val Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▉                                                                  | 26/200 [04:16<28:18,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 26/200, Train Loss: 0.9579,           Validation Loss: 0.9539, Duration: 0:00:09.717373, Best Val Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▎                                                                 | 27/200 [04:26<28:34,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 27/200, Train Loss: 0.9545,           Validation Loss: 0.9539, Duration: 0:00:10.255000, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▋                                                                 | 28/200 [04:36<28:21,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.9519,           Validation Loss: 0.9558, Duration: 0:00:09.842824, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████                                                                 | 29/200 [04:45<27:48,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 0.9507,           Validation Loss: 0.9558, Duration: 0:00:09.447645, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▍                                                                | 30/200 [04:55<27:20,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 0.9490,           Validation Loss: 0.9582, Duration: 0:00:09.400327, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▊                                                                | 31/200 [05:05<27:36,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.9487,           Validation Loss: 0.9556, Duration: 0:00:10.153701, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▏                                                               | 32/200 [05:15<27:36,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 0.9478,           Validation Loss: 0.9560, Duration: 0:00:09.990927, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                               | 33/200 [05:25<27:44,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.9473,           Validation Loss: 0.9564, Duration: 0:00:10.225369, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▉                                                               | 34/200 [05:35<27:21,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 0.9466,           Validation Loss: 0.9578, Duration: 0:00:09.690686, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▎                                                              | 35/200 [05:45<27:21,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 0.9453,           Validation Loss: 0.9570, Duration: 0:00:10.088783, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▋                                                              | 36/200 [05:54<26:59,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 0.9448,           Validation Loss: 0.9568, Duration: 0:00:09.697988, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████                                                              | 37/200 [06:04<26:32,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 0.9443,           Validation Loss: 0.9586, Duration: 0:00:09.530799, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                             | 38/200 [06:14<26:23,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 0.9437,           Validation Loss: 0.9568, Duration: 0:00:09.782366, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▊                                                             | 39/200 [06:24<26:17,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 0.9433,           Validation Loss: 0.9582, Duration: 0:00:09.848545, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 40/200 [06:33<26:09,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.9432,           Validation Loss: 0.9575, Duration: 0:00:09.837070, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▌                                                            | 41/200 [06:43<26:08,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 0.9433,           Validation Loss: 0.9572, Duration: 0:00:09.989352, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▉                                                            | 42/200 [06:53<25:49,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 0.9376,           Validation Loss: 0.9576, Duration: 0:00:09.679310, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▎                                                           | 43/200 [07:02<25:13,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Train Loss: 0.9362,           Validation Loss: 0.9585, Duration: 0:00:09.253988, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▋                                                           | 44/200 [07:12<25:16,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Train Loss: 0.9360,           Validation Loss: 0.9583, Duration: 0:00:09.894113, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████                                                           | 45/200 [07:23<25:39,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Train Loss: 0.9358,           Validation Loss: 0.9605, Duration: 0:00:10.424087, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▍                                                          | 46/200 [07:33<25:46, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 0.9351,           Validation Loss: 0.9602, Duration: 0:00:10.311267, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▊                                                          | 47/200 [07:43<25:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.9348,           Validation Loss: 0.9591, Duration: 0:00:09.889573, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▏                                                         | 48/200 [07:53<25:19, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 0.9348,           Validation Loss: 0.9595, Duration: 0:00:09.993209, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▌                                                         | 49/200 [08:02<24:49,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 0.9345,           Validation Loss: 0.9625, Duration: 0:00:09.551355, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                         | 50/200 [08:13<24:49,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Train Loss: 0.9341,           Validation Loss: 0.9609, Duration: 0:00:10.079981, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▍                                                        | 51/200 [08:23<24:39,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 0.9342,           Validation Loss: 0.9626, Duration: 0:00:09.937481, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▊                                                        | 52/200 [08:33<24:32,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.9297,           Validation Loss: 0.9601, Duration: 0:00:09.992483, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                       | 53/200 [08:43<24:33, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 0.9292,           Validation Loss: 0.9600, Duration: 0:00:10.196695, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▌                                                       | 54/200 [08:53<24:17,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200, Train Loss: 0.9284,           Validation Loss: 0.9601, Duration: 0:00:09.880889, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▉                                                       | 55/200 [09:02<23:58,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Train Loss: 0.9279,           Validation Loss: 0.9602, Duration: 0:00:09.768404, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▎                                                      | 56/200 [09:12<23:17,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Train Loss: 0.9278,           Validation Loss: 0.9602, Duration: 0:00:09.211912, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▋                                                      | 57/200 [09:21<23:07,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Train Loss: 0.9278,           Validation Loss: 0.9606, Duration: 0:00:09.703049, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████                                                      | 58/200 [09:31<22:56,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Train Loss: 0.9276,           Validation Loss: 0.9604, Duration: 0:00:09.672160, Best Val Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████                                                      | 58/200 [09:36<23:31,  9.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch size   ->    \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(batch_size))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer   ->    \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(optimizer))\n\u001b[0;32m----> 8\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_gd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 27\u001b[0m, in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m t0 \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     26\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# move data to GPU\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat), targets\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/venv-valley/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/venv-valley/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/venv-valley/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/venv-valley/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"------- List Hyper Parameters -------\")\n",
    "print(\"epochs   ->   \" + str(epochs))\n",
    "print(\"learningRate   ->   \" + str(lr))\n",
    "print(\"horizon    ->     \" + str(T))\n",
    "print(\"batch size   ->    \" + str(batch_size))\n",
    "print(\"Optimizer   ->    \" + str(optimizer))\n",
    "\n",
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                     epochs)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7CF2CwUkn4G"
   },
   "source": [
    "### **Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TFg5d6CzTgWS",
    "outputId": "8d1c2dfd-ecff-4f59-e1dd-45504c121328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5230\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./best_model_CTABL')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    #print(outputs)\n",
    "    #print(predictions)\n",
    "    #print(targets)\n",
    "    #print((predictions == targets).sum().item(), targets.shape[0])\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n",
    "  \n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0oOu5lwf6zw0",
    "outputId": "a7f1be3e-e874-4733-cead-ca3651a170cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5230309162740637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3972    0.6654    0.4975     42515\n",
      "           1     0.6705    0.5999    0.6332     73156\n",
      "           2     0.4857    0.2275    0.3098     39490\n",
      "\n",
      "    accuracy                         0.5230    155161\n",
      "   macro avg     0.5178    0.4976    0.4802    155161\n",
      "weighted avg     0.5486    0.5230    0.5137    155161\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))\n",
    "\n",
    "c = confusion_matrix(all_targets, all_predictions, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(c)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5230309162740637\n",
      "f1_score_w: 0.5137096176234173\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3972    0.6654    0.4975     42515\n",
      "           1     0.6705    0.5999    0.6332     73156\n",
      "           2     0.4857    0.2275    0.3098     39490\n",
      "\n",
      "    accuracy                         0.5230    155161\n",
      "   macro avg     0.5178    0.4976    0.4802    155161\n",
      "weighted avg     0.5486    0.5230    0.5137    155161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print('f1_score_w:', f1_score(all_targets, all_predictions, average='weighted'))\n",
    "\n",
    "print()\n",
    "print(classification_report(all_targets, all_predictions, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66536517, 0.24055039, 0.09408444],\n",
       "       [0.32479906, 0.5998551 , 0.07534584],\n",
       "       [0.48538871, 0.28713598, 0.22747531]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s = str(c.tolist())\n",
    "np.fromstring(', '.join(re.findall(r'\\[+(.+?)\\]', s)), sep =', ').reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
